{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/mdafifal.mamun/notebooks/triagerX/comp_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_state</th>\n",
       "      <th>creator</th>\n",
       "      <th>labels</th>\n",
       "      <th>owner</th>\n",
       "      <th>component</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2217</td>\n",
       "      <td>6455</td>\n",
       "      <td>AttachAPI backwards compatibility broken?</td>\n",
       "      <td>@pdbain-ibm Hey Peter, I just reimplemented th...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>DanHeidinga</td>\n",
       "      <td>question, prio:high, comp:vm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comp:vm</td>\n",
       "      <td>Bug Title: AttachAPI backwards compatibility b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2553</td>\n",
       "      <td>7332</td>\n",
       "      <td>JBoss cached LUDCL failure</td>\n",
       "      <td>As reported in \"DefaultContextServiceServletTe...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>DanHeidinga</td>\n",
       "      <td>comp:vm, doc:externals</td>\n",
       "      <td>theresa-m</td>\n",
       "      <td>comp:vm</td>\n",
       "      <td>Bug Title: JBoss cached LUDCL failure\\nBug Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1757</td>\n",
       "      <td>4976</td>\n",
       "      <td>Some ROMclasses in Java 11 are not stored in t...</td>\n",
       "      <td>Found some ROMclasses in Java 11 are not store...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>a7ehuo</td>\n",
       "      <td>bug, comp:vm, userRaised</td>\n",
       "      <td>babsingh</td>\n",
       "      <td>comp:vm</td>\n",
       "      <td>Bug Title: Some ROMclasses in Java 11 are not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3807</td>\n",
       "      <td>10454</td>\n",
       "      <td>JDK16 Valhalla ValueTypeTests FAILED: testGCFl...</td>\n",
       "      <td>Failure link\\nFrom an internal build `Test_ope...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>JasonFengJ9</td>\n",
       "      <td>comp:gc, project:valhalla, test failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comp:gc</td>\n",
       "      <td>Bug Title: JDK16 Valhalla ValueTypeTests FAILE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>6438</td>\n",
       "      <td>Support and enable arraycopy transformations f...</td>\n",
       "      <td>This issue tracks the work to enable the array...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>0xdaryl</td>\n",
       "      <td>help wanted, comp:jit, arch:aarch64</td>\n",
       "      <td>oussamasaoudi</td>\n",
       "      <td>comp:jit</td>\n",
       "      <td>Bug Title: Support and enable arraycopy transf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  issue_number  \\\n",
       "0        2217          6455   \n",
       "1        2553          7332   \n",
       "2        1757          4976   \n",
       "3        3807         10454   \n",
       "4        2205          6438   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0          AttachAPI backwards compatibility broken?   \n",
       "1                         JBoss cached LUDCL failure   \n",
       "2  Some ROMclasses in Java 11 are not stored in t...   \n",
       "3  JDK16 Valhalla ValueTypeTests FAILED: testGCFl...   \n",
       "4  Support and enable arraycopy transformations f...   \n",
       "\n",
       "                                         description  \\\n",
       "0  @pdbain-ibm Hey Peter, I just reimplemented th...   \n",
       "1  As reported in \"DefaultContextServiceServletTe...   \n",
       "2  Found some ROMclasses in Java 11 are not store...   \n",
       "3  Failure link\\nFrom an internal build `Test_ope...   \n",
       "4  This issue tracks the work to enable the array...   \n",
       "\n",
       "                                           issue_url issue_state      creator  \\\n",
       "0  https://github.com/eclipse-openj9/openj9/issue...      closed  DanHeidinga   \n",
       "1  https://github.com/eclipse-openj9/openj9/issue...      closed  DanHeidinga   \n",
       "2  https://github.com/eclipse-openj9/openj9/issue...      closed       a7ehuo   \n",
       "3  https://github.com/eclipse-openj9/openj9/issue...      closed  JasonFengJ9   \n",
       "4  https://github.com/eclipse-openj9/openj9/issue...      closed      0xdaryl   \n",
       "\n",
       "                                    labels          owner component  \\\n",
       "0             question, prio:high, comp:vm            NaN   comp:vm   \n",
       "1                   comp:vm, doc:externals      theresa-m   comp:vm   \n",
       "2                 bug, comp:vm, userRaised       babsingh   comp:vm   \n",
       "3  comp:gc, project:valhalla, test failure            NaN   comp:gc   \n",
       "4      help wanted, comp:jit, arch:aarch64  oussamasaoudi  comp:jit   \n",
       "\n",
       "                                                text  \n",
       "0  Bug Title: AttachAPI backwards compatibility b...  \n",
       "1  Bug Title: JBoss cached LUDCL failure\\nBug Des...  \n",
       "2  Bug Title: Some ROMclasses in Java 11 are not ...  \n",
       "3  Bug Title: JDK16 Valhalla ValueTypeTests FAILE...  \n",
       "4  Bug Title: Support and enable arraycopy transf...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"component\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df[\"component\"].isin([\"comp:jvmti\", \"comp:jclextensions\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[\"component\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "class Llama3:\n",
    "    def __init__(self, model_id, max_new_tokens=512):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def invoke(\n",
    "        self, system_prompt, question, temperature=0.5, return_token_usage=False\n",
    "    ):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            max_length=self.model.config.max_position_embeddings - self.max_new_tokens,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        terminators = [\n",
    "            self.tokenizer.eos_token_id,\n",
    "            self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
    "        ]\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=self.max_new_tokens,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        response = outputs[0][input_ids.shape[-1] :]\n",
    "\n",
    "        if return_token_usage:\n",
    "            prompt_tokens = len(input_ids[0])\n",
    "            completion_tokens = len(outputs[0]) - prompt_tokens\n",
    "\n",
    "            token_usage = {\n",
    "                \"prompt_tokens\": prompt_tokens,\n",
    "                \"completion_tokens\": completion_tokens,\n",
    "                \"total_tokens\": prompt_tokens + completion_tokens,\n",
    "            }\n",
    "\n",
    "            return (\n",
    "                self.tokenizer.decode(response, skip_special_tokens=True),\n",
    "                token_usage,\n",
    "            )\n",
    "\n",
    "        return self.tokenizer.decode(response, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176b4d855a3d49669241ff4c19448f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "llama3_model = Llama3(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an efficient and correct data augmentor. \n",
    "Your job is when provided a bug report text, you modify only the natural language part. \n",
    "You can use synonyms or change the structure of the sentence by swapping words. \n",
    "But you never change code artifacts like source codes, stack traces, logs, crash reports, version, etc.\n",
    "Only return the augmented output. Nothing else.\n",
    "\n",
    "Now augment the following bug report:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                   5729\n",
       "issue_number                                                14662\n",
       "issue_title                               Security Model for CRIU\n",
       "description     CRIU checkpoint/restore jdk feature requires s...\n",
       "issue_url       https://github.com/eclipse-openj9/openj9/issue...\n",
       "issue_state                                                  open\n",
       "creator                                                   alon-sh\n",
       "labels                             comp:jclextensions, criu, beta\n",
       "owner                                                     alon-sh\n",
       "component                                      comp:jclextensions\n",
       "text            Bug Title: Security Model for CRIU\\nBug Descri...\n",
       "Name: 1171, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.iloc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component: comp:jvmti\n",
      "Bug Title: RedefinePreviousVersions not supported by OpenJ9\n",
      "Bug Description: `serviceability/jvmti/RedefineClasses/RedefinePreviousVersions.java` tests Hotspot specific cmd line options which\n",
      "are not supported in OpenJ9:\n",
      "-Xlog:redefine+class+iklass+add=trace,redefine+class+iklass+purge=trace\n",
      "Test source code: Setting `vm.opt.final.ClassUnloading` to true enables this test.\n",
      "This test will be permanently disabled for OpenJ9 since the above options are not supported by OpenJ9.\n",
      "##############################\n",
      "Bug Report: Bug Title: RedefinePreviousVersions not compatible with OpenJ9\n",
      "Bug Description: `serviceability/jvmti/RedefineClasses/RedefinePreviousVersions.java` validates Hotspot-specific command-line options that are incompatible with OpenJ9:\n",
      "-Xlog:redefine+class+iklass+add=trace,redefine+class+iklass+purge=trace\n",
      "Test source code: Enabling `vm.opt.final.ClassUnloading` to true enables this test.\n",
      "This test will be permanently disabled for OpenJ9 as these options are not compatible with OpenJ9.\n"
     ]
    }
   ],
   "source": [
    "idx = 19\n",
    "\n",
    "bug_report = filtered_df.iloc[idx].text\n",
    "print(\"Component:\", filtered_df.iloc[idx].component)\n",
    "print(filtered_df.iloc[idx].text)\n",
    "print(\"##############################\")\n",
    "print(llama3_model.invoke(system_prompt=SYSTEM_PROMPT, question=f\"Bug Report: {bug_report}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5004\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmented_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data for component: comp:test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: Bug Title: Produce a summarized excludes list for a particular test run\n",
      "Bug Description: We currently run several different types of tests (that use various underlying test frameworks). There are several methods for excluding test targets and the individual tests within the test target. We would like a way to summarize all of the test exclusions of a particular test run. There are a variety of ways to do this, one way, which would produce this info even on a manual/local test run would be to add a \"getExcludes\" target to testkitgen to tally test exclusions.\n",
      "Different supported mechanisms to exclude tests:\n",
      "- disable an entire test target in playlist.xml using `<disabled>` tag (preferred way)\n",
      "- disable a target's subtest: openjdk regression test using openjdk exclude files - disable a target's subtest: testNG functional test using functional exclude files\n",
      "- disable a target's subtest: cmdlinetester functional test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/438 [00:05<36:48,  5.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Generate a concise summary of excluded tests for a specific test execution\n",
      "\n",
      "Bug Description: We execute multiple types of tests (utilizing various underlying test frameworks). There are several approaches to excluding test targets and individual tests within the target. We require a method to summarize all test exclusions for a particular test run. One feasible approach would be to incorporate a \"getExcludes\" target into testkitgen to track test exclusions, even during manual or local test execution.\n",
      "\n",
      "Supported mechanisms to exclude tests:\n",
      "\n",
      "- Preferably, disable an entire test target in playlist.xml using the `<disabled>` tag\n",
      "- Disable a target's subtest: openjdk regression test using openjdk exclusion files\n",
      "- Disable a target's subtest: testNG functional test using functional exclusion files\n",
      "- Disable a target's subtest: cmdlinetester functional test\n",
      "Original data: Bug Title: Investigate use of public AzDo in combo with Azure VM agents Jenkins plugin\n",
      "Bug Description: We believe that we may be able to combine a [public Azure Devops]( for this open-source project (with [unlimited machine minutes]( and up to 10 parallel jobs) with a few Azure Jenkins plugins to create dynamically created test agents to expand the number of xlinux/windows/mac test machines. This issue will track the investigation and work that is required to enable this (if it is indeed possible).\n",
      "- [ ] Create public AzDo organization\n",
      "- [ ] Add committers as admins\n",
      "- [ ] Create a PR to add several Azure plugins to Eclipse Jenkins (similar to but adding azure-commons azure-credentials and azure-vm-agents)\n",
      "- [ ] Configure public AzDo as a cloud provider to Eclipse Jenkins as per [azure-vm-agents doc]( (EF infra assistance? can raise bugzilla once we know what is required)\n",
      "- [ ] Change [Jenkinsfilebase]( (currently in Sophia's branch) to call azure-vm-agents when no static machines are idle\n",
      "- [ ] Verify on xlinux resources first (follow later with others)\n",
      "- [ ] If we get to this point, review with committers & present in OpenJ9 community call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/438 [00:11<44:12,  6.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Explore Azure DevOps integration with Azure VM agents Jenkins plugin\n",
      "\n",
      "Bug Description: We suspect that we can combine a [public Azure DevOps]( with [unlimited machine hours]( and up to 10 parallel jobs) for this open-source project with a few Azure Jenkins plugins to create dynamically created test agents, thereby expanding the number of xlinux/windows/mac test machines. This issue will track the investigation and work required to enable this (if it is indeed feasible).\n",
      "- [ ] Establish a public Azure DevOps organization\n",
      "- [ ] Add committers as administrators\n",
      "- [ ] Create a pull request to add several Azure plugins to Eclipse Jenkins (similar to but including azure-commons, azure-credentials, and azure-vm-agents)\n",
      "- [ ] Configure public Azure DevOps as a cloud provider to Eclipse Jenkins, as per [azure-vm-agents documentation]( (EF infrastructure assistance? can raise a bug report once we know what is required)\n",
      "- [ ] Modify [Jenkinsfilebase]( (currently in Sophia's branch) to invoke azure-vm-agents when no static machines are idle\n",
      "- [ ] Verify on xlinux resources first (followed by others)\n",
      "- [ ] If we reach this point, review with committers and present in the OpenJ9 community call\n",
      "Original data: Bug Title: OpenJ9 sanity tests fail on OpenJ9 build with OpenJDK10 (18.3)\n",
      "Bug Description: When running the Sanity tests against a build of OpenJ9 with OpenJDK10 (18..3) the following test suites fail.\n",
      "FAILED test targets:\n",
      " JCL_Test_SE90_0\n",
      " JCL_Test_SE90_1\n",
      "These fail on these tests:\n",
      "test_getProperties\n",
      "test_getProperty\n",
      "test_getProperty2\n",
      "because the tests retrieve the system properties and check the java.version. The tests are looking for java.version starting with 9 where the java.version returned from this jdk is '10-internal'. Either the test frameworks needs to detect this new jdk version and run new tests or these tests need to be updated to work with both jdk9 and jdk10.\n",
      "Exact test failure for one of the tests is:\n",
      "test_getProperty2\n",
      "java.lang.AssertionError: Failed to return correct property value: 10-internal\n",
      " at org.testng.AssertJUnit.fail(AssertJUnit.java:59) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:24) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.openj9.test.java.lang.Test_System.test_getProperty2(Test_System.java:220) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/Java8andUp/GeneralTest.jar)\n",
      " at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(java.base@10-internal/Native Method) from jrt:/java.base\n",
      " at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(java.base@10-internal/NativeMethodAccessorImpl.java:62) from jrt:/java.base\n",
      " at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(java.base@10-internal/DelegatingMethodAccessorImpl.java:43) from jrt:/java.base\n",
      " at java.lang.reflect.Method.invoke(java.base@10-internal/Method.java:564) from jrt:/java.base\n",
      " at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:104) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.internal.Invoker.invokeMethod(Invoker.java:645) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:851) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1177) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:129) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:112) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestRunner.privateRun(TestRunner.java:756) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestRunner.run(TestRunner.java:610) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunner.runTest(SuiteRunner.java:387) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:382) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunner.run(SuiteRunner.java:289) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.runSuitesSequentially(TestNG.java:1293) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.runSuitesLocally(TestNG.java:1218) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.runSuites(TestNG.java:1133) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.run(TestNG.java:1104) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.privateMain(TestNG.java:1434) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.TestNG.main(TestNG.java:1403) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/438 [00:25<1:07:48,  9.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Here is the augmented bug report:\n",
      "\n",
      "Bug Title: Sanity tests fail on OpenJ9 build with OpenJDK10 due to incompatible java.version\n",
      "\n",
      "Bug Description: When running the Sanity tests against a build of OpenJ9 with OpenJDK10 (18.3), the following test suites fail.\n",
      "\n",
      "FAILED test targets:\n",
      " JCL_Test_SE90_0\n",
      " JCL_Test_SE90_1\n",
      "\n",
      "These fail on these tests:\n",
      "test_getProperties\n",
      "test_getProperty\n",
      "test_getProperty2\n",
      "because the tests retrieve the system properties and check the java.version. The tests are looking for java.version starting with 9, where the java.version returned from this jdk is '10-internal'. Either the test frameworks needs to detect this new jdk version and run new tests or these tests need to be updated to work with both jdk9 and jdk10.\n",
      "\n",
      "Exact test failure for one of the tests is:\n",
      "test_getProperty2\n",
      "java.lang.AssertionError: Failed to return correct property value: 10-internal\n",
      " at org.testng.AssertJUnit.fail(AssertJUnit.java:59) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:24) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/TestConfig/lib/testng.jar)\n",
      " at org.openj9.test.java.lang.Test_System.test_getProperty2(Test_System.java:220) from jdk.internal.loader.ClassLoaders$AppClassLoader@e62d135f(file:/root/openj9-openjdk-jdk9/openj9/jvmtest/Java8andUp/GeneralTest.jar)\n",
      " at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(java.base@10-internal/Native Method) from jrt:/java.base\n",
      " at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(java.base@10-internal/NativeMethodAccessorImpl.java:62) from jrt:/java.base\n",
      " at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(java.base@10-internal/DelegatingMethodAccessorImpl.java:43) from jrt:/java.base\n",
      " at java.lang.reflect.Method.invoke(java.base@10-internal/Method.java:564) from jrt:/java.base\n",
      " at org.testng.internal.MethodInvocationHelper.invokeMethod(Method\n",
      "Original data: Bug Title: Add CRIU testing\n",
      "Bug Description: Add tests for CRIUSupport\n",
      "CRIU is supported on JDK11+ and will likely be supported on JDK8 as well. However, CRIU enabled JDKs need to be built with a special configure option `--enable-criu-support` and they can only be run on machines with CRIU installed. CRIU is only supported on linux.\n",
      "We need a way to add a tag to these tests that reflect their special properties while still enabling them to run on all JDK levels.\n",
      "- [ ] label the CRIU machine with the correct label (label name TBD - sw.tool.criu? )\n",
      "- [ ] add new linux platforms (i.e., x86-64_linux_criu) in openjdk_tests (Related:\n",
      "- [ ] Add criu build targets #14241)\n",
      "- [x] add new system properties to determine if CRIU is enabled in the JDK\n",
      "- [ ] update TKG to auto-detect the spec with CRIU\n",
      "- [ ] update modes (Ottawa.csv)\n",
      "- [ ] add feature.criu in platformRequirements\n",
      "Update: if we have CRIU installed on all linux, I think we do not need the specific label on the machines. And maybe we can also avoid update modes (Ottawa.csv).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/438 [00:32<1:01:15,  8.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Incorporate CRIU Testing\n",
      "Bug Description: Introduce Tests for CRIU Support\n",
      "\n",
      "CRIU is compatible with JDK 11 and above, and it is likely to be compatible with JDK 8 as well. Nevertheless, CRIU-enabled JDKs must be built with a specific configuration option `--enable-criu-support` and can only be executed on machines with CRIU installed. CRIU is only supported on Linux platforms.\n",
      "\n",
      "We require a method to add a tag to these tests that reflects their unique properties while still enabling them to run on all JDK levels.\n",
      "\n",
      "- [ ] Identify the CRIU machine with the correct label (label name TBD - sw.tool.criu? )\n",
      "- [ ] Add new Linux platforms (i.e., x86-64_linux_criu) in openjdk_tests (Related:\n",
      "- [ ] Add criu build targets #14241)\n",
      "- [x] Add new system properties to determine if CRIU is enabled in the JDK\n",
      "- [ ] Update TKG to automatically detect the spec with CRIU\n",
      "- [ ] Update feature.criu in platformRequirements\n",
      "Update: If CRIU is installed on all Linux machines, I believe we do not need the specific label on the machines. Maybe we can also avoid updating modes (Ottawa.csv).\n",
      "Original data: Bug Title: Additional arraylets testing in sanity build\n",
      "Bug Description: An issue was discovered in extended testing of arraylets modes which caused the backout in PR #413 we should add more arraylets testing to the sanity builds to prevent future breaks in this area that is often missed in testing since it requires running with a non-default GC policy (eg balanced).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/438 [00:34<45:06,  6.25s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Enhancing arraylets testing in sanity build\n",
      "Bug Description: A problem was identified in the comprehensive testing of arraylets modes, which led to a rollback in PR #413. To avoid future disruptions in this area, we should incorporate additional arraylets testing into the sanity builds, as it is frequently overlooked in testing due to the requirement of running with a non-standard garbage collection policy (for instance, a balanced one).\n",
      "Original data: Bug Title: Add automated test for custom classloader defined via java.system.class.loader\n",
      "Bug Description: Need implement a custom classloader which is going to be defined via a system property `java.system.class.loader`, in addition, a class can only be loaded by this custom classloader, for JVM without PR #2941, a `ClassNotFoundException` should be thrown.\n",
      "This test is to support #2941 and prevent a regression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/438 [00:36<35:30,  4.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Implement automated testing for custom classloader defined via java.system.class.loader property\n",
      "Bug Description: It is necessary to develop a custom classloader that will be specified via the system property `java.system.class.loader`, and a class can only be loaded by this custom classloader. In JVMs without PR #2941, a `ClassNotFoundException` should be thrown. This test aims to support #2941 and prevent a potential regression.\n",
      "Original data: Bug Title: Moving VM test shared libraries will affect testing\n",
      "Bug Description: The shared libraries only used for test need to be moved out of the production images. This is going to affect the tests, as the tests will need to find the libraries in their new location.\n",
      "Doc issue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/438 [00:38<27:25,  3.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Relocating VM test dependencies will impact testing\n",
      "Bug Description: The dependencies exclusively utilized for testing purposes require relocation from production images. This relocation will have a ripple effect on the tests, as they will need to locate the dependencies in their new environment.\n",
      "Doc issue\n",
      "Original data: Bug Title: ppc64le Calendar.getInstance incorrect timezone\n",
      "Bug Description: MauveMultiThreadLoadTest_special_26\n",
      "variation: Mode612-OSRG\n",
      "JVM_OPTIONS: -Xcompressedrefs -Xcompressedrefs -Xgcpolicy:gencon -Xjit:enableOSR,enableOSROnGuardFailure,count=1,disableAsyncCompilation ub16p8j96\n",
      "LT - Test failed\n",
      "LT Failure num. = 1\n",
      "LT Test number = 3189\n",
      "LT Test details = 'Mauve[gnu.testlet.java.util.Calendar.getInstance]'\n",
      "LT Suite number = 0\n",
      "LT Thread number = 11\n",
      "LT >>> Captured test output >>>\n",
      "LT FAIL: gnu.testlet.java.util.Calendar.getInstance: () (number 0)\n",
      "LT got sun.util.calendar.ZoneInfo[id=\"America/Toronto\",offset=-18000000,dstSavings=3600000,useDaylight=true,transitions=231,lastRule=java.util.SimpleTimeZone[id=America/Toronto,offset=-18000000,dstSavings=3600000,useDaylight=true,startYear=0,startMode=3,startMonth=2,startDay=8,startDayOfWeek=1,startTime=7200000,startTimeMode=0,endMode=3,endMonth=10,endDay=1,endDayOfWeek=1,endTime=7200000,endTimeMode=0]] but expected java.util.SimpleTimeZone[id=GMT,offset=0,dstSavings=3600000,useDaylight=false,startYear=0,startMode=0,startMonth=0,startDay=0,startDayOfWeek=0,startTime=0,startTimeMode=0,endMode=0,endMonth=0,endDay=0,endDayOfWeek=0,endTime=0,endTimeMode=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/438 [00:48<41:09,  5.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Here is the augmented bug report:\n",
      "\n",
      "Bug Report: Bug Title: ppc64le Calendar.getInstance incorrect timezone\n",
      "Bug Description: LavenderMultiThreadLoadTest_special_27\n",
      "variation: Mode613-OSRG\n",
      "JVM_OPTIONS: -Xcompressedrefs -Xcompressedrefs -Xgcpolicy:gencon -Xjit:enableOSR,enableOSROnGuardFailure,count=1,disableAsyncCompilation ub16p8j97\n",
      "LT - Test failed\n",
      "LT Failure num. = 2\n",
      "LT Test number = 3190\n",
      "LT Test details = 'Mauve[gnu.testlet.java.util.Calendar.getInstance]'\n",
      "LT Suite number = 1\n",
      "LT Thread number = 12\n",
      "LT >>> Captured test output >>>\n",
      "LT FAIL: gnu.testlet.java.util.Calendar.getInstance: () (number 1)\n",
      "LT got sun.util.calendar.ZoneInfo[id=\"America/Toronto\",offset=-18000000,dstSavings=3600000,useDaylight=true,transitions=232,lastRule=java.util.SimpleTimeZone[id=America/Toronto,offset=-18000000,dstSavings=3600000,useDaylight=true,startYear=0,startMode=3,startMonth=2,startDay=8,startDayOfWeek=1,startTime=7200000,startTimeMode=0,endMode=3,endMonth=10,endDay=1,endDayOfWeek=1,endTime=7200000,endTimeMode=0]] but expected java.util.SimpleTimeZone[id=GMT,offset=0,dstSavings=3600000,useDaylight=false,startYear=0,startMode=0,startMonth=0,startDay=0,startDayOfWeek=0,startTime=0,startTimeMode=0,endMode=0,endMonth=0,endDay=0,endDayOfWeek=0,endTime=0,endTimeMode=0]\n",
      "Original data: Bug Title: AIX jdk8_openj9-0.26.0-m1 : javax/rmi/ssl/SSLSocketParametersTest.sh.SSLSocketParametersTest : java.rmi.NoSuchObjectException\n",
      "Bug Description: javax/rmi/ssl/SSLSocketParametersTest.sh.SSLSocketParametersTest\n",
      " openjdk version \"1.8.0_292\"\n",
      " OpenJDK Runtime Environment (build 1.8.0_292-202103091149-b05)\n",
      " Eclipse OpenJ9 VM (build openj9-0.26.0-m1, JRE 1.8.0 AIX ppc64-64-Bit Compressed References 20210309_991 (JIT enabled, AOT enabled)\n",
      " OpenJ9 - b227feba2\n",
      " OMR - 4665e2f72\n",
      " JCL - 1780cbc92b based on jdk8u292-b05)\n",
      " Launching test for SSLSocketParametersTest\n",
      " KeyStore = /home/jenkins/workspace/Test_openjdk8_j9_extended.openjdk_ppc64_aix/openjdk-tests/openjdk/openjdk-jdk/jdk/test/javax/rmi/ssl/keystore\n",
      " TrustStore = /home/jenkins/workspace/Test_openjdk8_j9_extended.openjdk_ppc64_aix/openjdk-tests/openjdk/openjdk-jdk/jdk/test/javax/rmi/ssl/truststore\n",
      " Running SSLSocketParametersTest [1]\n",
      " ServerFactory::Calling createServerSocket(0)\n",
      " Inside HelloImpl::runServer\n",
      " Stub = Proxy[SSLSocketParametersTest$Hello,RemoteObjectInvocationHandler[UnicastRef2 [liveRef: [endpoint:[140.211.9.28:44417,SSLSocketParametersTest$ServerFactory@3f98c7f7,SSLSocketParametersTest$ClientFactory@bb7579f1](local),objID:[-1a3aaedf:1781749f858:-7fff, 8154199408189112208]]]]]\n",
      " Inside HelloClient::runClient\n",
      " ClientFactory::Calling createSocket(140.211.9.28,44417)\n",
      " SSLSocketParametersTest [1] FAILED! Exception: java.rmi.NoSuchObjectException: no such object in table\n",
      " java.rmi.NoSuchObjectException: no such object in table\n",
      " at sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:303)\n",
      " at sun.rmi.transport.StreamRemoteCall.executeCall(StreamRemoteCall.java:279)\n",
      " at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:164)\n",
      " at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:235)\n",
      " at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:180)\n",
      " at com.sun.proxy.$Proxy0.sayHello(Unknown Source)\n",
      " at SSLSocketParametersTest$HelloClient.runClient(SSLSocketParametersTest.java:75)\n",
      " at SSLSocketParametersTest.runTest(SSLSocketParametersTest.java:137)\n",
      " at SSLSocketParametersTest.main(SSLSocketParametersTest.java:286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/438 [01:01<57:38,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: AIX jdk8_openj9-0.26.0-m1 : javax/rmi/ssl/SSLSocketParametersTest.sh.SSLSocketParametersTest : java.rmi.NoSuchObjectException\n",
      "Bug Description: javax/rmi/ssl/SSLSocketParametersTest.sh.SSLSocketParametersTest\n",
      " openjdk version \"1.8.0_292\"\n",
      " OpenJDK Runtime Environment (build 1.8.0_292-202103091149-b05)\n",
      " Eclipse OpenJ9 VM (build openj9-0.26.0-m1, JRE 1.8.0 AIX ppc64-64-Bit Compressed References 20210309_991 (JIT enabled, AOT enabled)\n",
      " OpenJ9 - b227feba2\n",
      " OMR - 4665e2f72\n",
      " JCL - 1780cbc92b based on jdk8u292-b05)\n",
      " Launching test for SSLSocketParametersTest\n",
      " KeyStore = /home/jenkins/workspace/Test_openjdk8_j9_extended.openjdk_ppc64_aix/openjdk-tests/openjdk/openjdk-jdk/jdk/test/javax/rmi/ssl/keystore\n",
      " TrustStore = /home/jenkins/workspace/Test_openjdk8_j9_extended.openjdk_ppc64_aix/openjdk-tests/openjdk/openjdk-jdk/jdk/test/javax/rmi/ssl/truststore\n",
      " Running SSLSocketParametersTest [1]\n",
      " ServerFactory::Calling createServerSocket(0)\n",
      " Inside HelloImpl::runServer\n",
      " Stub = Proxy[SSLSocketParametersTest$Hello,RemoteObjectInvocationHandler[UnicastRef2 [liveRef: [endpoint:[140.211.9.28:44417,SSLSocketParametersTest$ServerFactory@3f98c7f7,SSLSocketParametersTest$ClientFactory@bb7579f1](local),objID:[-1a3aaedf:1781749f858:-7fff, 8154199408189112208]]]]]\n",
      " Inside HelloClient::runClient\n",
      " ClientFactory::Calling createSocket(140.211.9.28,44417)\n",
      " SSLSocketParametersTest [1] FAILED! Exception: java.rmi.NoSuchObjectException: no such object in table\n",
      " java.rmi.NoSuchObjectException: no such object in table\n",
      " at sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:303)\n",
      " at sun.rmi.transport.StreamRemote\n",
      "Original data: Bug Title: cmdLineTest_J9tests cleanup\n",
      "Bug Description: Currently cmdLineTest_J9tests contains two files:\n",
      "[j9tests_Java8.xml](\n",
      "[j9tests_Java9.xml](\n",
      "Most content is duplicated with only a few different tests. We should maintain one file for shared tests and only create separate files for non-shared tests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/438 [01:03<44:44,  6.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: cmdLineTest_J9tests Refactoring\n",
      "Bug Description: At present, cmdLineTest_J9tests comprises two files:\n",
      "[j9tests_Java9_config.xml](\n",
      "[j9tests_Java8_config.xml](\n",
      "The majority of the content is redundant, with only a handful of distinct tests. It would be beneficial to preserve a single file for common tests and create separate files solely for non-common tests.\n",
      "Original data: Bug Title: Failure in JLM_Tests_interface_0/1 on z/OS 3.1\n",
      "Bug Description: There isn't a public link as there is no z/OS machines available on OpenJ9 jenkins for testing. Specifically this is the sub-test that fails. This is a brand new system setup undergoing validation, but I think this is a real failure...\n",
      "BUILDLIST=functional\n",
      "TARGET=`testList TESTLIST=JLM_Tests_interface_0,JLM_Tests_interface_1`\n",
      "MACHINE=fyrec21g.vmec.svl.ibm.com (there is currently only 1 operational for testing at 3.1)\n",
      "SDK under test was the latest 11.0.20 build for z/OS JDK11\n",
      "Failure output (captured from console output)\n",
      " [TestOperatingSystemMXBean] [INFO] Starting TestOperatingSystemMXBean tests ...\n",
      "scriptorAPIs\n",
      " FAILED: testGetAttributes\n",
      " java.lang.AssertionError: at org.testng.AssertJUnit.fail(AssertJUnit.java:59)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:24)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:33)\n",
      " at org.openj9.test.java.lang.management.TestOperatingSystemMXBean.testGetAttributes(TestOperatingSystemMXBean.java:464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/438 [01:10<46:44,  6.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Issue with JLM_Tests_interface_0/1 on z/OS 3.1\n",
      "Bug Description: Unfortunately, there isn't a publicly accessible link available as no z/OS machines are currently available on the OpenJ9 Jenkins for testing purposes. Specifically, this is the sub-test that encounters an error. This is a brand new system setup undergoing validation, but I believe this is a genuine issue...\n",
      "BUILDLIST=functional\n",
      "TARGET=`testList TESTLIST=JLM_Tests_interface_0,JLM_Tests_interface_1`\n",
      "MACHINE=fyrec21g.vmec.svl.ibm.com (there is currently only 1 operational machine available for testing at 3.1)\n",
      "SDK under test was the latest 11.0.20 build for z/OS JDK11\n",
      "Failure output (captured from console output)\n",
      " [TestOperatingSystemMXBean] [INFO] Starting TestOperatingSystemMXBean tests...\n",
      "scriptorAPIs\n",
      " FAILED: testGetAttributes\n",
      " java.lang.AssertionError: at org.testng.AssertJUnit.fail(AssertJUnit.java:59)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:24)\n",
      " at org.testng.AssertJUnit.assertTrue(AssertJUnit.java:33)\n",
      " at org.openj9.test.java.lang.management.TestOperatingSystemMXBean.testGetAttributes(TestOperatingSystemMXBean.java:464)\n",
      "Original data: Bug Title: jdk22 MathLoadTest_bigdecimal OutOfMemoryError: too large to fit in a String\n",
      "Bug Description: MathLoadTest_bigdecimal_5m_1\n",
      "MLT testFailure: testItem_0460(net.adoptopenjdk.test.bigdecimal.TestSuite019): too large to fit in a String\n",
      "MLT java.lang.OutOfMemoryError: too large to fit in a String\n",
      "MLT at java.base/java.math.BigDecimal.getValueString(BigDecimal.java:3542)\n",
      "MLT at java.base/java.math.BigDecimal.toPlainString(BigDecimal.java:3524)\n",
      "MLT at net.adoptopenjdk.test.bigdecimal.TestSuite019.testItem_0460(TestSuite019.java:3188)\n",
      "MathLoadTest_bigdecimal_CS_5m_0\n",
      "MLT testFailure: testItem_0587(net.adoptopenjdk.test.bigdecimal.TestSuite029): too large to fit in a String\n",
      "MLT java.lang.OutOfMemoryError: too large to fit in a String\n",
      "MLT at java.base/java.math.BigDecimal.getValueString(BigDecimal.java:3542)\n",
      "MLT at java.base/java.math.BigDecimal.toPlainString(BigDecimal.java:3524)\n",
      "MLT at net.adoptopenjdk.test.bigdecimal.TestSuite029.testItem_0587(TestSuite029.java:4145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/438 [01:17<46:27,  6.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: jdk22 MathLoadTest_bigdecimal OutOfMemoryError: exceeds maximum string capacity\n",
      "Bug Description: MathLoadTest_bigdecimal_5m_1\n",
      "MLT testFailure: testItem_0460(net.adoptopenjdk.test.bigdecimal.TestSuite019): exceeds maximum string capacity\n",
      "MLT java.lang.OutOfMemoryError: exceeds maximum string capacity\n",
      "MLT at java.base/java.math.BigDecimal.getValueString(BigDecimal.java:3542)\n",
      "MLT at java.base/java.math.BigDecimal.toPlainString(BigDecimal.java:3524)\n",
      "MLT at net.adoptopenjdk.test.bigdecimal.TestSuite019.testItem_0460(TestSuite019.java:3188)\n",
      "MathLoadTest_bigdecimal_CS_5m_0\n",
      "MLT testFailure: testItem_0587(net.adoptopenjdk.test.bigdecimal.TestSuite029): exceeds maximum string capacity\n",
      "MLT java.lang.OutOfMemoryError: exceeds maximum string capacity\n",
      "MLT at java.base/java.math.BigDecimal.getValueString(BigDecimal.java:3542)\n",
      "MLT at java.base/java.math.BigDecimal.toPlainString(BigDecimal.java:3524)\n",
      "MLT at net.adoptopenjdk.test.bigdecimal.TestSuite029.testItem_0587(TestSuite029.java:4145)\n",
      "Original data: Bug Title: sanity.openjdk Windows Access is denied\n",
      "Bug Description: Execution failed: `main' threw exception: java.io.IOException: Access is denied. Execution failed: `main' threw exception: java.nio.file.AccessDeniedException: C:\\Windows\\7939526392057814672.tmp Execution failed: `main' threw exception: j7ava.nio.file.AccessDeniedException: C:\\Windows\\1406889845721675710.tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/438 [01:19<37:13,  5.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: sanity.openjdk Windows Permission Denied\n",
      "Bug Description: Execution failed: `main' threw exception: java.io.IOException: Permission Denied. Execution failed: `main' threw exception: java.nio.file.PermissionDeniedException: C:\\Windows\\12345678901234567890.tmp Execution failed: `main' threw exception: java.nio.file.PermissionDeniedException: C:\\Windows\\9876543210987654321.tmp\n",
      "Original data: Bug Title: Class.getMethods test is missing\n",
      "Bug Description: Class.getMethods are not invoked by sanity tests. org.openj9.test.reflect.GetMethodsTests has been implemented. Looks like just a missing line ` <class name=\"org.openj9.test.reflect.GetMethodsTests\" /> ` in file test/functional/Java8andUp/testng.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/438 [01:21<30:12,  4.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Class.getMethods assessment is incomplete\n",
      "Bug Description: Class.getMethods are not triggered by verification tests. org.openj9.test.reflect.GetMethodsAssessment has been developed. Appears to be just a missing line `<class name=\"org.openj9.test.reflect.GetMethodsAssessment\" />` in file test/functional/Java8andUp/testng.xml\n",
      "Original data: Bug Title: OpenSSL testing to confirm OpenSSL natives are being loaded\n",
      "Bug Description: As per OpenSSL support may be silently failing. There should be a test, likely using the `-Djdk.nativeCryptoTrace=true` option, to confirm the natives are being loaded as expected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/438 [01:23<24:30,  3.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data: Bug Report: Bug Title: Verifying OpenSSL Natives for Native Crypto Loading\n",
      "Bug Description: According to OpenSSL documentation, silent failures may occur. To ensure native loading, a test is required, possibly utilizing the `-Djdk.nativeCryptoTrace=true` flag, to verify the natives are being loaded as intended.\n",
      "Original data: Bug Title: ValueTypes: java.lang.VerifyError in ValueTypeTests_1  testFlatLayoutsWithRecursiveLongs\n",
      "Bug Description: After removing `<class name=\"org.openj9.test.lworld.ValueTypeArrayTests\"/>` from `testng.xml`, I'm able to run more Valhalla functional tests. The reason that it has to be removed in order to run more tests is tracked in `testFlatLayoutsWithRecursiveLongs` in `ValueTypeTests_1` failed due to `\"java.lang.VerifyError: JVMVRFY021 thrown object not throwable; class=QuadLong, method=withl(QDoubleLong;)QQuadLong;, pc=2\"`\n",
      "1:28:13 Eclipse OpenJ9 VM (build test-fix-field-offset-flattened-arrayelement-bb482f0ec7b, JRE 20 Linux amd64-64-Bit Compressed References 20221108_261 (JIT enabled, AOT enabled)\n",
      " OpenJ9 - bb482f0ec7b\n",
      " OMR - 1c49c4a411f\n",
      " JCL - 44115f48aff based on jdk-20+19)\n",
      "FAILED: testFlatLayoutsWithRecursiveLongs\n",
      "java.lang.VerifyError: JVMVRFY021 thrown object not throwable; class=QuadLong, method=withl(QDoubleLong;)QQuadLong;, pc=2\n",
      "Exception Details:\n",
      " Location:\n",
      " QuadLong.withl(QDoubleLong;)QQuadLong; @2: JBwithfield\n",
      " Reason:\n",
      " Type null (current frame, stack[1]) is not assignable to 'QuadLong'\n",
      " Current Frame:\n",
      " bci: @2\n",
      " flags: { }\n",
      " locals: { 'QuadLong', 'QDoubleLong;' }\n",
      " stack: { 'QuadLong', null }\n",
      " at java.base/jdk.internal.misc.Unsafe.ensureClassInitialized0(Native Method)\n",
      " at java.base/jdk.internal.misc.Unsafe.ensureClassInitialized(Unsafe.java:1525)\n",
      " at java.base/java.lang.invoke.DirectMethodHandle.checkInitialized(DirectMethodHandle.java:387)\n",
      " at java.base/java.lang.invoke.DirectMethodHandle.ensureInitialized(DirectMethodHandle.java:375)\n",
      " at java.base/java.lang.invoke.DirectMethodHandle.internalMemberNameEnsureInit(DirectMethodHandle.java:340)\n",
      " at org.openj9.test.lworld.ValueTypeTests.testFlatLayoutsWithRecursiveLongs(ValueTypeTests.java:1725)\n",
      " at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\n",
      " at java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      " at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)\n",
      " at org.testng.internal.Invoker.invokeMethod(Invoker.java:580)\n",
      " at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:716)\n",
      " at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:988)\n",
      " at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)\n",
      " at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)\n",
      " at org.testng.TestRunner.privateRun(TestRunner.java:648)\n",
      " at org.testng.TestRunner.run(TestRunner.java:505)\n",
      " at org.testng.SuiteRunner.runTest(SuiteRunner.java:455)\n",
      " at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)\n",
      " at org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)\n",
      " at org.testng.SuiteRunner.run(SuiteRunner.java:364)\n",
      " at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\n",
      " at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)\n",
      " at org.testng.TestNG.runSuitesSequentially(TestNG.java:1208)\n",
      " at org.testng.TestNG.runSuitesLocally(TestNG.java:1137)\n",
      " at org.testng.TestNG.runSuites(TestNG.java:1049)\n",
      " at org.testng.TestNG.run(TestNG.java:1017)\n",
      " at org.testng.TestNG.privateMain(TestNG.java:1354)\n",
      " at org.testng.TestNG.main(TestNG.java:1323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/438 [01:28<41:34,  5.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m bug_report \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m \u001b[43mllama3_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSYSTEM_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBug Report: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbug_report\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m augmented_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     19\u001b[0m augmented_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m augmented_text\n",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m, in \u001b[0;36mLlama3.invoke\u001b[0;34m(self, system_prompt, question, temperature, return_token_usage)\u001b[0m\n\u001b[1;32m     23\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     24\u001b[0m     messages,\n\u001b[1;32m     25\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     31\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     34\u001b[0m ]\n\u001b[0;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m response \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] :]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_token_usage:\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/generation/utils.py:1764\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1757\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1758\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1759\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1761\u001b[0m     )\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1781\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1782\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1788\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/generation/utils.py:2861\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1181\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1178\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1068\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1059\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1060\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         use_cache,\n\u001b[1;32m   1066\u001b[0m     )\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1068\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:796\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:704\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    701\u001b[0m     kv_seq_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mget_usable_length(kv_seq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx)\n\u001b[1;32m    702\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, seq_len\u001b[38;5;241m=\u001b[39mkv_seq_len)\n\u001b[0;32m--> 704\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos}  \u001b[38;5;66;03m# Specific to RoPE models\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:235\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    233\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    234\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 235\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:208\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    206\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    207\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "augmented_rows = []\n",
    "\n",
    "for component, num_components in df[\"component\"].value_counts().items():\n",
    "    if num_components < 1000:\n",
    "        print(f\"Augmenting data for component: {component}\")\n",
    "        augmentation_needed = 1000 - num_components\n",
    "\n",
    "        # Filter rows for the current component\n",
    "        original_data = df[df[\"component\"] == component]\n",
    "\n",
    "        # Augment data by sampling with replacement\n",
    "        for _ in tqdm(range(augmentation_needed), total=augmentation_needed):\n",
    "            # Sample one row randomly from the original_data\n",
    "            row = original_data.sample(n=1, replace=True).iloc[0]\n",
    "            print(\"Original data:\", row[\"text\"])\n",
    "            bug_report = row[\"text\"]\n",
    "            augmented_text = llama3_model.invoke(system_prompt=SYSTEM_PROMPT, question=f\"Bug Report: {bug_report}\")\n",
    "            augmented_row = row.copy()\n",
    "            augmented_row[\"text\"] = augmented_text\n",
    "            print(\"Augmented data:\", augmented_text)\n",
    "\n",
    "            augmented_rows.append(augmented_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  1%|▏         | 1/67 [00:37<41:12, 37.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  3%|▎         | 2/67 [00:43<20:17, 18.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  4%|▍         | 3/67 [01:17<27:37, 25.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  6%|▌         | 4/67 [01:43<27:03, 25.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  7%|▋         | 5/67 [02:20<31:05, 30.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "  9%|▉         | 6/67 [02:30<23:33, 23.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 10%|█         | 7/67 [03:07<27:40, 27.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 12%|█▏        | 8/67 [03:13<20:27, 20.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 13%|█▎        | 9/67 [03:37<21:11, 21.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 15%|█▍        | 10/67 [04:16<25:33, 26.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 16%|█▋        | 11/67 [04:38<23:49, 25.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 18%|█▊        | 12/67 [04:52<20:13, 22.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 19%|█▉        | 13/67 [05:02<16:32, 18.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 21%|██        | 14/67 [05:06<12:18, 13.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 22%|██▏       | 15/67 [05:08<09:07, 10.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 24%|██▍       | 16/67 [05:13<07:32,  8.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 25%|██▌       | 17/67 [05:51<14:29, 17.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 27%|██▋       | 18/67 [06:28<19:06, 23.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 28%|██▊       | 19/67 [07:05<22:05, 27.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 30%|██▉       | 20/67 [07:14<17:13, 21.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 31%|███▏      | 21/67 [07:35<16:29, 21.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 33%|███▎      | 22/67 [07:42<12:52, 17.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 34%|███▍      | 23/67 [08:19<16:59, 23.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 36%|███▌      | 24/67 [08:37<15:28, 21.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 37%|███▋      | 25/67 [09:18<19:16, 27.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 39%|███▉      | 26/67 [09:56<20:56, 30.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 40%|████      | 27/67 [10:36<22:22, 33.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 42%|████▏     | 28/67 [10:59<19:45, 30.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 43%|████▎     | 29/67 [11:37<20:40, 32.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 45%|████▍     | 30/67 [12:14<20:58, 34.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 46%|████▋     | 31/67 [12:51<20:56, 34.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 48%|████▊     | 32/67 [13:29<20:45, 35.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 49%|████▉     | 33/67 [13:34<15:02, 26.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 51%|█████     | 34/67 [13:57<13:56, 25.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 52%|█████▏    | 35/67 [14:35<15:31, 29.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 54%|█████▎    | 36/67 [15:13<16:27, 31.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 55%|█████▌    | 37/67 [15:38<14:59, 29.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 57%|█████▋    | 38/67 [16:11<14:55, 30.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 58%|█████▊    | 39/67 [16:50<15:31, 33.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 60%|█████▉    | 40/67 [17:28<15:36, 34.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 61%|██████    | 41/67 [18:05<15:21, 35.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 63%|██████▎   | 42/67 [18:12<11:12, 26.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 64%|██████▍   | 43/67 [18:50<12:01, 30.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 66%|██████▌   | 44/67 [19:10<10:21, 27.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 67%|██████▋   | 45/67 [19:50<11:21, 30.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 69%|██████▊   | 46/67 [20:29<11:38, 33.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 70%|███████   | 47/67 [21:06<11:31, 34.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 72%|███████▏  | 48/67 [21:13<08:16, 26.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 73%|███████▎  | 49/67 [21:54<09:12, 30.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 75%|███████▍  | 50/67 [22:32<09:17, 32.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 76%|███████▌  | 51/67 [22:39<06:44, 25.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 78%|███████▊  | 52/67 [23:18<07:17, 29.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 79%|███████▉  | 53/67 [23:21<05:01, 21.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 81%|████████  | 54/67 [23:23<03:22, 15.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 82%|████████▏ | 55/67 [23:28<02:28, 12.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 84%|████████▎ | 56/67 [24:05<03:38, 19.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 85%|████████▌ | 57/67 [24:25<03:18, 19.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 87%|████████▋ | 58/67 [25:03<03:46, 25.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 88%|████████▊ | 59/67 [25:40<03:50, 28.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 90%|████████▉ | 60/67 [26:18<03:40, 31.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 91%|█████████ | 61/67 [26:51<03:12, 32.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 93%|█████████▎| 62/67 [27:29<02:48, 33.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 94%|█████████▍| 63/67 [27:52<02:02, 30.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 96%|█████████▌| 64/67 [28:30<01:37, 32.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 97%|█████████▋| 65/67 [29:08<01:08, 34.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      " 99%|█████████▊| 66/67 [29:19<00:27, 27.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "100%|██████████| 67/67 [29:57<00:00, 26.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n",
    "    bug_report = row[\"text\"]\n",
    "    augmented_text = llama3_model.invoke(system_prompt=SYSTEM_PROMPT, question=f\"Bug Report: {bug_report}\")\n",
    "    augmented_row = row.copy()\n",
    "    augmented_row[\"text\"] = augmented_text\n",
    "\n",
    "    augmented_rows.append(augmented_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                   6815\n",
       "issue_number                                                16970\n",
       "issue_title     JDK20  jdk_nio_0_FAILED UnsupportedOperationEx...\n",
       "description     Failure link\\nFrom [an internal build](\\n open...\n",
       "issue_url       https://github.com/eclipse-openj9/openj9/issue...\n",
       "issue_state                                                closed\n",
       "creator                                               JasonFengJ9\n",
       "labels            test failure, os:aix, comp:jclextensions, jdk20\n",
       "owner                                                backwaterred\n",
       "component                                      comp:jclextensions\n",
       "text            Bug Report: Bug Title: JDK20  jdk_nio_0_FAILED...\n",
       "Name: 4968, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_rows[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.DataFrame(augmented_rows)\n",
    "result_df = pd.concat([df, augmented_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bug Title: Verifying OpenSSL Natives for Native Crypto Loading\\nBug Description: According to OpenSSL documentation, silent failures may occur. To ensure native loading, a test is required, possibly utilizing the `-Djdk.nativeCryptoTrace=true` flag, to verify the natives are being loaded as intended.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component\n",
       "comp:vm               1698\n",
       "comp:jit              1354\n",
       "comp:test              562\n",
       "comp:build             378\n",
       "comp:jitserver         373\n",
       "comp:infra             329\n",
       "comp:gc                243\n",
       "comp:jclextensions     180\n",
       "comp:jvmti              88\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.component.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"comp_train_augmented_3x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                   8217\n",
       "issue_number                                                20324\n",
       "issue_title     On AIX using zlibNX may cause ClassNotFoundExc...\n",
       "description     Experienced the following problem on AIX 7.3 P...\n",
       "issue_url       https://github.com/eclipse-openj9/openj9/issue...\n",
       "issue_state                                                  open\n",
       "creator                                                  pshipton\n",
       "labels                                 os:aix, comp:jclextensions\n",
       "owner                                                     r30shah\n",
       "component                                      comp:jclextensions\n",
       "text            Bug Report: Bug Title: On AIX utilizing zlibNX...\n",
       "Name: 5066, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.iloc[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
