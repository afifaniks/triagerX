{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from loguru import logger\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, PreTrainedTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_split(x):\n",
    "    x_split = str(x).split(\",\")\n",
    "\n",
    "    for s in x_split:\n",
    "        if \"comp:\" in s.lower():\n",
    "            return s.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18278\n",
      "All issues: 16342\n",
      "Excluding pull: 6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [00:00<00:00, 84917.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues: 6990\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/openj9/openj9_topic_all_issues.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(len(df))\n",
    "df = df.rename(columns={\"assignees\": \"owner\", \"issue_body\": \"description\"})\n",
    "# df = df[df[\"owner\"].notna()]\n",
    "\n",
    "def clean_data(df):\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df[\"labels\"].notna()]\n",
    "    print(f\"All issues: {len(df)}\")\n",
    "    df = df[~df[\"issue_url\"].str.contains(\"/pull/\")]\n",
    "    print(f\"Excluding pull: {len(df)}\")\n",
    "    df[\"component\"] = df[\"labels\"].apply(component_split)\n",
    "    \n",
    "    df[\"text\"] = df.progress_apply(\n",
    "            lambda x: \"Title: \"\n",
    "            + str(x[\"issue_title\"])\n",
    "            # + \"\\nIssue Labels: \"\n",
    "            # + str(x[\"labels\"])\n",
    "            + \"\\nIssue Topic: \"\n",
    "            + str(x[\"topic_label\"])\n",
    "            + \"\\nDescription: \"\n",
    "            + str(x[\"description\"]),\n",
    "            axis=1,\n",
    "        )\n",
    "    \n",
    "    min_length = 15\n",
    "    df = df[df[\"text\"].str.len().gt(min_length)]\n",
    "\n",
    "    # df[\"owner_id\"] = pd.factorize(df[\"assignees\"])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_dataframe(df)\n",
    "df = clean_data(df)\n",
    "df = df.sort_values(by=\"issue_number\")\n",
    "\n",
    "num_issues = len(df)\n",
    "\n",
    "print(f\"Total number of issues: {num_issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_hot\"] = pd.get_dummies(df[\"topic_id\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df[\"component\"].values:\n",
    "    if val is None:\n",
    "        continue\n",
    "    \n",
    "    split = val.split(\",\")\n",
    "    \n",
    "    for s in split:\n",
    "        components.add(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_values = df[\"component\"].value_counts()\n",
    "filtered_components = component_values.index[component_values >= 20]\n",
    "\n",
    "df = df[df[\"component\"].isin(filtered_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_component(source_df, train_size=0.8):\n",
    "    grouped = source_df.groupby('component')\n",
    "\n",
    "    # Initialize two empty lists to store the split datasets\n",
    "    dataset_1 = []\n",
    "    dataset_2 = []\n",
    "\n",
    "    # Iterate over each group\n",
    "    for _, group_df in grouped:\n",
    "        # Split the group into two halves\n",
    "        first_idx = int(len(group_df) * train_size)\n",
    "        group_half_1 = group_df.iloc[:first_idx]\n",
    "        group_half_2 = group_df.iloc[first_idx:]\n",
    "        \n",
    "        # Append each half to the respective dataset\n",
    "        dataset_1.append(group_half_1)\n",
    "        dataset_2.append(group_half_2)\n",
    "\n",
    "    return pd.concat(dataset_1, ignore_index=True), pd.concat(dataset_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"issue_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655 296\n"
     ]
    }
   ],
   "source": [
    "components = [\"comp:vm\", \"comp:jvmti\", \"comp:jclextensions\", \"comp:test\", \"comp:build\", \"comp:gc\"]\n",
    "filtered_df = df[df[\"component\"].isin(components)]\n",
    "\n",
    "# Splitting parition by size\n",
    "total_data = len(filtered_df)\n",
    "train_size = int(total_data*0.9)\n",
    "test_size = total_data - train_size\n",
    "df_train = filtered_df[:train_size]\n",
    "df_test = filtered_df[train_size:]\n",
    "\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component\n",
       "comp:vm               1509\n",
       "comp:test              509\n",
       "comp:build             391\n",
       "comp:gc                201\n",
       "comp:jclextensions      30\n",
       "comp:jvmti              15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.component.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component\n",
       "comp:vm               186\n",
       "comp:test              46\n",
       "comp:gc                33\n",
       "comp:build             13\n",
       "comp:jclextensions     11\n",
       "comp:jvmti              7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.component.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_train.component.unique()) == set(df_test.component.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_639804/3718604143.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"component_id\"] = [label2idx[component] for component in df_train[\"component\"].values]\n",
      "/tmp/ipykernel_639804/3718604143.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"component_id\"] = [label2idx[component] for component in df_test[\"component\"].values]\n"
     ]
    }
   ],
   "source": [
    "# Generate component ids\n",
    "label2idx = {label: idx for idx, label in enumerate(list(df_train[\"component\"].unique()))}\n",
    "df_train[\"component_id\"] = [label2idx[component] for component in df_train[\"component\"].values]\n",
    "df_test[\"component_id\"] = [label2idx[component] for component in df_test[\"component\"].values]\n",
    "\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size 2124 531 296\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size\", len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.component.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        feature: str = \"text\",\n",
    "        target: str = \"component_id\",\n",
    "    ):\n",
    "        logger.debug(\"Generating torch dataset...\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = [label for label in df[target]]\n",
    "        # self.embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "        logger.debug(\"Tokenizing texts...\")\n",
    "        self.texts = [\n",
    "            (row[feature], self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ), torch.tensor(row.topic_hot))\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBTPClassifierTopic(nn.Module):\n",
    "    def __init__(\n",
    "        self, output_size, topic_size, unfrozen_layers=4, embed_size=1024, dropout=0.1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        model_name = \"microsoft/deberta-large\"\n",
    "        self.base_model = AutoModel.from_pretrained(\n",
    "            model_name, output_hidden_states=True\n",
    "        )\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Freeze embedding layers\n",
    "        for p in self.base_model.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Freeze encoder layers till last {unfrozen_layers} layers\n",
    "        for i in range(0, self.base_model.config.num_hidden_layers - unfrozen_layers):\n",
    "            for p in self.base_model.encoder.layer[i].parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        filter_sizes = [3, 4, 5, 6]\n",
    "        self._num_filters = 256\n",
    "        self._max_tokens = 512\n",
    "        self._embed_size = embed_size\n",
    "        self.unfrozen_layers = unfrozen_layers\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv2d(1, self._num_filters, (K, embed_size)),\n",
    "                            nn.BatchNorm2d(self._num_filters),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Flatten(),\n",
    "                            nn.MaxPool1d(self._max_tokens - (K - 1)),\n",
    "                            nn.Flatten(start_dim=1),\n",
    "                        )\n",
    "                        for K in filter_sizes\n",
    "                    ]\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifiers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(\n",
    "                    len(filter_sizes) * self._num_filters + topic_size, output_size\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tok_type, topic_id):\n",
    "        outputs = []\n",
    "\n",
    "        base_out = self.base_model(input_ids=input_ids, token_type_ids=tok_type, attention_mask=attention_mask)\n",
    "        # pooler_out = base_out.last_hidden_state.squeeze(0)\n",
    "        hidden_states = base_out.hidden_states[-self.unfrozen_layers :]\n",
    "\n",
    "        for i in range(self.unfrozen_layers):\n",
    "            batch_size, sequence_length, hidden_size = hidden_states[i].size()\n",
    "            x = [\n",
    "                conv(hidden_states[i].view(batch_size, 1, sequence_length, hidden_size))\n",
    "                for conv in self.conv_blocks[i]\n",
    "            ]\n",
    "            # Concatanating outputs of the conv block of different filter sizes\n",
    "            x = torch.cat(x, dim=1)\n",
    "            x = self.dropout(x)\n",
    "            x = torch.cat([x, topic_id], dim=1)\n",
    "            x = self.classifiers[i](x)\n",
    "\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def tokenizer(self) -> AutoTokenizer:\n",
    "        return self._tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self, weights = None) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = nn.CrossEntropyLoss(weight=weights)\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_test.component.unique()) == set(df_val.component.unique()) == set(df_train.component.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df_train[\"component\"].unique())\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.bincount(df_train[\"component_id\"])\n",
    "num_samples = sum(class_counts)\n",
    "labels = df_train[\"component_id\"].to_list() # corresponding labels of samples\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "# weights_load_location = f\"/work/disa_lab/projects/triagerx/models/deberta_component_prediction.pt\"\n",
    "weights_save_location = f\"/work/disa_lab/projects/triagerx/models/deberta_component_prediction_chrono_10class.pt\"\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 1e-5\n",
    "epochs = 25\n",
    "batch_size = 10\n",
    "\n",
    "model = LBTPClassifierTopic(len(df_train.component_id.unique()), topic_size=20, unfrozen_layers=4, dropout=0.2)\n",
    "# Load best checkpoint\n",
    "# model.load_state_dict(torch.load(weights_load_location))\n",
    "criterion = CombineLoss(weights=None)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8, weight_decay=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=2, factor=0.1, threshold=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 14:47:54.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-04-21 14:47:54.555\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n",
      "\u001b[32m2024-04-21 14:47:58.575\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-04-21 14:47:58.578\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare torch dataset from train and validation splits\n",
    "train = TriageDataset(df_train, model.tokenizer())\n",
    "val = TriageDataset(df_val, model.tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mafifaniks\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mdafifal.mamun/notebooks/triagerX/wandb/run-20240421_144802-6q51lzsv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/afifaniks/openj9/runs/6q51lzsv' target=\"_blank\">component_prediction_chrono_order_6_classes</a></strong> to <a href='https://wandb.ai/afifaniks/openj9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/afifaniks/openj9' target=\"_blank\">https://wandb.ai/afifaniks/openj9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/afifaniks/openj9/runs/6q51lzsv' target=\"_blank\">https://wandb.ai/afifaniks/openj9/runs/6q51lzsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/afifaniks/openj9/runs/6q51lzsv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd123e789d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"openj9\", \n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=f\"component_prediction_chrono_order_{num_classes}_classes\", \n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"Deberta-LBT-P\",\n",
    "    \"dataset\": \"openj9\",\n",
    "    \"epochs\": epochs,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False if sampler else True,\n",
    "    sampler=sampler,\n",
    ")\n",
    "val_dataloader = DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 14:48:17.786\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mSelected compute device: cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.debug(f\"Selected compute device: {device}\")\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        topk,\n",
    "    ):\n",
    "        log = f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                    | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                    | Val Loss: {total_loss_val / len(validation_data): .3f} \\\n",
    "                    | Val Accuracy: {total_acc_val / len(validation_data): .3f} \\\n",
    "                    | Top 3: {topk} \\\n",
    "                    | Precision: {precision: .3f} \\\n",
    "                    | Recall: {recall: .3f} \\\n",
    "                    | F1-score: {f1_score: .3f}\"\n",
    "\n",
    "        logger.info(log)\n",
    "        wandb.log({\n",
    "            \"train_acc\": total_acc_train / len(train_data), \n",
    "            \"train_loss\": total_loss_train / len(train_data),\n",
    "            \"val_acc\": total_acc_val / len(validation_data),\n",
    "            \"val_loss\": total_loss_val / len(validation_data),\n",
    "            \"top3_acc\": topk,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1-score\": f1_score\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps: 100%|██████████| 213/213 [03:16<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.63it/s]\n",
      "\u001b[32m2024-04-21 14:52:00.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 1 | Train Loss:  0.509                     | Train Accuracy:  0.639                     | Val Loss:  0.515                     | Val Accuracy:  0.621                     | Top 3: 0.9416195856873822                     | Precision:  0.414                     | Recall:  0.536                     | F1-score:  0.452\u001b[0m\n",
      "\u001b[32m2024-04-21 14:52:00.781\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.64it/s]\n",
      "\u001b[32m2024-04-21 14:55:40.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 2 | Train Loss:  0.239                     | Train Accuracy:  0.872                     | Val Loss:  0.458                     | Val Accuracy:  0.669                     | Top 3: 0.9585687382297552                     | Precision:  0.554                     | Recall:  0.662                     | F1-score:  0.552\u001b[0m\n",
      "\u001b[32m2024-04-21 14:55:40.951\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "\u001b[32m2024-04-21 14:59:20.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 3 | Train Loss:  0.162                     | Train Accuracy:  0.913                     | Val Loss:  0.396                     | Val Accuracy:  0.714                     | Top 3: 0.9811676082862524                     | Precision:  0.529                     | Recall:  0.667                     | F1-score:  0.574\u001b[0m\n",
      "\u001b[32m2024-04-21 14:59:20.820\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:03:01.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 4 | Train Loss:  0.129                     | Train Accuracy:  0.926                     | Val Loss:  0.370                     | Val Accuracy:  0.725                     | Top 3: 0.9849340866290018                     | Precision:  0.564                     | Recall:  0.653                     | F1-score:  0.598\u001b[0m\n",
      "\u001b[32m2024-04-21 15:03:01.318\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:06:41.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 5 | Train Loss:  0.091                     | Train Accuracy:  0.959                     | Val Loss:  0.364                     | Val Accuracy:  0.729                     | Top 3: 0.9868173258003766                     | Precision:  0.605                     | Recall:  0.668                     | F1-score:  0.625\u001b[0m\n",
      "\u001b[32m2024-04-21 15:06:41.492\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:10:21.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 6 | Train Loss:  0.076                     | Train Accuracy:  0.967                     | Val Loss:  0.331                     | Val Accuracy:  0.751                     | Top 3: 0.9905838041431262                     | Precision:  0.574                     | Recall:  0.630                     | F1-score:  0.596\u001b[0m\n",
      "\u001b[32m2024-04-21 15:10:21.365\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "\u001b[32m2024-04-21 15:14:00.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 7 | Train Loss:  0.059                     | Train Accuracy:  0.977                     | Val Loss:  0.328                     | Val Accuracy:  0.757                     | Top 3: 0.9792843691148776                     | Precision:  0.789                     | Recall:  0.681                     | F1-score:  0.671\u001b[0m\n",
      "\u001b[32m2024-04-21 15:14:00.998\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:14<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:17:40.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 8 | Train Loss:  0.052                     | Train Accuracy:  0.983                     | Val Loss:  0.311                     | Val Accuracy:  0.780                     | Top 3: 0.9849340866290018                     | Precision:  0.640                     | Recall:  0.614                     | F1-score:  0.624\u001b[0m\n",
      "\u001b[32m2024-04-21 15:17:40.606\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:21:20.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 9 | Train Loss:  0.044                     | Train Accuracy:  0.985                     | Val Loss:  0.312                     | Val Accuracy:  0.778                     | Top 3: 0.9905838041431262                     | Precision:  0.644                     | Recall:  0.681                     | F1-score:  0.657\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:24:56.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 10 | Train Loss:  0.035                     | Train Accuracy:  0.989                     | Val Loss:  0.310                     | Val Accuracy:  0.778                     | Top 3: 0.9887005649717514                     | Precision:  0.638                     | Recall:  0.659                     | F1-score:  0.646\u001b[0m\n",
      "\u001b[32m2024-04-21 15:24:56.147\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "\u001b[32m2024-04-21 15:28:36.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 11 | Train Loss:  0.030                     | Train Accuracy:  0.990                     | Val Loss:  0.322                     | Val Accuracy:  0.772                     | Top 3: 0.9849340866290018                     | Precision:  0.801                     | Recall:  0.654                     | F1-score:  0.660\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:32:11.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 12 | Train Loss:  0.025                     | Train Accuracy:  0.992                     | Val Loss:  0.319                     | Val Accuracy:  0.751                     | Top 3: 0.9887005649717514                     | Precision:  0.619                     | Recall:  0.655                     | F1-score:  0.634\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:35:47.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 13 | Train Loss:  0.024                     | Train Accuracy:  0.994                     | Val Loss:  0.326                     | Val Accuracy:  0.776                     | Top 3: 0.9830508474576272                     | Precision:  0.645                     | Recall:  0.683                     | F1-score:  0.660\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:39:22.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 14 | Train Loss:  0.020                     | Train Accuracy:  0.997                     | Val Loss:  0.318                     | Val Accuracy:  0.763                     | Top 3: 0.9943502824858758                     | Precision:  0.632                     | Recall:  0.662                     | F1-score:  0.644\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:42:58.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 15 | Train Loss:  0.017                     | Train Accuracy:  0.998                     | Val Loss:  0.320                     | Val Accuracy:  0.766                     | Top 3: 0.9905838041431262                     | Precision:  0.635                     | Recall:  0.663                     | F1-score:  0.646\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:46:34.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 16 | Train Loss:  0.020                     | Train Accuracy:  0.997                     | Val Loss:  0.299                     | Val Accuracy:  0.791                     | Top 3: 0.9905838041431262                     | Precision:  0.654                     | Recall:  0.595                     | F1-score:  0.610\u001b[0m\n",
      "\u001b[32m2024-04-21 15:46:34.060\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m103\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "\u001b[32m2024-04-21 15:50:14.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 17 | Train Loss:  0.018                     | Train Accuracy:  0.998                     | Val Loss:  0.309                     | Val Accuracy:  0.780                     | Top 3: 0.9868173258003766                     | Precision:  0.806                     | Recall:  0.674                     | F1-score:  0.678\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:53:49.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 18 | Train Loss:  0.018                     | Train Accuracy:  0.997                     | Val Loss:  0.310                     | Val Accuracy:  0.778                     | Top 3: 0.9868173258003766                     | Precision:  0.641                     | Recall:  0.668                     | F1-score:  0.652\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 15:57:25.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 19 | Train Loss:  0.016                     | Train Accuracy:  0.999                     | Val Loss:  0.304                     | Val Accuracy:  0.780                     | Top 3: 0.9887005649717514                     | Precision:  0.652                     | Recall:  0.620                     | F1-score:  0.630\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 16:01:00.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 20 | Train Loss:  0.016                     | Train Accuracy:  0.999                     | Val Loss:  0.302                     | Val Accuracy:  0.780                     | Top 3: 0.9905838041431262                     | Precision:  0.646                     | Recall:  0.666                     | F1-score:  0.654\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "\u001b[32m2024-04-21 16:04:36.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 21 | Train Loss:  0.014                     | Train Accuracy:  0.999                     | Val Loss:  0.302                     | Val Accuracy:  0.791                     | Top 3: 0.992467043314501                     | Precision:  0.825                     | Recall:  0.693                     | F1-score:  0.698\u001b[0m\n",
      "Training Steps: 100%|██████████| 213/213 [03:15<00:00,  1.09it/s]\n",
      "Validation Steps: 100%|██████████| 54/54 [00:20<00:00,  2.65it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-04-21 16:08:11.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 22 | Train Loss:  0.017                     | Train Accuracy:  0.997                     | Val Loss:  0.306                     | Val Accuracy:  0.780                     | Top 3: 0.9887005649717514                     | Precision:  0.653                     | Recall:  0.620                     | F1-score:  0.631\u001b[0m\n",
      "\u001b[32m2024-04-21 16:08:11.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mEarly stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader, desc=\"Training Steps\"):\n",
    "        # print(train_input)\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = train_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "        tok_type = train_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        repr = train_input[2].to(device)\n",
    "        # print(tok_type.shape, input_id.shape, mask.shape)\n",
    "        # print(repr.dtype, input_id.dtype, mask.dtype)\n",
    "\n",
    "        output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "        batch_loss = criterion(output, train_label.long())\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        \n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_acc_val = 0\n",
    "    total_loss_val = 0\n",
    "    correct_top_k = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for val_input, val_label in tqdm(val_dataloader, desc=\"Validation Steps\"):\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "            input_id = val_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "            tok_type = val_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "            repr = val_input[2].to(device)\n",
    "\n",
    "            output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            output = torch.sum(torch.stack(output), 0)\n",
    "            _, top_k_predictions = output.topk(3, 1, True, True)\n",
    "\n",
    "            top_k_predictions = top_k_predictions.t()\n",
    "\n",
    "            correct_top_k += (\n",
    "                top_k_predictions.eq(\n",
    "                    val_label.view(1, -1).expand_as(top_k_predictions)\n",
    "                )\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "\n",
    "            all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.append(val_label.cpu().numpy())\n",
    "\n",
    "            total_acc_val += acc\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    top10 = correct_top_k / len(df_val)\n",
    "\n",
    "    log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        df_train,\n",
    "        df_val,\n",
    "        top10,\n",
    "    )\n",
    "\n",
    "    val_loss = total_loss_val / len(df_val)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        patience_counter = 0\n",
    "        logger.success(\"Found new best model. Saving weights...\")\n",
    "        torch.save(model.state_dict(), weights_save_location)\n",
    "        best_loss = val_loss\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter > patience:\n",
    "            logger.info(\"Early stopping...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd8134434cf46048fdd543469fcdd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.086 MB uploaded\\r'), FloatProgress(value=0.06106246480350695, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1-score</td><td>▁▄▄▅▆▅▇▆▇▇▇▆▇▆▇▅▇▇▆▇█▆</td></tr><tr><td>precision</td><td>▁▃▃▄▄▄▇▅▅▅█▄▅▅▅▅█▅▅▅█▅</td></tr><tr><td>recall</td><td>▁▇▇▆▇▅▇▄▇▇▆▆█▇▇▄▇▇▅▇█▅</td></tr><tr><td>top3_acc</td><td>▁▃▆▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇████████████████</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▆▇█▇▇▇▆▇▇▇██▇████</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1-score</td><td>0.63073</td></tr><tr><td>precision</td><td>0.65289</td></tr><tr><td>recall</td><td>0.61956</td></tr><tr><td>top3_acc</td><td>0.9887</td></tr><tr><td>train_acc</td><td>0.9967</td></tr><tr><td>train_loss</td><td>0.01662</td></tr><tr><td>val_acc</td><td>0.77966</td></tr><tr><td>val_loss</td><td>0.30558</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">component_prediction_chrono_order_6_classes</strong> at: <a href='https://wandb.ai/afifaniks/openj9/runs/6q51lzsv' target=\"_blank\">https://wandb.ai/afifaniks/openj9/runs/6q51lzsv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240421_144802-6q51lzsv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best checkpoint\n",
    "model.load_state_dict(torch.load(weights_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/disa_lab/projects/triagerx/models/deberta_component_prediction_chrono_10class.pt'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_save_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 16:15:05.351\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-04-21 16:15:05.352\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_ds = TriageDataset(df_test, model.tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(test_ds, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd6692c50664cd7a0754373f6a5f232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load embeddings for all train data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m similarity_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m similarity_model\u001b[38;5;241m.\u001b[39mencode(\u001b[43mX_df\u001b[49m\u001b[38;5;241m.\u001b[39missue_title\u001b[38;5;241m.\u001b[39mto_list(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Load embeddings for all train data\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "all_embeddings = similarity_model.encode(X_df.issue_title.to_list(), batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_similar_devs(issues, k=5, threshold=0.7):\n",
    "    test_embed = similarity_model.encode(issues)\n",
    "    cos = util.cos_sim(test_embed, all_embeddings)\n",
    "    topk_values, topk_indices = torch.topk(cos, k=k)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for idx, sim_score in zip(topk_indices, topk_values):\n",
    "        sim_threshold = sim_score >= threshold\n",
    "        filtered_idx = idx[sim_threshold].numpy()\n",
    "        similarities.append(X_df.iloc[filtered_idx][\"owner_id\"].unique().tolist())\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_k_similar_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_val = 0\n",
    "total_loss_val = 0\n",
    "correct_top_k = 0\n",
    "correct_top_k_wo_sim = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "device=\"cuda\"\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for val_input, val_label in loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = val_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "        tok_type = val_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        repr = val_input[2].to(device)\n",
    "\n",
    "        output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "\n",
    "        #wo similarity\n",
    "        _, top_k_wo_sim = output.topk(3, 1, True, True)\n",
    "\n",
    "        top_k_wo_sim = top_k_wo_sim.t()\n",
    "\n",
    "        correct_top_k_wo_sim += (\n",
    "            top_k_wo_sim.eq(\n",
    "                val_label.view(1, -1).expand_as(top_k_wo_sim)\n",
    "            )\n",
    "            .sum()\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "\n",
    "        # with similarity\n",
    "        # _, top_k_predictions = output.topk(10, 1, True, True)\n",
    "        # similar_preds = get_top_k_similar_devs(val_input[0], threshold=0.65)\n",
    "\n",
    "        # unique_preds = []\n",
    "\n",
    "        # for top, sim in zip(top_k_predictions, similar_preds):\n",
    "        #     # print(top, sim)\n",
    "            \n",
    "        #     copy_pred = top.cpu().numpy().tolist()\n",
    "        #     top_preds = top.cpu().numpy().tolist()[:5]\n",
    "\n",
    "        #     for s in sim:\n",
    "        #         if s not in top_preds:\n",
    "        #             top_preds.append(s)\n",
    "            \n",
    "        #     if len(top_preds) < 10:\n",
    "        #         top_preds = top_preds + copy_pred[5:5 + 10 - len(top_preds)]\n",
    "            \n",
    "        #     unique_preds.append(top_preds)\n",
    "\n",
    "        # unique_preds = torch.tensor(unique_preds).cuda()\n",
    "        # top_k_predictions = unique_preds.t()\n",
    "\n",
    "        # correct_top_k += (\n",
    "        #     top_k_predictions.eq(\n",
    "        #         val_label.view(1, -1).expand_as(top_k_predictions)\n",
    "        #     )\n",
    "        #     .sum()\n",
    "        #     .item()\n",
    "        # )\n",
    "\n",
    "        # # break\n",
    "\n",
    "        # acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "\n",
    "        all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.append(val_label.cpu().numpy())\n",
    "\n",
    "        # total_acc_val += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction without Similarity: 493, 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct Prediction without Similarity: {correct_top_k_wo_sim}, {correct_top_k_wo_sim / len(df_test)}\")\n",
    "# print(f\"Correct Prediction with Similarity: {correct_top_k}, {correct_top_k / len(y_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 5, 6, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1,\n",
       "       4, 2, 2, 2, 1, 1, 3, 1, 2, 7, 1, 2, 3, 1, 2, 6, 2, 1, 5, 2, 6, 6,\n",
       "       2, 4, 1, 2, 1, 6, 2, 1, 1, 3, 1, 1, 6, 1, 2, 1, 1, 1, 1, 6, 1, 4,\n",
       "       2, 4, 2, 1, 2, 2, 1, 1, 2, 1, 2, 6, 0, 4, 4, 1, 6, 2, 5, 6, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 3, 2, 1, 6, 5, 3, 1, 2, 2, 1, 3, 2, 6, 2, 5,\n",
       "       2, 2, 4, 2, 6, 2, 3, 5, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 5, 1, 6, 2,\n",
       "       0, 1, 1, 1, 6, 6, 1, 2, 5, 1, 3, 1, 5, 3, 2, 2, 1, 2, 2, 1, 5, 1,\n",
       "       6, 6, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 6, 1, 6,\n",
       "       6, 6, 2, 1, 1, 0, 1, 1, 6, 1, 4, 6, 2, 2, 3, 1, 2, 1, 1, 2, 2, 6,\n",
       "       1, 3, 4, 4, 1, 5, 2, 2, 1, 0, 4, 2, 1, 2, 2, 6, 1, 2, 5, 2, 1, 6,\n",
       "       6, 4, 2, 5, 1, 1, 2, 2, 2, 4, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 4, 3,\n",
       "       0, 4, 1, 1, 1, 1, 3, 5, 1, 1, 2, 4, 1, 2, 1, 2, 3, 5, 2, 1, 1, 6,\n",
       "       1, 6, 1, 1, 4, 2, 1, 1, 1, 4, 6, 6, 0, 2, 3, 3, 1, 2, 6, 6, 4, 3,\n",
       "       1, 2, 1, 6, 2, 6, 1, 0, 6, 2, 2, 5, 2, 4, 3, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 6, 1, 3, 2, 7, 1, 1, 6, 1, 5, 1, 6, 2, 3, 1, 3, 2, 4,\n",
       "       1, 1, 1, 2, 2, 0, 1, 1, 1, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 6, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 6, 6, 1, 3, 3, 2, 1,\n",
       "       1, 2, 6, 2, 6, 2, 1, 5, 5, 2, 6, 3, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       1, 1, 1, 6, 0, 6, 2, 2, 1, 2, 6, 1, 1, 1, 5, 2, 2, 1, 6, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 6, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 6, 5, 2, 4, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 5, 0, 2,\n",
       "       3, 2, 6, 1, 5, 2, 2, 3, 6, 2, 1, 2, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 6, 2, 2, 2, 5, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 5, 6, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1,\n",
       "       4, 2, 2, 2, 1, 1, 3, 1, 2, 7, 1, 2, 3, 1, 2, 6, 2, 1, 5, 2, 6, 6,\n",
       "       2, 4, 1, 2, 1, 6, 2, 1, 1, 3, 1, 1, 6, 1, 2, 1, 1, 1, 1, 6, 1, 4,\n",
       "       2, 4, 2, 1, 2, 2, 1, 1, 2, 1, 2, 6, 0, 4, 4, 1, 6, 2, 5, 6, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 3, 2, 1, 6, 5, 3, 1, 2, 2, 1, 3, 2, 6, 2, 5,\n",
       "       2, 2, 4, 2, 6, 2, 3, 5, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 5, 1, 6, 2,\n",
       "       0, 1, 1, 1, 6, 6, 1, 2, 5, 1, 3, 1, 5, 3, 2, 2, 1, 2, 2, 1, 5, 1,\n",
       "       6, 6, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 6, 1, 6,\n",
       "       6, 6, 2, 1, 1, 0, 1, 1, 6, 1, 4, 6, 2, 2, 3, 1, 2, 1, 1, 2, 2, 6,\n",
       "       1, 3, 4, 4, 1, 5, 2, 2, 1, 0, 4, 2, 1, 2, 2, 6, 1, 2, 5, 2, 1, 6,\n",
       "       6, 4, 2, 5, 1, 1, 2, 2, 2, 4, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 4, 3,\n",
       "       0, 4, 1, 1, 1, 1, 3, 5, 1, 1, 2, 4, 1, 2, 1, 2, 3, 5, 2, 1, 1, 6,\n",
       "       1, 6, 1, 1, 4, 2, 1, 1, 1, 4, 6, 6, 0, 2, 3, 3, 1, 2, 6, 6, 4, 3,\n",
       "       1, 2, 1, 6, 2, 6, 1, 0, 6, 2, 2, 5, 2, 4, 3, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 6, 1, 3, 2, 7, 1, 1, 6, 1, 5, 1, 6, 2, 3, 1, 3, 2, 4,\n",
       "       1, 1, 1, 2, 2, 0, 1, 1, 1, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 6, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 6, 6, 1, 3, 3, 2, 1,\n",
       "       1, 2, 6, 2, 6, 2, 1, 5, 5, 2, 6, 3, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       1, 1, 1, 6, 0, 6, 2, 2, 1, 2, 6, 1, 1, 1, 5, 2, 2, 1, 6, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 6, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 6, 5, 2, 4, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 5, 0, 2,\n",
       "       3, 2, 6, 1, 5, 2, 2, 3, 6, 2, 1, 2, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 6, 2, 2, 2, 5, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_np = np.concatenate(all_preds)\n",
    "all_labels_np = np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 32, does not match size of target_names, 2518. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2567\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2563\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2564\u001b[0m             )\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2573\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 32, does not match size of target_names, 2518. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels_np, all_preds_np, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    row[\"owner_id\"]: row[\"owner\"]\n",
    "    for _, row in y_df.iterrows()\n",
    "}\n",
    "\n",
    "labels = y_df.owner_id.to_list()\n",
    "labels = sorted(set(labels))\n",
    "labels = [f\"{idx}: {idx2label[idx]}\" for idx in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_distribution(owner):\n",
    "    print(\"Training topic distribution\")\n",
    "    print(\"=======================================\")\n",
    "    print(X_df[X_df.owner == owner].topic_label.value_counts())\n",
    "\n",
    "    print(\"\\n\\nTesting topic distribution\")\n",
    "    print(\"=======================================\")\n",
    "    print(y_df[y_df.owner == owner].topic_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chrome Tab and Window Behavior Issues     947\n",
       "Build failures                            840\n",
       "Chrome stability issues                   487\n",
       "Layout Testing Issues                     400\n",
       "Chrome crash reports                      391\n",
       "Security and SSL issues                   372\n",
       "Input and keyboard issues                 370\n",
       "Webpage rendering regression issues       357\n",
       "Chrome sync issues                        354\n",
       "Shill WiFi configuration                  337\n",
       "iOS File Issues                           321\n",
       "Data Enhancement                          298\n",
       "Touch and Scroll Issues                   273\n",
       "DevTools Crashes                          260\n",
       "GPU rendering issues                      235\n",
       "Memory Leaks in WebCore and Blink         220\n",
       "Performance testing issues in Chromium    197\n",
       "WebRTC audio/video issues                 184\n",
       "Bookmark issues                           174\n",
       "Performance Regression in Blink            13\n",
       "Name: topic_label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.topic_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training topic distribution\n",
      "=======================================\n",
      "Chrome Tab and Window Behavior Issues     10\n",
      "Webpage rendering regression issues        5\n",
      "Memory Leaks in WebCore and Blink          4\n",
      "Chrome stability issues                    4\n",
      "DevTools Crashes                           3\n",
      "Data Enhancement                           3\n",
      "Input and keyboard issues                  3\n",
      "Touch and Scroll Issues                    2\n",
      "Bookmark issues                            1\n",
      "Security and SSL issues                    1\n",
      "Chrome sync issues                         1\n",
      "Layout Testing Issues                      1\n",
      "Build failures                             1\n",
      "iOS File Issues                            1\n",
      "Performance testing issues in Chromium     1\n",
      "Name: topic_label, dtype: int64\n",
      "\n",
      "\n",
      "Testing topic distribution\n",
      "=======================================\n",
      "Chrome Tab and Window Behavior Issues     17\n",
      "Webpage rendering regression issues        7\n",
      "DevTools Crashes                           6\n",
      "iOS File Issues                            6\n",
      "Touch and Scroll Issues                    4\n",
      "Input and keyboard issues                  4\n",
      "Data Enhancement                           4\n",
      "Chrome crash reports                       4\n",
      "Chrome stability issues                    3\n",
      "Memory Leaks in WebCore and Blink          2\n",
      "Chrome sync issues                         2\n",
      "Bookmark issues                            1\n",
      "Performance testing issues in Chromium     1\n",
      "Name: topic_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_topic_distribution(\"a...@chromium.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
