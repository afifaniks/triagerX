{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from loguru import logger\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, PreTrainedTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_split(x):\n",
    "    x_split = str(x).split(\",\")\n",
    "\n",
    "    for s in x_split:\n",
    "        if \"comp:\" in s.lower():\n",
    "            return s.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2098717/1565925833.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"component\"] = df[\"labels\"].apply(component_split)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5180/5180 [00:00<00:00, 71581.28it/s]\n",
      "/tmp/ipykernel_2098717/1565925833.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = df.progress_apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues: 5180\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/openj9/openj9_topic_all_issues.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(len(df))\n",
    "df = df.rename(columns={\"assignees\": \"owner\", \"issue_body\": \"description\"})\n",
    "df = df[df[\"owner\"].notna()]\n",
    "\n",
    "def clean_data(df):\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df[\"labels\"].notna()]\n",
    "    df[\"component\"] = df[\"labels\"].apply(component_split)\n",
    "    \n",
    "    df[\"text\"] = df.progress_apply(\n",
    "            lambda x: \"Title: \"\n",
    "            + str(x[\"issue_title\"])\n",
    "            + \"\\nIssue Labels: \"\n",
    "            + str(x[\"labels\"])\n",
    "            + \"\\nIssue Topic: \"\n",
    "            + str(x[\"topic_label\"])\n",
    "            + \"\\nDescription: \"\n",
    "            + str(x[\"description\"]),\n",
    "            axis=1,\n",
    "        )\n",
    "    \n",
    "    min_length = 15\n",
    "    df = df[df[\"text\"].str.len().gt(min_length)]\n",
    "\n",
    "    # df[\"owner_id\"] = pd.factorize(df[\"assignees\"])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_dataframe(df)\n",
    "df = clean_data(df)\n",
    "df = df.sort_values(by=\"issue_number\")\n",
    "\n",
    "num_issues = len(df)\n",
    "\n",
    "print(f\"Total number of issues: {num_issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_hot\"] = pd.get_dummies(df[\"topic_id\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df[\"component\"].values:\n",
    "    if val is None:\n",
    "        continue\n",
    "    \n",
    "    split = val.split(\",\")\n",
    "    \n",
    "    for s in split:\n",
    "        components.add(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp:build',\n",
       " 'comp:crypto',\n",
       " 'comp:doc',\n",
       " 'comp:gc',\n",
       " 'comp:infra',\n",
       " 'comp:jclextensions',\n",
       " 'comp:jit',\n",
       " 'comp:jit:aot',\n",
       " 'comp:jitserver',\n",
       " 'comp:jvmti',\n",
       " 'comp:port',\n",
       " 'comp:test',\n",
       " 'comp:vm'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comp:jit              1870\n",
       "comp:vm               1546\n",
       "comp:jitserver         610\n",
       "comp:build             376\n",
       "comp:gc                207\n",
       "comp:test              196\n",
       "comp:doc                86\n",
       "comp:infra              39\n",
       "comp:jit:aot            15\n",
       "comp:port               11\n",
       "comp:jclextensions       8\n",
       "comp:jvmti               4\n",
       "comp:crypto              3\n",
       "Name: component, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"component\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_values = df[\"component\"].value_counts()\n",
    "filtered_components = component_values.index[component_values >= 25]\n",
    "\n",
    "df = df[df[\"component\"].isin(filtered_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Component vs Number of issue')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"component\"].value_counts().plot(kind = \"bar\").set_title(\"Component vs Number of issue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross-Validation Fold Definition\n",
    "\n",
    "# num_cv = 10\n",
    "# sample_threshold=20 # Threshold to filter developers\n",
    "# samples_per_block = len(df) // num_cv + 1\n",
    "# print(f\"Samples per block: {samples_per_block}\")\n",
    "\n",
    "# block = 9 \n",
    "# sliced_df = df[: samples_per_block * (block+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {label: idx for idx, label in enumerate(list(df[\"component\"].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"component_id\"] = [label2idx[component] for component in df[\"component\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3944 493 493\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=22),\n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and Validation preparation\n",
    "\n",
    "# X_df = sliced_df[:samples_per_block*block]\n",
    "# y_df = sliced_df[samples_per_block*block : samples_per_block * (block+1)]\n",
    "\n",
    "# developers = X_df[\"owner\"].value_counts()\n",
    "# filtered_developers = developers.index[developers >= sample_threshold]\n",
    "# X_df = X_df[X_df[\"owner\"].isin(filtered_developers)]\n",
    "\n",
    "# train_owners = set(X_df[\"owner\"])\n",
    "# test_owners = set(y_df[\"owner\"])\n",
    "\n",
    "# unwanted = list(test_owners - train_owners)\n",
    "\n",
    "# y_df = y_df[~y_df[\"owner\"].isin(unwanted)]\n",
    "\n",
    "# print(f\"Training data: {len(X_df)}, Validation data: {len(y_df)}\")\n",
    "# print(f\"Number of developers: {len(X_df.owner.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.owner.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Label encode developers\n",
    "\n",
    "# lbl2idx = {}\n",
    "\n",
    "# train_owners = sorted(train_owners)\n",
    "\n",
    "# for idx, dev in enumerate(train_owners):\n",
    "#     lbl2idx[dev] = idx\n",
    "\n",
    "# X_df[\"owner_id\"] = X_df[\"owner\"].apply(lambda owner: lbl2idx[owner])\n",
    "# y_df[\"owner_id\"] = y_df[\"owner\"].apply(lambda owner: lbl2idx[owner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribution plot\n",
    "\n",
    "# X_df.owner_id.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        feature: str = \"text\",\n",
    "        target: str = \"component_id\",\n",
    "    ):\n",
    "        logger.debug(\"Generating torch dataset...\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = [label for label in df[target]]\n",
    "        # self.embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "        logger.debug(\"Tokenizing texts...\")\n",
    "        self.texts = [\n",
    "            (row[feature], self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ), torch.tensor(row.topic_hot))\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBTPClassifierTopic(nn.Module):\n",
    "    def __init__(\n",
    "        self, output_size, topic_size, unfrozen_layers=4, embed_size=1024, dropout=0.1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        model_name = \"microsoft/deberta-large\"\n",
    "        self.base_model = AutoModel.from_pretrained(\n",
    "            model_name, output_hidden_states=True\n",
    "        )\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Freeze embedding layers\n",
    "        for p in self.base_model.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Freeze encoder layers till last {unfrozen_layers} layers\n",
    "        for i in range(0, 24 - unfrozen_layers):\n",
    "            for p in self.base_model.encoder.layer[i].parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        filter_sizes = [3, 4, 5, 6]\n",
    "        self._num_filters = 256\n",
    "        self._max_tokens = 512\n",
    "        self._embed_size = embed_size\n",
    "        self.unfrozen_layers = unfrozen_layers\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv2d(1, self._num_filters, (K, embed_size)),\n",
    "                            nn.BatchNorm2d(self._num_filters),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Flatten(),\n",
    "                            nn.MaxPool1d(self._max_tokens - (K - 1)),\n",
    "                            nn.Flatten(start_dim=1),\n",
    "                        )\n",
    "                        for K in filter_sizes\n",
    "                    ]\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifiers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(\n",
    "                    len(filter_sizes) * self._num_filters + topic_size, output_size\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tok_type, topic_id):\n",
    "        outputs = []\n",
    "\n",
    "        base_out = self.base_model(input_ids=input_ids, token_type_ids=tok_type, attention_mask=attention_mask)\n",
    "        # pooler_out = base_out.last_hidden_state.squeeze(0)\n",
    "        hidden_states = base_out.hidden_states[-self.unfrozen_layers :]\n",
    "\n",
    "        for i in range(self.unfrozen_layers):\n",
    "            batch_size, sequence_length, hidden_size = hidden_states[i].size()\n",
    "            x = [\n",
    "                conv(hidden_states[i].view(batch_size, 1, sequence_length, hidden_size))\n",
    "                for conv in self.conv_blocks[i]\n",
    "            ]\n",
    "            # Concatanating outputs of the conv block of different filter sizes\n",
    "            x = torch.cat(x, dim=1)\n",
    "            x = self.dropout(x)\n",
    "            x = torch.cat([x, topic_id], dim=1)\n",
    "            x = self.classifiers[i](x)\n",
    "\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def tokenizer(self) -> AutoTokenizer:\n",
    "        return self._tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            focal_loss = focal_loss * self.alpha\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self, weights = None) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = nn.CrossEntropyLoss(weight=weights)\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineFocalLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = FocalLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df_train[\"component\"].unique())\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.bincount(df_train[\"component_id\"])\n",
    "num_samples = sum(class_counts)\n",
    "labels = df_train[\"component_id\"].to_list() # corresponding labels of samples\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "weights_save_location = f\"deberta_component.pt\"\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 1e-5\n",
    "epochs = 20\n",
    "batch_size = 15\n",
    "\n",
    "model = LBTPClassifierTopic(len(df_train.component_id.unique()), topic_size=20, unfrozen_layers=2, dropout=0.3)\n",
    "criterion = CombineLoss(weights=None)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8, weight_decay=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=2, factor=0.1, threshold=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-31 23:26:08.128\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-03-31 23:26:08.130\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n",
      "\u001b[32m2024-03-31 23:26:12.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-03-31 23:26:12.536\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare torch dataset from train and validation splits\n",
    "train = TriageDataset(df_train, model.tokenizer())\n",
    "val = TriageDataset(df_val, model.tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=10,\n",
    "    shuffle=False if sampler else True,\n",
    "    sampler=sampler,\n",
    ")\n",
    "val_dataloader = DataLoader(val, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-31 23:26:13.138\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mSelected compute device: cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.debug(f\"Selected compute device: {device}\")\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        topk,\n",
    "    ):\n",
    "        log = f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                    | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                    | Val Loss: {total_loss_val / len(validation_data): .3f} \\\n",
    "                    | Val Accuracy: {total_acc_val / len(validation_data): .3f} \\\n",
    "                    | Top 10: {topk} \\\n",
    "                    | Precision: {precision: .3f} \\\n",
    "                    | Recall: {recall: .3f} \\\n",
    "                    | F1-score: {f1_score: .3f}\"\n",
    "\n",
    "        logger.info(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps:   0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps: 100%|██████████| 395/395 [05:20<00:00,  1.23it/s]\n",
      "Validation Steps: 100%|██████████| 50/50 [00:17<00:00,  2.91it/s]\n",
      "\u001b[32m2024-03-31 23:31:51.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 1 | Train Loss:  0.250                     | Train Accuracy:  0.686                     | Val Loss:  0.092                     | Val Accuracy:  0.941                     | Top 10: 0.9898580121703854                     | Precision:  0.896                     | Recall:  0.944                     | F1-score:  0.915\u001b[0m\n",
      "\u001b[32m2024-03-31 23:31:51.326\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m99\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 395/395 [05:20<00:00,  1.23it/s]\n",
      "Validation Steps: 100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n",
      "\u001b[32m2024-03-31 23:37:33.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 2 | Train Loss:  0.022                     | Train Accuracy:  0.992                     | Val Loss:  0.010                     | Val Accuracy:  0.998                     | Top 10: 1.0                     | Precision:  0.999                     | Recall:  0.993                     | F1-score:  0.996\u001b[0m\n",
      "\u001b[32m2024-03-31 23:37:33.325\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m99\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps: 100%|██████████| 395/395 [05:20<00:00,  1.23it/s]\n",
      "Validation Steps: 100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n",
      "\u001b[32m2024-03-31 23:43:15.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_step\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpochs: 3 | Train Loss:  0.004                     | Train Accuracy:  0.999                     | Val Loss:  0.004                     | Val Accuracy:  0.998                     | Top 10: 1.0                     | Precision:  0.993                     | Recall:  0.998                     | F1-score:  0.996\u001b[0m\n",
      "\u001b[32m2024-03-31 23:43:15.955\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m99\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "Training Steps:  11%|█         | 42/395 [00:34<04:48,  1.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_id, mask, tok_type, \u001b[38;5;28mrepr\u001b[39m)\n\u001b[1;32m     17\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m criterion(output, train_label\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m---> 18\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbatch_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(output), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m acc \u001b[38;5;241m=\u001b[39m (output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m train_label)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader, desc=\"Training Steps\"):\n",
    "        # print(train_input)\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = train_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "        tok_type = train_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        repr = train_input[2].to(device)\n",
    "        # print(tok_type.shape, input_id.shape, mask.shape)\n",
    "        # print(repr.dtype, input_id.dtype, mask.dtype)\n",
    "\n",
    "        output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "        batch_loss = criterion(output, train_label.long())\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        \n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_acc_val = 0\n",
    "    total_loss_val = 0\n",
    "    correct_top_k = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for val_input, val_label in tqdm(val_dataloader, desc=\"Validation Steps\"):\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "            input_id = val_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "            tok_type = val_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "            repr = val_input[2].to(device)\n",
    "\n",
    "            output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            output = torch.sum(torch.stack(output), 0)\n",
    "            _, top_k_predictions = output.topk(3, 1, True, True)\n",
    "\n",
    "            top_k_predictions = top_k_predictions.t()\n",
    "\n",
    "            correct_top_k += (\n",
    "                top_k_predictions.eq(\n",
    "                    val_label.view(1, -1).expand_as(top_k_predictions)\n",
    "                )\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "\n",
    "            all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.append(val_label.cpu().numpy())\n",
    "\n",
    "            total_acc_val += acc\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    top10 = correct_top_k / len(df_val)\n",
    "\n",
    "    log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        df_train,\n",
    "        df_val,\n",
    "        top10,\n",
    "    )\n",
    "\n",
    "    val_loss = total_loss_val / len(df_val)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        logger.success(\"Found new best model. Saving weights...\")\n",
    "        torch.save(model.state_dict(), weights_save_location)\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best checkpoint\n",
    "model.load_state_dict(torch.load(weights_save_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-31 23:44:36.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-03-31 23:44:36.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_ds = TriageDataset(df_test, model.tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(test_ds, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings for all train data\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "all_embeddings = similarity_model.encode(X_df.issue_title.to_list(), batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_similar_devs(issues, k=5, threshold=0.7):\n",
    "    test_embed = similarity_model.encode(issues)\n",
    "    cos = util.cos_sim(test_embed, all_embeddings)\n",
    "    topk_values, topk_indices = torch.topk(cos, k=k)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for idx, sim_score in zip(topk_indices, topk_values):\n",
    "        sim_threshold = sim_score >= threshold\n",
    "        filtered_idx = idx[sim_threshold].numpy()\n",
    "        similarities.append(X_df.iloc[filtered_idx][\"owner_id\"].unique().tolist())\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_val = 0\n",
    "total_loss_val = 0\n",
    "correct_top_k = 0\n",
    "correct_top_k_wo_sim = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "device=\"cuda\"\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for val_input, val_label in loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = val_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "        tok_type = val_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        repr = val_input[2].to(device)\n",
    "\n",
    "        output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "\n",
    "        #wo similarity\n",
    "        _, top_k_wo_sim = output.topk(3, 1, True, True)\n",
    "\n",
    "        top_k_wo_sim = top_k_wo_sim.t()\n",
    "\n",
    "        correct_top_k_wo_sim += (\n",
    "            top_k_wo_sim.eq(\n",
    "                val_label.view(1, -1).expand_as(top_k_wo_sim)\n",
    "            )\n",
    "            .sum()\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "\n",
    "        # with similarity\n",
    "        # _, top_k_predictions = output.topk(10, 1, True, True)\n",
    "        # similar_preds = get_top_k_similar_devs(val_input[0], threshold=0.65)\n",
    "\n",
    "        # unique_preds = []\n",
    "\n",
    "        # for top, sim in zip(top_k_predictions, similar_preds):\n",
    "        #     # print(top, sim)\n",
    "            \n",
    "        #     copy_pred = top.cpu().numpy().tolist()\n",
    "        #     top_preds = top.cpu().numpy().tolist()[:5]\n",
    "\n",
    "        #     for s in sim:\n",
    "        #         if s not in top_preds:\n",
    "        #             top_preds.append(s)\n",
    "            \n",
    "        #     if len(top_preds) < 10:\n",
    "        #         top_preds = top_preds + copy_pred[5:5 + 10 - len(top_preds)]\n",
    "            \n",
    "        #     unique_preds.append(top_preds)\n",
    "\n",
    "        # unique_preds = torch.tensor(unique_preds).cuda()\n",
    "        # top_k_predictions = unique_preds.t()\n",
    "\n",
    "        # correct_top_k += (\n",
    "        #     top_k_predictions.eq(\n",
    "        #         val_label.view(1, -1).expand_as(top_k_predictions)\n",
    "        #     )\n",
    "        #     .sum()\n",
    "        #     .item()\n",
    "        # )\n",
    "\n",
    "        # # break\n",
    "\n",
    "        # acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "\n",
    "        all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.append(val_label.cpu().numpy())\n",
    "\n",
    "        # total_acc_val += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction without Similarity: 493, 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct Prediction without Similarity: {correct_top_k_wo_sim}, {correct_top_k_wo_sim / len(df_test)}\")\n",
    "# print(f\"Correct Prediction with Similarity: {correct_top_k}, {correct_top_k / len(y_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 5, 6, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1,\n",
       "       4, 2, 2, 2, 1, 1, 3, 1, 2, 7, 1, 2, 3, 1, 2, 6, 2, 1, 5, 2, 6, 6,\n",
       "       2, 4, 1, 2, 1, 6, 2, 1, 1, 3, 1, 1, 6, 1, 2, 1, 1, 1, 1, 6, 1, 4,\n",
       "       2, 4, 2, 1, 2, 2, 1, 1, 2, 1, 2, 6, 0, 4, 4, 1, 6, 2, 5, 6, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 3, 2, 1, 6, 5, 3, 1, 2, 2, 1, 3, 2, 6, 2, 5,\n",
       "       2, 2, 4, 2, 6, 2, 3, 5, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 5, 1, 6, 2,\n",
       "       0, 1, 1, 1, 6, 6, 1, 2, 5, 1, 3, 1, 5, 3, 2, 2, 1, 2, 2, 1, 5, 1,\n",
       "       6, 6, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 6, 1, 6,\n",
       "       6, 6, 2, 1, 1, 0, 1, 1, 6, 1, 4, 6, 2, 2, 3, 1, 2, 1, 1, 2, 2, 6,\n",
       "       1, 3, 4, 4, 1, 5, 2, 2, 1, 0, 4, 2, 1, 2, 2, 6, 1, 2, 5, 2, 1, 6,\n",
       "       6, 4, 2, 5, 1, 1, 2, 2, 2, 4, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 4, 3,\n",
       "       0, 4, 1, 1, 1, 1, 3, 5, 1, 1, 2, 4, 1, 2, 1, 2, 3, 5, 2, 1, 1, 6,\n",
       "       1, 6, 1, 1, 4, 2, 1, 1, 1, 4, 6, 6, 0, 2, 3, 3, 1, 2, 6, 6, 4, 3,\n",
       "       1, 2, 1, 6, 2, 6, 1, 0, 6, 2, 2, 5, 2, 4, 3, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 6, 1, 3, 2, 7, 1, 1, 6, 1, 5, 1, 6, 2, 3, 1, 3, 2, 4,\n",
       "       1, 1, 1, 2, 2, 0, 1, 1, 1, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 6, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 6, 6, 1, 3, 3, 2, 1,\n",
       "       1, 2, 6, 2, 6, 2, 1, 5, 5, 2, 6, 3, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       1, 1, 1, 6, 0, 6, 2, 2, 1, 2, 6, 1, 1, 1, 5, 2, 2, 1, 6, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 6, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 6, 5, 2, 4, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 5, 0, 2,\n",
       "       3, 2, 6, 1, 5, 2, 2, 3, 6, 2, 1, 2, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 6, 2, 2, 2, 5, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 5, 6, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1,\n",
       "       4, 2, 2, 2, 1, 1, 3, 1, 2, 7, 1, 2, 3, 1, 2, 6, 2, 1, 5, 2, 6, 6,\n",
       "       2, 4, 1, 2, 1, 6, 2, 1, 1, 3, 1, 1, 6, 1, 2, 1, 1, 1, 1, 6, 1, 4,\n",
       "       2, 4, 2, 1, 2, 2, 1, 1, 2, 1, 2, 6, 0, 4, 4, 1, 6, 2, 5, 6, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 3, 2, 1, 6, 5, 3, 1, 2, 2, 1, 3, 2, 6, 2, 5,\n",
       "       2, 2, 4, 2, 6, 2, 3, 5, 1, 1, 1, 2, 1, 1, 1, 4, 2, 1, 5, 1, 6, 2,\n",
       "       0, 1, 1, 1, 6, 6, 1, 2, 5, 1, 3, 1, 5, 3, 2, 2, 1, 2, 2, 1, 5, 1,\n",
       "       6, 6, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 6, 1, 6,\n",
       "       6, 6, 2, 1, 1, 0, 1, 1, 6, 1, 4, 6, 2, 2, 3, 1, 2, 1, 1, 2, 2, 6,\n",
       "       1, 3, 4, 4, 1, 5, 2, 2, 1, 0, 4, 2, 1, 2, 2, 6, 1, 2, 5, 2, 1, 6,\n",
       "       6, 4, 2, 5, 1, 1, 2, 2, 2, 4, 1, 2, 2, 2, 1, 1, 2, 1, 3, 2, 4, 3,\n",
       "       0, 4, 1, 1, 1, 1, 3, 5, 1, 1, 2, 4, 1, 2, 1, 2, 3, 5, 2, 1, 1, 6,\n",
       "       1, 6, 1, 1, 4, 2, 1, 1, 1, 4, 6, 6, 0, 2, 3, 3, 1, 2, 6, 6, 4, 3,\n",
       "       1, 2, 1, 6, 2, 6, 1, 0, 6, 2, 2, 5, 2, 4, 3, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 6, 1, 3, 2, 7, 1, 1, 6, 1, 5, 1, 6, 2, 3, 1, 3, 2, 4,\n",
       "       1, 1, 1, 2, 2, 0, 1, 1, 1, 6, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 6, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 6, 6, 1, 3, 3, 2, 1,\n",
       "       1, 2, 6, 2, 6, 2, 1, 5, 5, 2, 6, 3, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       1, 1, 1, 6, 0, 6, 2, 2, 1, 2, 6, 1, 1, 1, 5, 2, 2, 1, 6, 1, 1, 1,\n",
       "       2, 1, 1, 2, 1, 1, 6, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 6, 5, 2, 4, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 5, 0, 2,\n",
       "       3, 2, 6, 1, 5, 2, 2, 3, 6, 2, 1, 2, 3, 1, 4, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 6, 2, 2, 2, 5, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_np = np.concatenate(all_preds)\n",
    "all_labels_np = np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 32, does not match size of target_names, 2518. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2567\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2563\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2564\u001b[0m             )\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2573\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 32, does not match size of target_names, 2518. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels_np, all_preds_np, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    row[\"owner_id\"]: row[\"owner\"]\n",
    "    for _, row in y_df.iterrows()\n",
    "}\n",
    "\n",
    "labels = y_df.owner_id.to_list()\n",
    "labels = sorted(set(labels))\n",
    "labels = [f\"{idx}: {idx2label[idx]}\" for idx in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_distribution(owner):\n",
    "    print(\"Training topic distribution\")\n",
    "    print(\"=======================================\")\n",
    "    print(X_df[X_df.owner == owner].topic_label.value_counts())\n",
    "\n",
    "    print(\"\\n\\nTesting topic distribution\")\n",
    "    print(\"=======================================\")\n",
    "    print(y_df[y_df.owner == owner].topic_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chrome Tab and Window Behavior Issues     947\n",
       "Build failures                            840\n",
       "Chrome stability issues                   487\n",
       "Layout Testing Issues                     400\n",
       "Chrome crash reports                      391\n",
       "Security and SSL issues                   372\n",
       "Input and keyboard issues                 370\n",
       "Webpage rendering regression issues       357\n",
       "Chrome sync issues                        354\n",
       "Shill WiFi configuration                  337\n",
       "iOS File Issues                           321\n",
       "Data Enhancement                          298\n",
       "Touch and Scroll Issues                   273\n",
       "DevTools Crashes                          260\n",
       "GPU rendering issues                      235\n",
       "Memory Leaks in WebCore and Blink         220\n",
       "Performance testing issues in Chromium    197\n",
       "WebRTC audio/video issues                 184\n",
       "Bookmark issues                           174\n",
       "Performance Regression in Blink            13\n",
       "Name: topic_label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.topic_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training topic distribution\n",
      "=======================================\n",
      "Chrome Tab and Window Behavior Issues     10\n",
      "Webpage rendering regression issues        5\n",
      "Memory Leaks in WebCore and Blink          4\n",
      "Chrome stability issues                    4\n",
      "DevTools Crashes                           3\n",
      "Data Enhancement                           3\n",
      "Input and keyboard issues                  3\n",
      "Touch and Scroll Issues                    2\n",
      "Bookmark issues                            1\n",
      "Security and SSL issues                    1\n",
      "Chrome sync issues                         1\n",
      "Layout Testing Issues                      1\n",
      "Build failures                             1\n",
      "iOS File Issues                            1\n",
      "Performance testing issues in Chromium     1\n",
      "Name: topic_label, dtype: int64\n",
      "\n",
      "\n",
      "Testing topic distribution\n",
      "=======================================\n",
      "Chrome Tab and Window Behavior Issues     17\n",
      "Webpage rendering regression issues        7\n",
      "DevTools Crashes                           6\n",
      "iOS File Issues                            6\n",
      "Touch and Scroll Issues                    4\n",
      "Input and keyboard issues                  4\n",
      "Data Enhancement                           4\n",
      "Chrome crash reports                       4\n",
      "Chrome stability issues                    3\n",
      "Memory Leaks in WebCore and Blink          2\n",
      "Chrome sync issues                         2\n",
      "Bookmark issues                            1\n",
      "Performance testing issues in Chromium     1\n",
      "Name: topic_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_topic_distribution(\"a...@chromium.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
