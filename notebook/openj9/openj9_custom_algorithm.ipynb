{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from loguru import logger\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup, PreTrainedTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_split(x):\n",
    "    x_split = str(x).split(\",\")\n",
    "\n",
    "    for s in x_split:\n",
    "        if \"comp:\" in s.lower():\n",
    "            return s.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18278\n",
      "All issues: 16342\n",
      "Excluding pull: 6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [00:00<00:00, 85160.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues: 6990\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/openj9/openj9_topic_all_issues.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(len(df))\n",
    "df = df.rename(columns={\"assignees\": \"owner\", \"issue_body\": \"description\"})\n",
    "# df = df[df[\"owner\"].notna()]\n",
    "\n",
    "def clean_data(df):\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df[\"labels\"].notna()]\n",
    "    print(f\"All issues: {len(df)}\")\n",
    "    df = df[~df[\"issue_url\"].str.contains(\"/pull/\")]\n",
    "    print(f\"Excluding pull: {len(df)}\")\n",
    "    df[\"component\"] = df[\"labels\"].apply(component_split)\n",
    "    \n",
    "    df[\"text\"] = df.progress_apply(\n",
    "            lambda x: \"Title: \"\n",
    "            + str(x[\"issue_title\"])\n",
    "            # + \"\\nIssue Labels: \"\n",
    "            # + str(x[\"labels\"])\n",
    "            + \"\\nIssue Topic: \"\n",
    "            + str(x[\"topic_label\"])\n",
    "            + \"\\nDescription: \"\n",
    "            + str(x[\"description\"]),\n",
    "            axis=1,\n",
    "        )\n",
    "    \n",
    "    min_length = 15\n",
    "    df = df[df[\"text\"].str.len().gt(min_length)]\n",
    "\n",
    "    # df[\"owner_id\"] = pd.factorize(df[\"assignees\"])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_dataframe(df)\n",
    "df = clean_data(df)\n",
    "df = df.sort_values(by=\"issue_number\")\n",
    "\n",
    "num_issues = len(df)\n",
    "\n",
    "print(f\"Total number of issues: {num_issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_hot\"] = pd.get_dummies(df[\"topic_id\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df[\"component\"].values:\n",
    "    if val is None:\n",
    "        continue\n",
    "    \n",
    "    split = val.split(\",\")\n",
    "    \n",
    "    for s in split:\n",
    "        components.add(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp:build',\n",
       " 'comp:crypto',\n",
       " 'comp:doc',\n",
       " 'comp:fips',\n",
       " 'comp:gc',\n",
       " 'comp:infra',\n",
       " 'comp:jclextensions',\n",
       " 'comp:jit',\n",
       " 'comp:jit:aot',\n",
       " 'comp:jitserver',\n",
       " 'comp:jvmti',\n",
       " 'comp:openssl',\n",
       " 'comp:port',\n",
       " 'comp:test',\n",
       " 'comp:vm'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_values = df[\"component\"].value_counts()\n",
    "filtered_components = component_values.index[component_values >= 20]\n",
    "\n",
    "df = df[df[\"component\"].isin(filtered_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_component(source_df, train_size=0.8):\n",
    "    grouped = source_df.groupby('component')\n",
    "\n",
    "    # Initialize two empty lists to store the split datasets\n",
    "    dataset_1 = []\n",
    "    dataset_2 = []\n",
    "\n",
    "    # Iterate over each group\n",
    "    for _, group_df in grouped:\n",
    "        # Split the group into two halves\n",
    "        first_idx = int(len(group_df) * train_size)\n",
    "        group_half_1 = group_df.iloc[:first_idx]\n",
    "        group_half_2 = group_df.iloc[first_idx:]\n",
    "        \n",
    "        # Append each half to the respective dataset\n",
    "        dataset_1.append(group_half_1)\n",
    "        dataset_2.append(group_half_2)\n",
    "\n",
    "    return pd.concat(dataset_1, ignore_index=True), pd.concat(dataset_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"issue_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655 296\n"
     ]
    }
   ],
   "source": [
    "components = [\"comp:vm\", \"comp:jvmti\", \"comp:jclextensions\", \"comp:test\", \"comp:build\", \"comp:gc\"]\n",
    "filtered_df = df[df[\"component\"].isin(components)]\n",
    "\n",
    "# Splitting parition by size\n",
    "total_data = len(filtered_df)\n",
    "train_size = int(total_data*0.9)\n",
    "test_size = total_data - train_size\n",
    "df_train = filtered_df[:train_size]\n",
    "df_test = filtered_df[train_size:]\n",
    "\n",
    "\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_train.component.unique()) == set(df_test.component.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size 2124 531 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_683278/1024108671.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"component_id\"] = [label2idx[component] for component in df_train[\"component\"].values]\n",
      "/tmp/ipykernel_683278/1024108671.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"component_id\"] = [label2idx[component] for component in df_test[\"component\"].values]\n"
     ]
    }
   ],
   "source": [
    "# Generate component ids\n",
    "label2idx = {label: idx for idx, label in enumerate(list(df_train[\"component\"].unique()))}\n",
    "df_train[\"component_id\"] = [label2idx[component] for component in df_train[\"component\"].values]\n",
    "df_test[\"component_id\"] = [label2idx[component] for component in df_test[\"component\"].values]\n",
    "\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Dataset size\", len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        feature: str = \"text\",\n",
    "        target: str = \"component_id\",\n",
    "    ):\n",
    "        logger.debug(\"Generating torch dataset...\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = [label for label in df[target]]\n",
    "        # self.embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "        logger.debug(\"Tokenizing texts...\")\n",
    "        self.texts = [\n",
    "            (row[feature], self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ), torch.tensor(row.topic_hot))\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBTPClassifierTopic(nn.Module):\n",
    "    def __init__(\n",
    "        self, output_size, topic_size, unfrozen_layers=4, embed_size=1024, dropout=0.1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        model_name = \"microsoft/deberta-large\"\n",
    "        self.base_model = AutoModel.from_pretrained(\n",
    "            model_name, output_hidden_states=True\n",
    "        )\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Freeze embedding layers\n",
    "        for p in self.base_model.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Freeze encoder layers till last {unfrozen_layers} layers\n",
    "        for i in range(0, self.base_model.config.num_hidden_layers - unfrozen_layers):\n",
    "            for p in self.base_model.encoder.layer[i].parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        filter_sizes = [3, 4, 5, 6]\n",
    "        self._num_filters = 256\n",
    "        self._max_tokens = 512\n",
    "        self._embed_size = embed_size\n",
    "        self.unfrozen_layers = unfrozen_layers\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv2d(1, self._num_filters, (K, embed_size)),\n",
    "                            nn.BatchNorm2d(self._num_filters),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Flatten(),\n",
    "                            nn.MaxPool1d(self._max_tokens - (K - 1)),\n",
    "                            nn.Flatten(start_dim=1),\n",
    "                        )\n",
    "                        for K in filter_sizes\n",
    "                    ]\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifiers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(\n",
    "                    len(filter_sizes) * self._num_filters + topic_size, output_size\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tok_type, topic_id):\n",
    "        outputs = []\n",
    "\n",
    "        base_out = self.base_model(input_ids=input_ids, token_type_ids=tok_type, attention_mask=attention_mask)\n",
    "        # pooler_out = base_out.last_hidden_state.squeeze(0)\n",
    "        hidden_states = base_out.hidden_states[-self.unfrozen_layers :]\n",
    "\n",
    "        for i in range(self.unfrozen_layers):\n",
    "            batch_size, sequence_length, hidden_size = hidden_states[i].size()\n",
    "            x = [\n",
    "                conv(hidden_states[i].view(batch_size, 1, sequence_length, hidden_size))\n",
    "                for conv in self.conv_blocks[i]\n",
    "            ]\n",
    "            # Concatanating outputs of the conv block of different filter sizes\n",
    "            x = torch.cat(x, dim=1)\n",
    "            x = self.dropout(x)\n",
    "            x = torch.cat([x, topic_id], dim=1)\n",
    "            x = self.classifiers[i](x)\n",
    "\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def tokenizer(self) -> AutoTokenizer:\n",
    "        return self._tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self, weights = None) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = nn.CrossEntropyLoss(weight=weights)\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df_train[\"component\"].unique())\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.bincount(df_train[\"component_id\"])\n",
    "num_samples = sum(class_counts)\n",
    "labels = df_train[\"component_id\"].to_list() # corresponding labels of samples\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "# weights_load_location = f\"/work/disa_lab/projects/triagerx/models/deberta_component_prediction.pt\"\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 1e-5\n",
    "epochs = 25\n",
    "batch_size = 10\n",
    "\n",
    "model = LBTPClassifierTopic(len(df_train.component_id.unique()), topic_size=20, unfrozen_layers=4, dropout=0.2)\n",
    "criterion = CombineLoss(weights=None)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8, weight_decay=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=2, factor=0.1, threshold=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best checkpoint\n",
    "weights_load_location = f\"/work/disa_lab/projects/triagerx/models/deberta_component_prediction_chrono_10class.pt\"\n",
    "model.load_state_dict(torch.load(weights_load_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 19:13:11.791\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-04-21 19:13:11.793\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare torch dataset from train and validation splits\n",
    "test = TriageDataset(df_test, model.tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 19:13:12.514\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mSelected compute device: cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.debug(f\"Selected compute device: {device}\")\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_val = 0\n",
    "total_loss_val = 0\n",
    "correct_top_k = 0\n",
    "correct_top_k_wo_sim = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "topk_preds = []\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for val_input, val_label in test_dataloader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input[1][\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = val_input[1][\"input_ids\"].squeeze(1).to(device)\n",
    "        tok_type = val_input[1][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        repr = val_input[2].to(device)\n",
    "\n",
    "        output = model(input_id, mask, tok_type, repr)\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "\n",
    "        #wo similarity\n",
    "        _, top_k_wo_sim = output.topk(3, 1, True, True)\n",
    "\n",
    "        topk_preds.append(top_k_wo_sim.cpu().numpy())\n",
    "        top_k_wo_sim = top_k_wo_sim.t()\n",
    "        \n",
    "\n",
    "        correct_top_k_wo_sim += (\n",
    "            top_k_wo_sim.eq(\n",
    "                val_label.view(1, -1).expand_as(top_k_wo_sim)\n",
    "            )\n",
    "            .sum()\n",
    "            .item()\n",
    "        )\n",
    "\n",
    "\n",
    "        all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.append(val_label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_preds = np.concatenate(topk_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_cat = np.concatenate(all_preds)\n",
    "all_labels_cat = np.concatenate(all_labels)\n",
    "\n",
    "accuracy = np.mean(all_preds_cat == all_labels_cat)\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "    all_labels_cat, all_preds_cat, average=\"macro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75, Precision: 0.5888617891563539, Recall: 0.536684369082686, F1: 0.5378976175501237\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction without Similarity: 292, 0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct Prediction without Similarity: {correct_top_k_wo_sim}, {correct_top_k_wo_sim / len(df_test)}\")\n",
    "# print(f\"Correct Prediction with Similarity: {correct_top_k}, {correct_top_k / len(y_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {idx: label for idx, label in enumerate(label2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings for all train data\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "all_embeddings = similarity_model.encode(df_train.text.to_list(), batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_similar_issues(issues, k=5, threshold=0.5):\n",
    "    test_embed = similarity_model.encode(issues)\n",
    "    cos = util.cos_sim(test_embed, all_embeddings)\n",
    "    topk_values, topk_indices = torch.topk(cos, k=k)\n",
    "    topk_values = topk_values.cpu().numpy()[0]\n",
    "    topk_indices = topk_indices.cpu().numpy()[0]\n",
    "    \n",
    "    similar_issues = []\n",
    "    \n",
    "    for idx, sim_score in zip(topk_indices, topk_values):\n",
    "        if sim_score >= threshold:\n",
    "            similar_issues.append([idx, sim_score])\n",
    "\n",
    "    return similar_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_predictions = [\n",
    "    get_top_k_similar_issues(issue.text, k=3)\n",
    "    for _, issue in df_test.iterrows() \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dir = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/openj9/issue_data\"\n",
    "all_issues = os.listdir(issues_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_users = ['pshipton', 'keithc-ca', 'gacholio', 'tajila', 'babsingh', 'JasonFengJ9', 'fengxue-IS', 'hangshao0', 'theresa.t.mammarella', 'ChengJin01', 'singh264', 'thallium', 'ThanHenderson']\n",
    "jvmti_users = ['gacholio', 'tajila', 'babsingh', 'fengxue-IS']\n",
    "jclextensions_users = ['JasonFengJ9', 'pshipton', 'keithc-ca']\n",
    "test_users = ['LongyuZhang', 'annaibm', 'sophiaxu0424', 'KapilPowar', 'llxia']\n",
    "build_users = ['adambrousseau', 'mahdipub']\n",
    "gc_users = ['dmitripivkine', 'amicic', 'kangyining', 'LinHu2016']\n",
    "\n",
    "# Putting them in dictionaries\n",
    "components = {\n",
    "    'comp:vm': vm_users,\n",
    "    'comp:jvmti': jvmti_users,\n",
    "    'comp:jclextensions': jclextensions_users,\n",
    "    'comp:test': test_users,\n",
    "    'comp:build': build_users,\n",
    "    'comp:gc': gc_users\n",
    "}\n",
    "\n",
    "expected_users = [user for user_list in components.values() for user in user_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contribution_data(issue_number):\n",
    "    contributions = {}\n",
    "    issue_file = f\"{issue_number}.json\"\n",
    "    \n",
    "    if issue_file in all_issues:\n",
    "        with open(os.path.join(issues_dir, issue_file), \"r\") as file:\n",
    "            issue = json.load(file)      \n",
    "\n",
    "            assignees = issue[\"assignees\"]\n",
    "            assignee_logins = (\n",
    "                [assignee[\"login\"] for assignee in assignees] if len(assignees) > 0 else []\n",
    "            )\n",
    "\n",
    "            contributions[\"direct_assignment\"] = assignee_logins\n",
    "\n",
    "            timeline = issue[\"timeline_data\"]\n",
    "            pull_requests = []\n",
    "            commits = []\n",
    "            discussion = []\n",
    "\n",
    "            for timeline_event in timeline:\n",
    "                event = timeline_event[\"event\"]\n",
    "\n",
    "                if event == \"cross-referenced\" and timeline_event[\"source\"][\"issue\"].get(\"pull_request\", None):\n",
    "                    actor = timeline_event[\"actor\"][\"login\"]\n",
    "                    pull_requests.append(actor)\n",
    "\n",
    "                if event == \"referenced\" and timeline_event[\"commit_url\"]:\n",
    "                    actor = timeline_event[\"actor\"][\"login\"]\n",
    "                    commits.append(actor)\n",
    "\n",
    "                if event == \"commented\":\n",
    "                    actor = timeline_event[\"actor\"][\"login\"]\n",
    "                    discussion.append(actor)\n",
    "            \n",
    "            contributions[\"direct_assignment\"] = assignee_logins\n",
    "            contributions[\"pull_request\"] = pull_requests\n",
    "            contributions[\"commits\"] = commits\n",
    "            contributions[\"discussion\"] = discussion\n",
    "\n",
    "    return contributions\n",
    "         \n",
    "\n",
    "\n",
    "def get_historical_contributors(similar_issues, predicted_component_ids):\n",
    "    user_contribution_counts = {}\n",
    "    base_points = 1\n",
    "\n",
    "    for issue_index, sim_score in similar_issues:\n",
    "        print(base_points)\n",
    "        issue = df_train.iloc[issue_index]\n",
    "\n",
    "        print(f\"Issue label: {label2idx[issue.component]} -- Predicted: {predicted_component_ids}\")\n",
    "\n",
    "        if label2idx[issue.component] not in predicted_component_ids:\n",
    "            print(f\"Skipping issue as label id {label2idx[issue.component]} did not match with any of {predicted_component_ids}\")\n",
    "            continue\n",
    "\n",
    "        issue_number = issue.issue_number\n",
    "        contributors = get_contribution_data(issue_number)\n",
    "\n",
    "        for _, users in contributors.items():\n",
    "            for user in users:\n",
    "                if user not in expected_users:\n",
    "                    print(f\"Skipping: {user}\")\n",
    "                    continue            \n",
    "                \n",
    "                if user in components[issue.component]:\n",
    "                    user_contribution_counts[user] = user_contribution_counts.get(user, 0) + base_points * 1.25\n",
    "                else:\n",
    "                    user_contribution_counts[user] = user_contribution_counts.get(user, 0) + base_points\n",
    "        \n",
    "        base_points /= 2.0\n",
    "    \n",
    "    user_contribution_counts = sorted(user_contribution_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(user_contribution_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real label: comp:jvmti\n",
      "Predicted labels: ['comp:vm', 'comp:gc', 'comp:jvmti']\n",
      "[[255, 0.71805286], [2073, 0.69125384], [2081, 0.6891853]]\n",
      "Issue number: 17520\n",
      "Component: comp:jvmti\n",
      "1\n",
      "Issue label: 2 -- Predicted: [2 3 5]\n",
      "0.5\n",
      "Issue label: 2 -- Predicted: [2 3 5]\n",
      "Skipping: dipak-bagadiya\n",
      "0.25\n",
      "Issue label: 2 -- Predicted: [2 3 5]\n",
      "[('babsingh', 16.875), ('pshipton', 3.125), ('fengxue-IS', 1.5625), ('gacholio', 1.25), ('thallium', 0.3125), ('tajila', 0.3125)]\n"
     ]
    }
   ],
   "source": [
    "test_idx = 176\n",
    "historical_data = similarity_predictions[test_idx]\n",
    "predicted_labels = topk_preds[test_idx]\n",
    "print(f\"Real label: {df_test.iloc[test_idx].component}\")\n",
    "print(f\"Predicted labels: {[idx2label[pred] for pred in predicted_labels]}\")\n",
    "print(historical_data)\n",
    "print(\"Issue number:\", df_test.iloc[test_idx].issue_number)\n",
    "print(\"Component:\", df_test.iloc[test_idx].component)\n",
    "get_historical_contributors(historical_data, predicted_labels)\n",
    "# print(df_train.iloc[historical_data])\n",
    "\n",
    "# print(df_test.iloc[test_idx])\n",
    "# print(all_labels_cat[test_idx])\n",
    "# print(all_preds_cat[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_preds_cat == all_labels_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_issues = get_top_k_similar_issues(df_test.iloc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1220, 0.94563663],\n",
       " [1899, 0.9409791],\n",
       " [2083, 0.91344625],\n",
       " [1610, 0.9121801],\n",
       " [544, 0.9099889]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                                                14391\n",
       "Unnamed: 0                                                     90\n",
       "issue_number                                                14396\n",
       "issue_url       https://github.com/eclipse-openj9/openj9/issue...\n",
       "issue_title     testSoftMxDisclaimMemory_GC_3_FAILED : Segment...\n",
       "description     Failure link\\r\\n------------\\r\\n\\r\\nFrom an in...\n",
       "issue_state                                                closed\n",
       "creator                                               JasonFengJ9\n",
       "comments        <comment><user>dmitripivkine</user><body>This ...\n",
       "owner                                                         NaN\n",
       "labels                      comp:gc, test failure, blocker, jdk18\n",
       "topic_id                                                       18\n",
       "topic_label                               Java Crashes and Errors\n",
       "component                                                 comp:gc\n",
       "text            Title: testSoftMxDisclaimMemory_GC_3_FAILED : ...\n",
       "topic_hot       [False, False, False, False, False, False, Fal...\n",
       "component_id                                                    3\n",
       "Name: 14391, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                                                16586\n",
       "Unnamed: 0                                                     95\n",
       "issue_number                                                16593\n",
       "issue_url       https://github.com/eclipse-openj9/openj9/issue...\n",
       "issue_title     JDK19 serviceability_jvmti_j9_1_FAILED Segment...\n",
       "description     Failure link\\r\\n------------\\r\\n\\r\\nFrom [an i...\n",
       "issue_state                                                closed\n",
       "creator                                               JasonFengJ9\n",
       "comments        <comment><user>pshipton</user><body>@JasonFeng...\n",
       "owner                                                    babsingh\n",
       "labels                 comp:vm, comp:gc, test failure, os:windows\n",
       "topic_id                                                       18\n",
       "topic_label                               Java Crashes and Errors\n",
       "component                                                 comp:vm\n",
       "text            Title: JDK19 serviceability_jvmti_j9_1_FAILED ...\n",
       "topic_hot       [False, False, False, False, False, False, Fal...\n",
       "component_id                                                    2\n",
       "Name: 16586, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_filtered = df_test[df_test[\"owner\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_filtered = df_val[df_val[\"owner\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component\n",
       "comp:vm           46\n",
       "comp:jit          26\n",
       "comp:test          8\n",
       "comp:build         6\n",
       "comp:jitserver     5\n",
       "comp:infra         5\n",
       "comp:gc            3\n",
       "comp:doc           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered.component.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11139"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered.iloc[0][\"issue_number\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
