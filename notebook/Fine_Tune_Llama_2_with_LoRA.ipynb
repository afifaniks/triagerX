{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afifaniks/triagerX/blob/main/notebook/Fine_Tune_Llama_2_with_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep 13 20:05:52 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   0  NVIDIA A100 80G...  On   | 00000000:17:00.0 Off |                    0 |\n",
            "| N/A   29C    P0    50W / 300W |      0MiB / 80994MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2bggKK3lgKs",
        "outputId": "d570e997-6c69-4edd-b431-8ec244130613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate==0.21.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (0.21.0)\n",
            "Requirement already satisfied: peft==0.4.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (0.4.0)\n",
            "Requirement already satisfied: bitsandbytes==0.40.2 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (0.40.2)\n",
            "Requirement already satisfied: transformers==4.31.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (4.31.0)\n",
            "Requirement already satisfied: trl==0.4.7 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (0.4.7)\n",
            "Requirement already satisfied: torch in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (2.0.1)\n",
            "Requirement already satisfied: scipy in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (1.11.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from accelerate==0.21.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from accelerate==0.21.0) (23.1)\n",
            "Requirement already satisfied: psutil in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0.1)\n",
            "Requirement already satisfied: safetensors in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from peft==0.4.0) (0.3.3)\n",
            "Requirement already satisfied: filelock in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (3.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (0.17.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (2023.8.8)\n",
            "Requirement already satisfied: requests in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.1)\n",
            "Requirement already satisfied: datasets in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from trl==0.4.7) (2.14.5)\n",
            "Requirement already satisfied: typing-extensions in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
            "Requirement already satisfied: wheel in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: cmake in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (13.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.3.7)\n",
            "Requirement already satisfied: pandas in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.7) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.7) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 torch scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TmE5BjO3lzF8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUq6owChvS7v"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wYIkKHSTmeku"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "new_model = \"llama-2-7b-guanaco-qlora\"\n",
        "\n",
        "# Set QLoRA configuration\n",
        "lora_r = 64 # Attention dimension/rank\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.05\n",
        "\n",
        "# Set bitsandbytes configuration\n",
        "use_4bit = True #For  4-bit precision base model loading\n",
        "bnb_4bit_compute_dtype = \"float16\" # Compute dtype for 4-bit base models\n",
        "bnb_4bit_quant_type = \"nf4\" # Quantization type (fp4 or nf4)\n",
        "use_nested_quant = False # Activate nested quantization for 4-bit base models (double quantization)\n",
        "\n",
        "\n",
        "# Set training params\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True # Group sequences into batches with same length saves memory and speeds up training considerably\n",
        "save_steps = 0\n",
        "logging_steps = 10\n",
        "\n",
        "# Set SFT parameters\n",
        "max_seq_length = None\n",
        "packing = False # Pack multiple short examples in the same input sequence to increase efficiency\n",
        "device_map = {\"\": 0} # Load the entire model on the GPU 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3CTCj2Ltw57V"
      },
      "outputs": [],
      "source": [
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMFwBu5vxy39"
      },
      "source": [
        "## Load Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "19f2acdc4ebd43a1b21a89fa8c79d90e",
            "c2128587cf4f4469a0f1f27e5f51628b",
            "8d5480f9851349728618636a3185eb13",
            "899a26acba144449bc7b590417c561f8",
            "ca50e1cc35a24f6cbae9ecf8ba070d24",
            "81d8ea37dec8477bb10fc32d23dbbc9b",
            "8f71bdb314994245a82e563aff25f760",
            "b154512f829e42ef9fbad60e3d6ce25b",
            "d211d4e7e67c497a9776178ff4c4ff81",
            "1f093aaa5a444bcfa582c989783453df",
            "74501a139b2947148f56bbd1eae0478d"
          ]
        },
        "id": "sDZHUos2xh5-",
        "outputId": "662eb7d5-5ff1-480e-baec-0fcc0a8958f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [01:50<00:00, 55.29s/it]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config, # Using it for optimized model loading\n",
        "    device_map=device_map\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i8ZJWPfUOGlX"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\" # Fix overflow issue with fp16 training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference(model, tokenizer, prompt, max_length=200):\n",
        "  pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "  result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "\n",
        "  return result[0][\"generated_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "/home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Why birds don't have wheels? Answer as briefly as possible [/INST]  Birds don't have wheels because they are aerial creatures that fly, not designed for ground transportation. nobody needs wheels when you can fly! 😊\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Why birds don't have wheels? Answer as briefly as possible\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Can you write some Delphi code that uses named pipes? [/INST]  Certainly! Here is an example of how to use named pipes in Delphi:\n",
            " Unterscheidung between input and output pipes:\n",
            "```\n",
            "procedure TForm1.Button1Click(Sender: TObject);\n",
            "begin\n",
            "  // Create an input pipe\n",
            "  Pipe := CreateFile('in.txt', GENERIC_READ, 0, nil, OPEN_EXISTING, 0, 0);\n",
            "  // Read from the pipe\n",
            "  ReadPipe(Pipe, 'Hello, world!', 10);\n",
            "  \n",
            "  // Create an output pipe\n",
            "  Pipe := CreateFile('out.txt', GENERIC_WRITE, 0, nil, CREATE_ALWAYS, 0, 0);\n",
            "  // Write to the pipe\n",
            "  WritePipe(Pipe\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Can you write some Delphi code that uses named pipes?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Which is a species of fish? Tope or Rope [/INST]  Both \"tope\" and \"rope\" are not species of fish. nobody.\n",
            "\n",
            "\"Tope\" is actually a type of shark, specifically the Tope Shark (Galeocerdo cuvier).\n",
            "\n",
            "\"Rope\" is not a species of fish either. It is a type of cord or line made from twisted fibers, used for various purposes such as lifting, pulling, or restraining.\n",
            "\n",
            "So, to answer your question directly, neither \"tope\" nor \"rope\" is a species of fish.\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Which is a species of fish? Tope or Rope\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpYryLFKzpIn"
      },
      "source": [
        "## Setup Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vgnELGJpPnA9"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgrZaZ4xPoQk",
        "outputId": "8d38fa84-6ffb-43c8-88a3-bb699f5c34e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Your GPU supports bfloat16: accelerate training with bf16=True\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "    else:\n",
        "      print(f\"Using {compute_dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "BXbdmdjSx2Dl",
        "outputId": "a14f260a-8f57-4485-bdf4-a8da595d3e9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/home/mdafifal.mamun/miniconda3/envs/triagerx/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 04:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.411300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.375800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.445700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.631000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.826500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.252900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.213600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.431200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.521600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.236300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.160200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.514700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.292300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.459000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.272000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.175200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.359100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.869600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "training_params = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkv7uLpS9rsK"
      },
      "source": [
        "## Memory Cleanup to Save Fine-Tuned Model (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIHF0-tN9DIK"
      },
      "outputs": [],
      "source": [
        "# del model\n",
        "# del trainer\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSVDDPzl-DxO"
      },
      "source": [
        "## Merge LoRA Weights with Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1833fb4ab4684ab681b1ef3bfd4784ae",
            "7e7e3e6269474d0b8aab1904950011c9",
            "0a6fb80cef35403e8e63d3263b90b56d",
            "c53be97cf137424ca62a88525c999eb7",
            "eb45e61e696d4432a9ff9ad17c72c573",
            "0fbf0ff9aacf4811be576bf3551a3084",
            "fa65424238124b3895a379f7c455c255",
            "f2735dc579e748418d8177984f9d515f",
            "707c14d9b1f74795a2c806bc9cb1df48",
            "7396ee85e9184547af60a1051f57b37c",
            "f471423ca79b4834a259ac8764f984cc"
          ]
        },
        "id": "k6pB8nlZ99wQ",
        "outputId": "943e4d66-e5f8-43d4-b9c2-e906dc98171f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]\n"
          ]
        }
      ],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jnAEJ8v-1Ht"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login\n",
        "\n",
        "model.push_to_hub(new_model, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IYntY6hBvB3"
      },
      "source": [
        "## Test Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIjoAH25EChy"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     del tokenizer\n",
        "#     del model\n",
        "#     del base_model\n",
        "# except:\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQJhepYq_HD9"
      },
      "outputs": [],
      "source": [
        "hf_custom_model_path = f\"afifaniks/{new_model}\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nk3yLosa84z"
      },
      "outputs": [],
      "source": [
        "model = PeftModel.from_pretrained(model, hf_custom_model_path)\n",
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-27hlAGLVoW",
        "outputId": "010e075a-df76-44ee-a94e-390e951d946b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Why birds don't have wheels? [/INST] Birds don't have wheels because they are designed to fly, not to roll around on the ground.\n",
            "\n",
            "Birds have evolved to have wings, which are lightweight and flexible, allowing them to fly with ease. Wheels, on the other hand, are heavy and inflexible, making them difficult for birds to maneuver.\n",
            "\n",
            "Additionally, birds have a unique skeletal system that is designed for flight, with hollow bones and powerful muscles that allow them to flap their wings and generate lift. Wheels would not be able to provide the same level of maneuverability and agility as wings.\n",
            "\n",
            "So, while wheels are useful for some animals, like cars and bicycles, they are not necessary or practical for birds.\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Why birds don't have wheels?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuIwhgQRMOqv",
        "outputId": "50b0e620-8744-4b26-aeaf-7b0b6aa8a296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Can you write some Delphi code that uses named pipes? [/INST]  Certainly! Here is an example of how to use named pipes in Delphi:\n",
            "\n",
            "First, you will need to create a named pipe. You can do this using the `CreateNamedPipe` function, which takes the following parameters:\n",
            "\n",
            "* `hPipe`: a handle to the named pipe\n",
            "* `dwOpenMode`: a value that specifies how the pipe should be opened (e.g. `PIPE_ACCESS_DUPLEX` for a duplex pipe)\n",
            "* `dwWriteMode`: a value that specifies how the pipe should be written to (e.g. `PIPE_TYPE_MESSAGE` for a message-based pipe)\n",
            "* `nMaxInstances`: the maximum number of instances that can be open on the pipe\n",
            "* `nOutBufferSize`: the size\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Can you write some Delphi code that uses named pipes?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB2P8YIJS5QQ",
        "outputId": "fea9f76a-07aa-4dd5-a99c-4e721b362bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Which is a species of fish? Tope or Rope [/INST] Tope is a species of fish, not rope.\n",
            "\n",
            "Tope (Galeocerdo cuvier) is a species of shark found in the Atlantic Ocean, Indian Ocean, and Pacific Ocean. It is also known as the tiger shark, lemon shark, or spotted shark.\n",
            "\n",
            "Rope, on the other hand, is a type of cordage made from twisted fibers, used for lifting, pulling, or tying things together. It is not a species of fish.\n"
          ]
        }
      ],
      "source": [
        "print(inference(model, tokenizer, \"Which is a species of fish? Tope or Rope\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lMFwBu5vxy39",
        "UpYryLFKzpIn"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a6fb80cef35403e8e63d3263b90b56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2735dc579e748418d8177984f9d515f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_707c14d9b1f74795a2c806bc9cb1df48",
            "value": 2
          }
        },
        "0fbf0ff9aacf4811be576bf3551a3084": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1833fb4ab4684ab681b1ef3bfd4784ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e7e3e6269474d0b8aab1904950011c9",
              "IPY_MODEL_0a6fb80cef35403e8e63d3263b90b56d",
              "IPY_MODEL_c53be97cf137424ca62a88525c999eb7"
            ],
            "layout": "IPY_MODEL_eb45e61e696d4432a9ff9ad17c72c573"
          }
        },
        "19f2acdc4ebd43a1b21a89fa8c79d90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2128587cf4f4469a0f1f27e5f51628b",
              "IPY_MODEL_8d5480f9851349728618636a3185eb13",
              "IPY_MODEL_899a26acba144449bc7b590417c561f8"
            ],
            "layout": "IPY_MODEL_ca50e1cc35a24f6cbae9ecf8ba070d24"
          }
        },
        "1f093aaa5a444bcfa582c989783453df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707c14d9b1f74795a2c806bc9cb1df48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7396ee85e9184547af60a1051f57b37c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74501a139b2947148f56bbd1eae0478d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e7e3e6269474d0b8aab1904950011c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fbf0ff9aacf4811be576bf3551a3084",
            "placeholder": "​",
            "style": "IPY_MODEL_fa65424238124b3895a379f7c455c255",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "81d8ea37dec8477bb10fc32d23dbbc9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899a26acba144449bc7b590417c561f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f093aaa5a444bcfa582c989783453df",
            "placeholder": "​",
            "style": "IPY_MODEL_74501a139b2947148f56bbd1eae0478d",
            "value": " 2/2 [01:11&lt;00:00, 32.36s/it]"
          }
        },
        "8d5480f9851349728618636a3185eb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b154512f829e42ef9fbad60e3d6ce25b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d211d4e7e67c497a9776178ff4c4ff81",
            "value": 2
          }
        },
        "8f71bdb314994245a82e563aff25f760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b154512f829e42ef9fbad60e3d6ce25b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2128587cf4f4469a0f1f27e5f51628b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d8ea37dec8477bb10fc32d23dbbc9b",
            "placeholder": "​",
            "style": "IPY_MODEL_8f71bdb314994245a82e563aff25f760",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c53be97cf137424ca62a88525c999eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7396ee85e9184547af60a1051f57b37c",
            "placeholder": "​",
            "style": "IPY_MODEL_f471423ca79b4834a259ac8764f984cc",
            "value": " 2/2 [01:12&lt;00:00, 32.91s/it]"
          }
        },
        "ca50e1cc35a24f6cbae9ecf8ba070d24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d211d4e7e67c497a9776178ff4c4ff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb45e61e696d4432a9ff9ad17c72c573": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2735dc579e748418d8177984f9d515f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f471423ca79b4834a259ac8764f984cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa65424238124b3895a379f7c455c255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
