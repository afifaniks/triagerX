{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/deeptriage/gc_20.json\"\n",
    "\n",
    "df = pd.read_json(dataset_path)\n",
    "df = df[df[\"owner\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amit@chromium.org</td>\n",
       "      <td>Scrolling with some scroll mice (touchpad, etc...</td>\n",
       "      <td>\\nProduct Version      : &lt;see about:version&gt;\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Proxy causes some or all network requests to fail</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfeldman@chromium.org</td>\n",
       "      <td>Web inspector button \"dock to main window\" doe...</td>\n",
       "      <td>\\nProduct Version      : chrome beta 1\\r\\nURLs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Habari admin interface is not rendered correctly</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkasting@chromium.org</td>\n",
       "      <td>Maximize on second larger monitor not working</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27\\r\\nURLs (i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   owner                                        issue_title  \\\n",
       "0      amit@chromium.org  Scrolling with some scroll mice (touchpad, etc...   \n",
       "1       jon@chromium.org  Proxy causes some or all network requests to fail   \n",
       "2  pfeldman@chromium.org  Web inspector button \"dock to main window\" doe...   \n",
       "3       jon@chromium.org   Habari admin interface is not rendered correctly   \n",
       "4  pkasting@chromium.org      Maximize on second larger monitor not working   \n",
       "\n",
       "                                         description  \n",
       "0  \\nProduct Version      : <see about:version>\\r...  \n",
       "1  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...  \n",
       "2  \\nProduct Version      : chrome beta 1\\r\\nURLs...  \n",
       "3  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...  \n",
       "4  \\nProduct Version      : 0.2.149.27\\r\\nURLs (i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109979"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per block: 10998\n"
     ]
    }
   ],
   "source": [
    "num_cv = 10\n",
    "sample_threshold=20\n",
    "samples_per_block = len(df) // num_cv + 1\n",
    "print(f\"Samples per block: {samples_per_block}\")\n",
    "\n",
    "block = 5\n",
    "X_df = df[:samples_per_block*block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54990"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "developers = X_df[\"owner\"].value_counts()\n",
    "filtered_developers = developers.index[developers >= sample_threshold]\n",
    "X_df = X_df[X_df[\"owner\"].isin(filtered_developers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total developers: 629\n"
     ]
    }
   ],
   "source": [
    "num_developers = len(X_df[\"owner\"].unique())\n",
    "print(f\"Total developers: {num_developers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of words in a summary'}, xlabel='issue_title'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHLCAYAAAAqWYniAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWE0lEQVR4nO3deVxU1f8/8NcMO+KwKVsikJriTpgEopKiqJRiai4oVrhLhpYpfQyXLHfT1DStXErLJTWXMkkyMBGRJHczRSUNrFRQVFB4f//wx/05MqBsItfX8/G4jwdzzzn3nHtne3HunRmNiAiIiIiIVEZb2QMgIiIiqggMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5RI/Q7t27odFosGHDhsoeykPJyMhAz549YW9vD41Gg3nz5lX2kB5aQEAAAgICyryds2fPQqPRYMWKFWXeFhE9Wgw5pDorVqyARqOBubk5Lly4UKg8ICAAjRs3roSRVT2jR4/Gjz/+iKioKHz55Zfo1KlTZQ+JiOihGVf2AIgqSk5ODqZPn44FCxZU9lCqrNjYWHTr1g1vv/12ZQ+l0ri5ueHmzZswMTGp7KEQUQlxJodUq3nz5li2bBkuXrxY2UN55LKzs8tlO5cuXYKNjU25bKu8ldc+PkjBrKCRkdEj6Y8e3qN6DFDVxZBDqvXuu+8iLy8P06dPL7ZecddcaDQaTJo0Sbk9adIkaDQa/PHHH+jfvz+sra1Rs2ZNvPfeexARpKWloVu3btDpdHBycsKcOXMM9pmXl4d3330XTk5OqFatGrp27Yq0tLRC9RITE9GpUydYW1vD0tISbdu2xa+//qpXp2BMx44dQ79+/WBrawt/f/9i9/nMmTPo1asX7OzsYGlpieeffx7bt29XygtO+YkIFi1aBI1GA41GU+T2nn32Wbz88st665o0aQKNRoNDhw4p69auXQuNRoPjx48r6w4ePIjOnTtDp9PBysoK7du3x759+/S2VTCeX375BSNGjICDgwNq1aqllC9duhR16tSBhYUFWrZsifj4eIPjXLBgARo1agRLS0vY2tqiRYsWWLNmTbHHytDj49VXX4WVlRUuXLiAkJAQWFlZoWbNmnj77beRl5dX7PYA4LvvvkNwcDBcXFxgZmaGOnXq4P3333+otteuXUNkZCTc3d1hZmYGBwcHdOjQAb/99ptSx93dHa+++mqhtvdfp1Rwjdi6deswefJkPPXUU6hevTp69uyJzMxM5OTkIDIyEg4ODrCyssJrr72GnJwcvW1qNBpERERg/fr1aNiwISwsLODr64vDhw8DAD799FPUrVsX5ubmCAgIwNmzZ/Xax8fHo1evXqhduzbMzMzg6uqK0aNH4+bNm3r1Co756dOn0aVLF1SvXh2hoaGYOHEiTExM8M8//xTa3yFDhsDGxga3bt164HEldeLpKlItDw8PhIWFYdmyZRg/fjxcXFzKbdu9e/eGp6cnpk+fju3bt2Pq1Kmws7PDp59+inbt2mHGjBlYvXo13n77bTz33HNo06aNXvsPPvgAGo0G48aNw6VLlzBv3jwEBgYiJSUFFhYWAO6eKurcuTO8vb0xceJEaLVaLF++HO3atUN8fDxatmypt81evXqhXr16+PDDDyEiRY49IyMDfn5+uHHjBkaNGgV7e3usXLkSXbt2xYYNG9C9e3e0adMGX375JQYMGIAOHTogLCys2OPRunVrfP3118rty5cv4+jRo9BqtYiPj0fTpk0B3H1Dq1mzJjw9PQEAR48eRevWraHT6fDOO+/AxMQEn376KQICAvDLL7/Ax8dHr58RI0agZs2aiI6OVv6L//zzzzF06FD4+fkhMjISZ86cQdeuXWFnZwdXV1el7bJlyzBq1Cj07NkTb775Jm7duoVDhw4hMTER/fr1K3b/DMnLy0NQUBB8fHwwe/Zs/PTTT5gzZw7q1KmD4cOHF9t2xYoVsLKywpgxY2BlZYXY2FhER0cjKysLs2bNKrbtsGHDsGHDBkRERKBhw4b477//sGfPHhw/fhzPPvtsifcDAKZNmwYLCwuMHz8ef/75JxYsWAATExNotVpcuXIFkyZNwr59+7BixQp4eHggOjpar318fDy2bNmCkSNHKtt78cUX8c477+CTTz7BiBEjcOXKFcycOROvv/46YmNjlbbr16/HjRs3MHz4cNjb22P//v1YsGAB/vrrL6xfv16vnzt37iAoKAj+/v6YPXs2LC0t4evriylTpmDt2rWIiIhQ6ubm5mLDhg3o0aMHzM3NS3VcSAWESGWWL18uACQpKUlOnz4txsbGMmrUKKW8bdu20qhRI+V2amqqAJDly5cX2hYAmThxonJ74sSJAkCGDBmirLtz547UqlVLNBqNTJ8+XVl/5coVsbCwkIEDByrrfv75ZwEgTz31lGRlZSnr161bJwBk/vz5IiKSn58v9erVk6CgIMnPz1fq3bhxQzw8PKRDhw6FxtS3b9+HOj6RkZECQOLj45V1165dEw8PD3F3d5e8vDy9/R85cuQDt7l+/XoBIMeOHRMRkS1btoiZmZl07dpVevfurdRr2rSpdO/eXbkdEhIipqamcvr0aWXdxYsXpXr16tKmTRtlXcF96u/vL3fu3FHW5+bmioODgzRv3lxycnKU9UuXLhUA0rZtW2Vdt27d9O73h2Xo8TFw4EABIFOmTNGr6+XlJd7e3g/c5o0bNwqtGzp0qFhaWsqtW7eKbWttbf3A+8TNzU3vcVegbdu2esek4PHYuHFjyc3NVdb37dtXNBqNdO7cWa+9r6+vuLm56a0DIGZmZpKamqqs+/TTTwWAODk56T3Oo6KiBIBeXUPHYtq0aaLRaOTcuXPKuoJjPn78+EL1fX19xcfHR2/dxo0bBYD8/PPPherTk4Onq0jVnn76aQwYMABLly7F33//XW7bHTRokPK3kZERWrRoARFBeHi4st7Gxgb169fHmTNnCrUPCwtD9erVlds9e/aEs7Mzvv/+ewBASkoKTp06hX79+uG///7Dv//+i3///RfZ2dlo37494uLikJ+fr7fNYcOGPdTYv//+e7Rs2VLvlJaVlRWGDBmCs2fP4tixYw93EO7RunVrAEBcXByAu//ZP/fcc+jQoYNy6ujq1as4cuSIUjcvLw87d+5ESEgInn76aWVbzs7O6NevH/bs2YOsrCy9fgYPHqx3bcyBAwdw6dIlDBs2DKampsr6V199FdbW1nptbWxs8NdffyEpKanE+1eU+49569atDd7f9yuYrQPunn76999/0bp1a9y4cQMnTpwotq2NjQ0SExPL9VqzsLAwvQurfXx8ICJ4/fXX9er5+PggLS0Nd+7c0Vvfvn17uLu769UDgB49eug9zgvW33uM7j0W2dnZ+Pfff+Hn5wcRwcGDBwuN1dAsWVhYGBITE3H69Gll3erVq+Hq6oq2bdsWu++kbgw5pHoTJkzAnTt3HnhtTknUrl1b77a1tTXMzc1Ro0aNQuuvXLlSqH29evX0bms0GtStW1e5XuHUqVMAgIEDB6JmzZp6y2effYacnBxkZmbqbcPDw+Ohxn7u3DnUr1+/0PqCU0jnzp17qO3cy9HREfXq1VMCTXx8PFq3bo02bdrg4sWLOHPmDH799Vfk5+crIeeff/7BjRs3ihxLfn5+oeuU7t/HgrHefzxNTEz0ghMAjBs3DlZWVmjZsiXq1auHkSNHFrq+qSTMzc1Rs2ZNvXW2trYG7+/7HT16FN27d4e1tTV0Oh1q1qyJ/v37A0Ch+/V+M2fOxJEjR+Dq6oqWLVti0qRJDxWsimPo8QxA73Rfwfr8/PxCYyxJewB6x+j8+fN49dVXYWdnp1zbVBBM7u/H2NhY71qsAr1794aZmRlWr16ttNu2bRtCQ0OLvZaM1I8hh1Tv6aefRv/+/YuczSnqRbC4i0ANfdKmqE/fSDHXxxSlYJZm1qxZiImJMbhYWVnptbn3P+LK4O/vj/j4eNy8eRPJyclo3bo1GjduDBsbG8THxyM+Ph5WVlbw8vIqdR9l2UdPT0+cPHkS33zzDfz9/fHtt9/C398fEydOLNX2Svtpq6tXr6Jt27b4/fffMWXKFGzduhUxMTGYMWMGABSaobvfK6+8gjNnzmDBggVwcXHBrFmz0KhRI/zwww9KnZI+poval4d9TJe2fV5eHjp06IDt27dj3Lhx2Lx5M2JiYpSLvO8/FmZmZtBqC79t2dra4sUXX1RCzoYNG5CTk6MER3py8cJjeiJMmDABX331lfJGci9bW1sAd9987lWaGY2HVTBTU0BE8OeffyoX6NapUwcAoNPpEBgYWK59u7m54eTJk4XWF5wmcXNzK9V2W7dujeXLl+Obb75BXl4e/Pz8oNVqlfBz/Phx+Pn5KW98NWvWhKWlZZFj0Wq1hWYCDO0LcPd4tmvXTll/+/ZtpKamolmzZnr1q1Wrht69e6N3797Izc3Fyy+/jA8++ABRUVGP7OLU3bt347///sPGjRv1LkhPTU196G04OztjxIgRGDFiBC5duoRnn30WH3zwATp37gzg7mP6/sczcPcxff8MV2U6fPgw/vjjD6xcuVLv4vaYmJgSbyssLAzdunVDUlISVq9eDS8vLzRq1Kg8h0tVEGdy6IlQp04d9O/fH59++inS09P1ynQ6HWrUqKFcT1Lgk08+qbDxrFq1CteuXVNub9iwAX///bfyJuXt7Y06depg9uzZuH79eqH2hj4u+7C6dOmC/fv3IyEhQVmXnZ2NpUuXwt3dHQ0bNizVdgtOQ82YMQNNmzZVTk20bt0au3btwoEDB5Q6wN3/8jt27IjvvvtO72PFGRkZWLNmDfz9/aHT6Yrts0WLFqhZsyaWLFmC3NxcZf2KFSsKvcn/999/erdNTU3RsGFDiAhu375dml0ulYKQd+9sSG5u7kM93vLy8gqdwnFwcICLi4veR7vr1KmDffv26R2Tbdu2Gfyagspk6FiICObPn1/ibXXu3Bk1atTAjBkz8Msvv3AWhwBwJoeeIP/73//w5Zdf4uTJk4X+wxs0aBCmT5+OQYMGoUWLFoiLi8Mff/xRYWOxs7ODv78/XnvtNWRkZGDevHmoW7cuBg8eDADQarX47LPP0LlzZzRq1AivvfYannrqKVy4cAE///wzdDodtm7dWqq+x48fj6+//hqdO3fGqFGjYGdnh5UrVyI1NRXffvutwdMBD6Nu3bpwcnLCyZMn8cYbbyjr27Rpg3HjxgGAXsgBgKlTpyImJgb+/v4YMWIEjI2N8emnnyInJwczZ858YJ8mJiaYOnUqhg4dinbt2qF3795ITU3F8uXLC81YdOzYEU5OTmjVqhUcHR1x/PhxLFy4EMHBwXoXx1Y0Pz8/2NraYuDAgRg1ahQ0Gg2+/PLLhzqtee3aNdSqVQs9e/ZEs2bNYGVlhZ9++glJSUl638k0aNAgbNiwAZ06dcIrr7yC06dP46uvvlJmCB8XDRo0QJ06dfD222/jwoUL0Ol0+Pbbbx/quqb7mZiYoE+fPli4cCGMjIzQt2/fChgxVTWcyaEnRt26dYv87y46Ohrh4eHYsGED3nnnHeTl5eld41De3n33XQQHB2PatGmYP38+2rdvj127dsHS0lKpExAQgISEBLRo0QILFy7EG2+8gRUrVsDJyQmjR48udd+Ojo7Yu3cvOnTogAULFiAqKgqmpqbYunUrunfvXqb9Kggx935yy9vbG5aWljA1NS30vTeNGjVCfHw8GjdujGnTpmHy5Mlwc3PDzz//XKhuUYYMGYJPPvkEFy9exNixY5XvbLn/VNfQoUNx/fp1zJ07FyNHjsTmzZsxatQofPXVV2Xa55Kyt7fHtm3b4OzsjAkTJmD27Nno0KHDQ4U6S0tLjBgxAikpKZg4cSJGjx6NkydP4pNPPsGYMWOUekFBQZgzZw7++OMPREZGIiEhAdu2bTN40W5lMjExwdatW9G8eXPl/q9Xrx5WrVpVqu0VnPJq3749nJ2dy3OoVEVppDRXRRIRET1mfv/9dzRv3hyrVq3CgAEDKns49BjgTA4REanCsmXLYGVlVegnRujJxWtyiIioStu6dSuOHTuGpUuXIiIiAtWqVavsIdFjgqeriIioSnN3d0dGRgaCgoLw5ZdfPtILyenxxpBDREREqsRrcoiIiEiVGHKIiIhIlZ7oC4/z8/Nx8eJFVK9enT/iRkREVEWICK5duwYXF5div8D0iQ45Fy9efOBv4xAREdHjKS0trdgvuXyiQ07BFfhpaWkP/I0cIiIiejxkZWXB1dX1gZ+ke6JDTsEpKp1Ox5BDRERUxTzoUhNeeExERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKpkXNkDeJy4j99eZNnZ6cGPcCRERERUVpzJISIiIlUqcciJi4vDSy+9BBcXF2g0GmzevLnIusOGDYNGo8G8efP01l++fBmhoaHQ6XSwsbFBeHg4rl+/rlfn0KFDaN26NczNzeHq6oqZM2cW2v769evRoEEDmJubo0mTJvj+++9LujtERESkUiUOOdnZ2WjWrBkWLVpUbL1NmzZh3759cHFxKVQWGhqKo0ePIiYmBtu2bUNcXByGDBmilGdlZaFjx45wc3NDcnIyZs2ahUmTJmHp0qVKnb1796Jv374IDw/HwYMHERISgpCQEBw5cqSku0REREQqpBERKXVjjQabNm1CSEiI3voLFy7Ax8cHP/74I4KDgxEZGYnIyEgAwPHjx9GwYUMkJSWhRYsWAIAdO3agS5cu+Ouvv+Di4oLFixfjf//7H9LT02FqagoAGD9+PDZv3owTJ04AAHr37o3s7Gxs27ZN6ff5559H8+bNsWTJkocaf1ZWFqytrZGZmQmdTsdrcoiIiKqA+9+/i1Lu1+Tk5+djwIABGDt2LBo1alSoPCEhATY2NkrAAYDAwEBotVokJiYqddq0aaMEHAAICgrCyZMnceXKFaVOYGCg3raDgoKQkJBQ3rtEREREVVC5f7pqxowZMDY2xqhRowyWp6enw8HBQX8Qxsaws7NDenq6UsfDw0OvjqOjo1Jma2uL9PR0Zd29dQq2YUhOTg5ycnKU21lZWQ+/Y0RERFSllOtMTnJyMubPn48VK1ZAo9GU56bLxbRp02Btba0srq6ulT0kIiIiqiDlGnLi4+Nx6dIl1K5dG8bGxjA2Nsa5c+fw1ltvwd3dHQDg5OSES5cu6bW7c+cOLl++DCcnJ6VORkaGXp2C2w+qU1BuSFRUFDIzM5UlLS2tTPtLREREj69yDTkDBgzAoUOHkJKSoiwuLi4YO3YsfvzxRwCAr68vrl69iuTkZKVdbGws8vPz4ePjo9SJi4vD7du3lToxMTGoX78+bG1tlTq7du3S6z8mJga+vr5Fjs/MzAw6nU5vISIiInUq8TU5169fx59//qncTk1NRUpKCuzs7FC7dm3Y29vr1TcxMYGTkxPq168PAPD09ESnTp0wePBgLFmyBLdv30ZERAT69OmjfNy8X79+mDx5MsLDwzFu3DgcOXIE8+fPx0cffaRs980330Tbtm0xZ84cBAcH45tvvsGBAwf0PmZORERET64Sz+QcOHAAXl5e8PLyAgCMGTMGXl5eiI6OfuhtrF69Gg0aNED79u3RpUsX+Pv764UTa2tr7Ny5E6mpqfD29sZbb72F6Ohove/S8fPzw5o1a7B06VI0a9YMGzZswObNm9G4ceOS7hIRERGpUJm+J6eq4/fkEBERVT2V9j05RERERI8D/gp5OeAMEBER0eOHMzlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSsaVPYAnmfv47cWWn50e/IhGQkREpD6cySEiIiJVKnHIiYuLw0svvQQXFxdoNBps3rxZKbt9+zbGjRuHJk2aoFq1anBxcUFYWBguXryot43Lly8jNDQUOp0ONjY2CA8Px/Xr1/XqHDp0CK1bt4a5uTlcXV0xc+bMQmNZv349GjRoAHNzczRp0gTff/99SXeHiIiIVKrEISc7OxvNmjXDokWLCpXduHEDv/32G9577z389ttv2LhxI06ePImuXbvq1QsNDcXRo0cRExODbdu2IS4uDkOGDFHKs7Ky0LFjR7i5uSE5ORmzZs3CpEmTsHTpUqXO3r170bdvX4SHh+PgwYMICQlBSEgIjhw5UtJdIiIiIhXSiIiUurFGg02bNiEkJKTIOklJSWjZsiXOnTuH2rVr4/jx42jYsCGSkpLQokULAMCOHTvQpUsX/PXXX3BxccHixYvxv//9D+np6TA1NQUAjB8/Hps3b8aJEycAAL1790Z2dja2bdum9PX888+jefPmWLJkyUONPysrC9bW1sjMzIROpyv2Gpniro+piHYPaktERPSkuv/9uygVfk1OZmYmNBoNbGxsAAAJCQmwsbFRAg4ABAYGQqvVIjExUanTpk0bJeAAQFBQEE6ePIkrV64odQIDA/X6CgoKQkJCQgXvEREREVUFFfrpqlu3bmHcuHHo27evkrTS09Ph4OCgPwhjY9jZ2SE9PV2p4+HhoVfH0dFRKbO1tUV6erqy7t46BdswJCcnBzk5OcrtrKys0u8cERERPdYqbCbn9u3beOWVVyAiWLx4cUV1UyLTpk2DtbW1sri6ulb2kIiIiKiCVEjIKQg4586dQ0xMjN75MicnJ1y6dEmv/p07d3D58mU4OTkpdTIyMvTqFNx+UJ2CckOioqKQmZmpLGlpaaXfSSIiInqslXvIKQg4p06dwk8//QR7e3u9cl9fX1y9ehXJycnKutjYWOTn58PHx0epExcXh9u3byt1YmJiUL9+fdja2ip1du3apbftmJgY+Pr6Fjk2MzMz6HQ6vYWIiIjUqcQh5/r160hJSUFKSgoAIDU1FSkpKTh//jxu376Nnj174sCBA1i9ejXy8vKQnp6O9PR05ObmAgA8PT3RqVMnDB48GPv378evv/6KiIgI9OnTBy4uLgCAfv36wdTUFOHh4Th69CjWrl2L+fPnY8yYMco43nzzTezYsQNz5szBiRMnMGnSJBw4cAARERHlcFiIiIioqitxyDlw4AC8vLzg5eUFABgzZgy8vLwQHR2NCxcuYMuWLfjrr7/QvHlzODs7K8vevXuVbaxevRoNGjRA+/bt0aVLF/j7++t9B461tTV27tyJ1NRUeHt746233kJ0dLTed+n4+flhzZo1WLp0KZo1a4YNGzZg8+bNaNy4cVmOBxEREalEiT9dFRAQgOK+WudhvnbHzs4Oa9asKbZO06ZNER8fX2ydXr16oVevXg/sj4iIiJ48/O0qIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiXjyh4AlY77+O1Flp2dHvwIR0JERPR44kwOERERqRJDDhEREakSQw4RERGpEkMOERERqRIvPH7C8IJlIiJ6UnAmh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUqcQhJy4uDi+99BJcXFyg0WiwefNmvXIRQXR0NJydnWFhYYHAwECcOnVKr87ly5cRGhoKnU4HGxsbhIeH4/r163p1Dh06hNatW8Pc3Byurq6YOXNmobGsX78eDRo0gLm5OZo0aYLvv/++pLtDREREKlXikJOdnY1mzZph0aJFBstnzpyJjz/+GEuWLEFiYiKqVauGoKAg3Lp1S6kTGhqKo0ePIiYmBtu2bUNcXByGDBmilGdlZaFjx45wc3NDcnIyZs2ahUmTJmHp0qVKnb1796Jv374IDw/HwYMHERISgpCQEBw5cqSku0REREQqVOKfdejcuTM6d+5ssExEMG/ePEyYMAHdunUDAKxatQqOjo7YvHkz+vTpg+PHj2PHjh1ISkpCixYtAAALFixAly5dMHv2bLi4uGD16tXIzc3FF198AVNTUzRq1AgpKSmYO3euEobmz5+PTp06YezYsQCA999/HzExMVi4cCGWLFlSqoNBRERE6lGu1+SkpqYiPT0dgYGByjpra2v4+PggISEBAJCQkAAbGxsl4ABAYGAgtFotEhMTlTpt2rSBqampUicoKAgnT57ElStXlDr39lNQp6AfQ3JycpCVlaW3EBERkTqVa8hJT08HADg6Ouqtd3R0VMrS09Ph4OCgV25sbAw7Ozu9Ooa2cW8fRdUpKDdk2rRpsLa2VhZXV9eS7iIRERFVEU/Up6uioqKQmZmpLGlpaZU9JCIiIqog5RpynJycAAAZGRl66zMyMpQyJycnXLp0Sa/8zp07uHz5sl4dQ9u4t4+i6hSUG2JmZgadTqe3EBERkTqVa8jx8PCAk5MTdu3apazLyspCYmIifH19AQC+vr64evUqkpOTlTqxsbHIz8+Hj4+PUicuLg63b99W6sTExKB+/fqwtbVV6tzbT0Gdgn6IiIjoyVbikHP9+nWkpKQgJSUFwN2LjVNSUnD+/HloNBpERkZi6tSp2LJlCw4fPoywsDC4uLggJCQEAODp6YlOnTph8ODB2L9/P3799VdERESgT58+cHFxAQD069cPpqamCA8Px9GjR7F27VrMnz8fY8aMUcbx5ptvYseOHZgzZw5OnDiBSZMm4cCBA4iIiCj7USEiIqIqr8QfIT9w4ABeeOEF5XZB8Bg4cCBWrFiBd955B9nZ2RgyZAiuXr0Kf39/7NixA+bm5kqb1atXIyIiAu3bt4dWq0WPHj3w8ccfK+XW1tbYuXMnRo4cCW9vb9SoUQPR0dF636Xj5+eHNWvWYMKECXj33XdRr149bN68GY0bNy7VgSAiIiJ1KXHICQgIgIgUWa7RaDBlyhRMmTKlyDp2dnZYs2ZNsf00bdoU8fHxxdbp1asXevXqVfyAiYiI6In0RH26ioiIiJ4cDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpErGlT0Aqhrcx28vsuzs9OBHOBIiIqKHw5kcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUiWGHCIiIlIlhhwiIiJSJYYcIiIiUqVyDzl5eXl477334OHhAQsLC9SpUwfvv/8+RESpIyKIjo6Gs7MzLCwsEBgYiFOnTult5/LlywgNDYVOp4ONjQ3Cw8Nx/fp1vTqHDh1C69atYW5uDldXV8ycObO8d4eIiIiqqHIPOTNmzMDixYuxcOFCHD9+HDNmzMDMmTOxYMECpc7MmTPx8ccfY8mSJUhMTES1atUQFBSEW7duKXVCQ0Nx9OhRxMTEYNu2bYiLi8OQIUOU8qysLHTs2BFubm5ITk7GrFmzMGnSJCxdurS8d4mIiIiqIOPy3uDevXvRrVs3BAcHAwDc3d3x9ddfY//+/QDuzuLMmzcPEyZMQLdu3QAAq1atgqOjIzZv3ow+ffrg+PHj2LFjB5KSktCiRQsAwIIFC9ClSxfMnj0bLi4uWL16NXJzc/HFF1/A1NQUjRo1QkpKCubOnasXhoiIiOjJVO4zOX5+fti1axf++OMPAMDvv/+OPXv2oHPnzgCA1NRUpKenIzAwUGljbW0NHx8fJCQkAAASEhJgY2OjBBwACAwMhFarRWJiolKnTZs2MDU1VeoEBQXh5MmTuHLlSnnvFhEREVUx5T6TM378eGRlZaFBgwYwMjJCXl4ePvjgA4SGhgIA0tPTAQCOjo567RwdHZWy9PR0ODg46A/U2Bh2dnZ6dTw8PApto6DM1ta20NhycnKQk5Oj3M7KyirLrhIREdFjrNxnctatW4fVq1djzZo1+O2337By5UrMnj0bK1euLO+uSmzatGmwtrZWFldX18oeEhEREVWQcg85Y8eOxfjx49GnTx80adIEAwYMwOjRozFt2jQAgJOTEwAgIyNDr11GRoZS5uTkhEuXLumV37lzB5cvX9arY2gb9/Zxv6ioKGRmZipLWlpaGfeWiIiIHlflHnJu3LgBrVZ/s0ZGRsjPzwcAeHh4wMnJCbt27VLKs7KykJiYCF9fXwCAr68vrl69iuTkZKVObGws8vPz4ePjo9SJi4vD7du3lToxMTGoX7++wVNVAGBmZgadTqe3EBERkTqVe8h56aWX8MEHH2D79u04e/YsNm3ahLlz56J79+4AAI1Gg8jISEydOhVbtmzB4cOHERYWBhcXF4SEhAAAPD090alTJwwePBj79+/Hr7/+ioiICPTp0wcuLi4AgH79+sHU1BTh4eE4evQo1q5di/nz52PMmDHlvUtERERUBZX7hccLFizAe++9hxEjRuDSpUtwcXHB0KFDER0drdR55513kJ2djSFDhuDq1avw9/fHjh07YG5urtRZvXo1IiIi0L59e2i1WvTo0QMff/yxUm5tbY2dO3di5MiR8Pb2Ro0aNRAdHc2PjxMRERGACgg51atXx7x58zBv3rwi62g0GkyZMgVTpkwpso6dnR3WrFlTbF9NmzZFfHx8aYdKREREKsbfriIiIiJVYsghIiIiVWLIISIiIlViyCEiIiJVYsghIiIiVWLIISIiIlUq94+QE93Lffz2IsvOTg9+hCMhIqInDWdyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVjCt7AESGuI/fXmTZ2enBj3AkRERUVXEmh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSpQkLOhQsX0L9/f9jb28PCwgJNmjTBgQMHlHIRQXR0NJydnWFhYYHAwECcOnVKbxuXL19GaGgodDodbGxsEB4ejuvXr+vVOXToEFq3bg1zc3O4urpi5syZFbE7REREVAWVe8i5cuUKWrVqBRMTE/zwww84duwY5syZA1tbW6XOzJkz8fHHH2PJkiVITExEtWrVEBQUhFu3bil1QkNDcfToUcTExGDbtm2Ii4vDkCFDlPKsrCx07NgRbm5uSE5OxqxZszBp0iQsXbq0vHeJiIiIqiDj8t7gjBkz4OrqiuXLlyvrPDw8lL9FBPPmzcOECRPQrVs3AMCqVavg6OiIzZs3o0+fPjh+/Dh27NiBpKQktGjRAgCwYMECdOnSBbNnz4aLiwtWr16N3NxcfPHFFzA1NUWjRo2QkpKCuXPn6oUhIiIiejKV+0zOli1b0KJFC/Tq1QsODg7w8vLCsmXLlPLU1FSkp6cjMDBQWWdtbQ0fHx8kJCQAABISEmBjY6MEHAAIDAyEVqtFYmKiUqdNmzYwNTVV6gQFBeHkyZO4cuVKee8WERERVTHlHnLOnDmDxYsXo169evjxxx8xfPhwjBo1CitXrgQApKenAwAcHR312jk6Oipl6enpcHBw0Cs3NjaGnZ2dXh1D27i3j/vl5OQgKytLbyEiIiJ1KvfTVfn5+WjRogU+/PBDAICXlxeOHDmCJUuWYODAgeXdXYlMmzYNkydPrtQxEBER0aNR7jM5zs7OaNiwod46T09PnD9/HgDg5OQEAMjIyNCrk5GRoZQ5OTnh0qVLeuV37tzB5cuX9eoY2sa9fdwvKioKmZmZypKWllaaXSQiIqIqoNxDTqtWrXDy5Em9dX/88Qfc3NwA3L0I2cnJCbt27VLKs7KykJiYCF9fXwCAr68vrl69iuTkZKVObGws8vPz4ePjo9SJi4vD7du3lToxMTGoX7++3ie57mVmZgadTqe3EBERkTqVe8gZPXo09u3bhw8//BB//vkn1qxZg6VLl2LkyJEAAI1Gg8jISEydOhVbtmzB4cOHERYWBhcXF4SEhAC4O/PTqVMnDB48GPv378evv/6KiIgI9OnTBy4uLgCAfv36wdTUFOHh4Th69CjWrl2L+fPnY8yYMeW9S0RERFQFlfs1Oc899xw2bdqEqKgoTJkyBR4eHpg3bx5CQ0OVOu+88w6ys7MxZMgQXL16Ff7+/tixYwfMzc2VOqtXr0ZERATat28PrVaLHj164OOPP1bKra2tsXPnTowcORLe3t6oUaMGoqOj+fFxgvv47UWWnZ0e/AhHQkRElancQw4AvPjii3jxxReLLNdoNJgyZQqmTJlSZB07OzusWbOm2H6aNm2K+Pj4Uo+TiIiI1Iu/XUVERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxJBDREREqlQhv11FVBXxhz2JiNSFMzlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKFR5ypk+fDo1Gg8jISGXdrVu3MHLkSNjb28PKygo9evRARkaGXrvz588jODgYlpaWcHBwwNixY3Hnzh29Ort378azzz4LMzMz1K1bFytWrKjo3SEiIqIqokJDTlJSEj799FM0bdpUb/3o0aOxdetWrF+/Hr/88gsuXryIl19+WSnPy8tDcHAwcnNzsXfvXqxcuRIrVqxAdHS0Uic1NRXBwcF44YUXkJKSgsjISAwaNAg//vhjRe4SERERVREVFnKuX7+O0NBQLFu2DLa2tsr6zMxMfP7555g7dy7atWsHb29vLF++HHv37sW+ffsAADt37sSxY8fw1VdfoXnz5ujcuTPef/99LFq0CLm5uQCAJUuWwMPDA3PmzIGnpyciIiLQs2dPfPTRRxW1S0RERFSFVFjIGTlyJIKDgxEYGKi3Pjk5Gbdv39Zb36BBA9SuXRsJCQkAgISEBDRp0gSOjo5KnaCgIGRlZeHo0aNKnfu3HRQUpGzDkJycHGRlZektREREpE7GFbHRb775Br/99huSkpIKlaWnp8PU1BQ2NjZ66x0dHZGenq7UuTfgFJQXlBVXJysrCzdv3oSFhUWhvqdNm4bJkyeXer+IiIio6ij3mZy0tDS8+eabWL16NczNzct782USFRWFzMxMZUlLS6vsIREREVEFKfeQk5ycjEuXLuHZZ5+FsbExjI2N8csvv+Djjz+GsbExHB0dkZubi6tXr+q1y8jIgJOTEwDAycmp0KetCm4/qI5OpzM4iwMAZmZm0Ol0egsRERGpU7mHnPbt2+Pw4cNISUlRlhYtWiA0NFT528TEBLt27VLanDx5EufPn4evry8AwNfXF4cPH8alS5eUOjExMdDpdGjYsKFS595tFNQp2AYRERE92cr9mpzq1aujcePGeuuqVasGe3t7ZX14eDjGjBkDOzs76HQ6vPHGG/D19cXzzz8PAOjYsSMaNmyIAQMGYObMmUhPT8eECRMwcuRImJmZAQCGDRuGhQsX4p133sHrr7+O2NhYrFu3Dtu3by/vXSIiIqIqqEIuPH6Qjz76CFqtFj169EBOTg6CgoLwySefKOVGRkbYtm0bhg8fDl9fX1SrVg0DBw7ElClTlDoeHh7Yvn07Ro8ejfnz56NWrVr47LPPEBQUVBm7RERERI+ZRxJydu/erXfb3NwcixYtwqJFi4ps4+bmhu+//77Y7QYEBODgwYPlMUSiUnMfX/Ts4dnpwY9wJEREdC/+dhURERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqRJDDhEREakSQw4RERGpEkMOERERqZJxZQ+A6EnlPn57kWVnpwc/wpEQEakTZ3KIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJUYcoiIiEiVGHKIiIhIlRhyiIiISJXKPeRMmzYNzz33HKpXrw4HBweEhITg5MmTenVu3bqFkSNHwt7eHlZWVujRowcyMjL06pw/fx7BwcGwtLSEg4MDxo4dizt37ujV2b17N5599lmYmZmhbt26WLFiRXnvDhEREVVR5R5yfvnlF4wcORL79u1DTEwMbt++jY4dOyI7O1upM3r0aGzduhXr16/HL7/8gosXL+Lll19WyvPy8hAcHIzc3Fzs3bsXK1euxIoVKxAdHa3USU1NRXBwMF544QWkpKQgMjISgwYNwo8//ljeu0RERERVkHF5b3DHjh16t1esWAEHBwckJyejTZs2yMzMxOeff441a9agXbt2AIDly5fD09MT+/btw/PPP4+dO3fi2LFj+Omnn+Do6IjmzZvj/fffx7hx4zBp0iSYmppiyZIl8PDwwJw5cwAAnp6e2LNnDz766CMEBQWV924RERFRFVPh1+RkZmYCAOzs7AAAycnJuH37NgIDA5U6DRo0QO3atZGQkAAASEhIQJMmTeDo6KjUCQoKQlZWFo4eParUuXcbBXUKtkFERERPtnKfyblXfn4+IiMj0apVKzRu3BgAkJ6eDlNTU9jY2OjVdXR0RHp6ulLn3oBTUF5QVlydrKws3Lx5ExYWFoXGk5OTg5ycHOV2VlZW2XaQiIiIHlsVGnJGjhyJI0eOYM+ePRXZzUObNm0aJk+eXNnDICoT9/Hbiyw7Oz34EY6EiOjxVmGnqyIiIrBt2zb8/PPPqFWrlrLeyckJubm5uHr1ql79jIwMODk5KXXu/7RVwe0H1dHpdAZncQAgKioKmZmZypKWllamfSQiIqLHV7mHHBFBREQENm3ahNjYWHh4eOiVe3t7w8TEBLt27VLWnTx5EufPn4evry8AwNfXF4cPH8alS5eUOjExMdDpdGjYsKFS595tFNQp2IYhZmZm0Ol0egsRERGpU7mfrho5ciTWrFmD7777DtWrV1euobG2toaFhQWsra0RHh6OMWPGwM7ODjqdDm+88QZ8fX3x/PPPAwA6duyIhg0bYsCAAZg5cybS09MxYcIEjBw5EmZmZgCAYcOGYeHChXjnnXfw+uuvIzY2FuvWrcP27UVP5RMREdGTo9xnchYvXozMzEwEBATA2dlZWdauXavU+eijj/Diiy+iR48eaNOmDZycnLBx40al3MjICNu2bYORkRF8fX3Rv39/hIWFYcqUKUodDw8PbN++HTExMWjWrBnmzJmDzz77jB8fJyIiIgAVMJMjIg+sY25ujkWLFmHRokVF1nFzc8P3339f7HYCAgJw8ODBEo+RiIiI1I+/XUVERESqxJBDREREqlSh35NDRI8Pfr8OET1pOJNDREREqsSQQ0RERKrEkENERESqxJBDREREqsSQQ0RERKrEkENERESqxI+QE9ED8ePnRFQVcSaHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiSGHiIiIVIkhh4iIiFSJIYeIiIhUiT/QSUQVhj/sSUSViTM5REREpEoMOURERKRKDDlERESkSgw5REREpEoMOURERKRKDDlERESkSvwIORE9dvjRcyIqD5zJISIiIlViyCEiIiJVYsghIiIiVWLIISIiIlViyCEiIiJV4qeriEg1+KksIroXZ3KIiIhIlTiTQ0RPPM4AEalTlZ/JWbRoEdzd3WFubg4fHx/s37+/sodEREREj4EqPZOzdu1ajBkzBkuWLIGPjw/mzZuHoKAgnDx5Eg4ODpU9PCJSOc4AET3eqvRMzty5czF48GC89tpraNiwIZYsWQJLS0t88cUXlT00IiIiqmRVdiYnNzcXycnJiIqKUtZptVoEBgYiISGhEkdGRPRgpZ0F4uwR0cOrsiHn33//RV5eHhwdHfXWOzo64sSJEwbb5OTkICcnR7mdmZkJAMjKygIA5OfcKLK/gjqGVES7yuhTDe0qo0+1t6uMPtXerjL6bDzxxyLLjkwOemzaET2Mgse6iBRfUaqoCxcuCADZu3ev3vqxY8dKy5YtDbaZOHGiAODChQsXLly4qGBJS0srNitU2ZmcGjVqwMjICBkZGXrrMzIy4OTkZLBNVFQUxowZo9zOz8/H5cuXYW9vD41Go1c3KysLrq6uSEtLg06ne+hxqb1dVRprVWlXlcZaVdpVpbFWlXZVaaxVpV1VGuvjdmxEBNeuXYOLi0ux26iyIcfU1BTe3t7YtWsXQkJCANwNLbt27UJERITBNmZmZjAzM9NbZ2NjU2w/Op2uxHfMk9CuMvpUe7vK6FPt7SqjT7W3q4w+1d6uMvqsKu2Ka2ttbf3AtlU25ADAmDFjMHDgQLRo0QItW7bEvHnzkJ2djddee62yh0ZERESVrEqHnN69e+Off/5BdHQ00tPT0bx5c+zYsaPQxchERET05KnSIQcAIiIiijw9VRZmZmaYOHFiodNbT3q7yuhT7e0qo0+1t6uMPtXerjL6VHu7yuizqrQra9sCGpEHff6KiIiIqOqp0t94TERERFQUhhwiIiJSJYYcIiIiUiWGHHpkePkXERE9SlX+01VUdZiZmeH333+Hp6dnZQ+FiIgqwL///osvvvgCCQkJSE9PBwA4OTnBz88Pr776KmrWrPlIx8NPV5XBG2+8gVdeeQWtW7eulP6zs7Oxbt06/Pnnn3B2dkbfvn1hb29vsO7ff/+NxYsXY8+ePfj777+h1Wrx9NNPIyQkBK+++iqMjIzKbVz3/nTGvebPn4/+/fsrY5w7d2659QkAx48fx759++Dr64sGDRrgxIkTmD9/PnJyctC/f3+0a9euXPurSm7evInk5GTY2dmhYcOGemW3bt3CunXrEBYWVkmjq3z79+8v9KLs6+uLli1blmp7V65cwdatW4s8pvn5+dBqC0+k5+fn46+//kLt2rVL1a8hIoKzZ8/C1dUVxsbGyM3NxaZNm5CTk4MuXbqgRo0aJdpeu3btsHz5cri5uT10m9TUVOV1qnHjxgbr5OTkQKvVwsTEBABw+vRpfPHFFzh//jzc3NwQHh4ODw+PQu2+/fZbdO7cGZaWliXaDwD4/fffkZycjICAADz99NM4evQoFi1ahPz8fHTv3h1BQfwh0ZJISkpCUFAQLC0tERgYqHxnXUZGBnbt2oUbN27gxx9/RIsWLR7doMr+U5lVX3Jyspw5c0a5vWrVKvHz85NatWpJq1at5OuvvzbYTqPRiFarlXr16sn06dPl77//fug+FyxYIAMGDFC2vWrVKvH09JT69etLVFSU3L59u1AbT09P+e+//0RE5Pz58+Lu7i7W1tby3HPPiZ2dnTg4OOjtR4GkpCSxtrYWb29v8ff3FyMjIxkwYID07t1bbGxsxM/PT7Kysooca05Ojqxdu1YiIyOlT58+0qdPH4mMjJR169ZJTk6OwePSvHlzCQgI0Fs0Go0899xzEhAQIC+88MJDH6t7paeny+TJkwut/+GHH8TU1FTs7OzE3NxcfvjhB6lZs6YEBgZKu3btxMjISHbt2lXsttPS0uTatWuF1ufm5sovv/xisM2///4rsbGxyv3yzz//yPTp02Xy5Mly7NixEu2bh4eH/PHHHw9dPz8/X2JjY2Xp0qWydetWyc3NNVjv5MmT4ubmpjxe27RpIxcvXlTK09PTRavVGmyblpYm//zzj3I7Li5O+vXrJ/7+/hIaGlroB3ILzJ49W86ePfvQ+3KvrVu3ynvvvSd79uwREZFdu3ZJ586dJSgoSD799NMi2924cUM+//xzee2116RTp07SpUsXiYiIkJ9++qnINhkZGeLv7y8ajUbc3NykZcuW0rJlS+V4+fv7S0ZGRon3ISUlxeAxzczMlF69eom5ubk4ODjIe++9J3fu3FHKi7svHuT8+fPy2muv6a07ceKEuLm5iVarlbp168qZM2fE29tbqlWrJpaWllKjRo0iH3PfffedwcXIyEgWLlyo3L7f8OHDlefRjRs3pEePHqLVapXH3wsvvGDweda2bVtZv369iIjs2bNHzMzMpGnTptK7d2/x8vISS0tLg483jUYjOp1OBg8eLPv27Xvo4/Xtt9+KkZGR2Nvbi5WVlcTExIiNjY0EBgZKUFCQGBkZyerVq4vdRmJiosybN0/Gjx8v48ePl3nz5kliYuJDj+F+ly9flpUrVxZZnpeXV+T6c+fOPXQ/L7zwQrHPzw0bNkh2dvZDb6+Aj4+PDBkyRPLz8wuV5efny5AhQ+T5558vsn1+fr6cOXNGef/LycmRb775RlauXKn3OlQSDDki0rRpU4mJiRERkWXLlomFhYWMGjVKFi9eLJGRkWJlZSWff/55oXYajUZ++uknefPNN6VGjRpiYmIiXbt2la1btxb5YBQRef/996V69erSo0cPcXJykunTp4u9vb1MnTpVPvzwQ6lZs6ZER0cb7K/gBTc0NFT8/Pzk6tWrIiJy7do1CQwMlL59+xZq16pVK5k0aZJy+8svvxQfHx8Rufukat68uYwaNcrgWE+dOiVPP/20mJubS9u2beWVV16RV155Rdq2bSvm5uZSt25dOXXqlF6badOmiYeHR6FQYWxsLEePHi3yuDyMot48fH195X//+5+IiHz99ddia2sr7777rlI+fvx46dChg8FtXrx4UZ577jnRarVKALz3RbioN57ExESxtrYWjUYjtra2cuDAAfHw8JB69epJnTp1xMLCQpKTkwu1mz9/vsHFyMhIoqKilNv369y5s3J///fff+Lj4yMajUZq1qwpWq1WGjRoIJcuXSrULiQkRIKDg+Wff/6RU6dOSXBwsHh4eCgvisW9sbZs2VK2bt0qIiKbN28WrVYrXbt2lXHjxkn37t3FxMREKb+XRqMRIyMjCQwMlG+++cZgGDZkyZIlYmxsLN7e3qLT6eTLL7+U6tWry6BBg2To0KFiYWEh8+bNK9Tu1KlT4ubmJg4ODuLq6ioajUaCg4PFx8dHjIyMpFevXgb/cejRo4f4+vrKiRMnCpWdOHFC/Pz8pGfPnoXKMjMzi13i4+MNHtNRo0bJM888I+vXr5dly5aJm5ubBAcHK8cnPT1dNBrNQx2r+xl6bnTr1k26du0qhw4dksjISPH09JRu3bpJbm6u3Lp1S1566SXp37+/we0VhBKNRlPkYmgftVqt8joVFRUltWrVktjYWMnOzpY9e/ZInTp1ZPz48YXa6XQ6JXC1bdtWRo8erVc+YcIEadWqlcFxTpkyRby8vESj0UijRo3ko48+kn///bfY4/Xss8/K1KlTReTua4aNjY1MmTJFKZ89e7Y0b97cYNuqEo5LG1RLGxzNzc3l+PHjRZYfP35czM3NDZaVJZAXhyFHRCwsLJRU6+XlJUuXLtUrX716tTRs2LBQu3tDR25urqxdu1b5D8DFxUXefffdQgFARKROnTry7bffisjdB7WRkZF89dVXSvnGjRulbt26xfb39NNPy86dO/XKf/31V3F1dTW4f6dPn1Zu5+XliYmJiaSnp4uIyM6dO8XFxcXAkREJDAyUbt26SWZmZqGyzMxM6datm3Ts2LFQ2f79++WZZ56Rt956S5lheJiQ8/vvvxe7rF271uCTWafTKcc6Ly9PjI2N5bffflPKDx8+LI6Ojgb7DAsLEx8fH0lKSpKYmBjx9vaWFi1ayOXLl0Wk6DeewMBAGTRokGRlZcmsWbOkVq1aMmjQIKX8tddek5CQkELtNBqN1KpVS9zd3fUWjUYjTz31lLi7u4uHh4fBdgX3//Dhw6Vhw4bKzF1aWpp4e3vLsGHDCrVzcHCQQ4cOKbfz8/Nl2LBhUrt2bTl9+nSxIadatWpKHz4+PjJ9+nS98gULFoiXl5fBsS5fvly6desmJiYmYm9vL2+++aYcPnzYYD8FGjZsqDz/YmNjxdzcXBYtWqSUL1++XDw9PQu169y5swwdOlT5D3L69OnSuXNnERH5448/xN3dXSZOnFionZWVld7j5H4HDhwQKysrg/un1WqLXIoKALVr15aff/5Zuf3PP/9Iy5YtpWPHjnLr1q1i74ui3rAKlo8++qhQ25o1a8rBgwdFROT69eui0WgkPj5eKf/111+ldu3aBvvr1KmTBAcHF3qzftDz+N7HaePGjWXNmjWF9uOZZ54p1K5atWrKG6Sjo6OkpKTolf/5559F3hcF/R04cECGDx8uNjY2YmZmJr169Sr0Onlvf6mpqSJy9zlhYmKi9zw5ffq0wf5Eqk44Lm1QLW1wdHd3L3YmauXKleLm5mawrCyBvDgMOSJib28vBw4cEJG7bwiGnlwWFhaF2t375LrXuXPnZOLEiUoqvZ+FhYXe1KKJiYkcOXJEuX327FmxtLQ02F/Bf+ouLi6F3jDOnj1rMCW7ubkpU/8id2cuNBqN3LhxQ0REUlNTi0zXFhYWxb4xHTp0yOCxEbk7uxQWFiZNmzaVw4cPi4mJyQNDTnFPyuLePHQ6nfz555/KbSsrK71gV9SxEbl7LO+dYi54QjVv3lz++++/It94bG1tlVNSubm5otVq9baTnJwsTz31VKF2Q4cOlebNmxc6nVWSN4/69esX+g/sp59+MhiOqlevbvDU2ciRI6VWrVoSFxdX5BurtbW1/P777yJy97lR8HeBP//8s8jHasFYMzIyZMaMGdKgQQPRarXy3HPPydKlSw2eIjX03Lj38ZeammqwP0tLS73/8nJycsTExER5Ud68ebO4u7sXamdvby+7d+82uO8iIj///LPY29sXWq/T6WTGjBmye/dug8uyZcuKfO7ff0o5KytLfH19pV27dnLmzJki74vSvGHdfzytrKz0nifnz58XMzOzIvd/7ty54urqqjdb9zCP04LXqRo1aui9toncfS4aes1o166dzJw5U0RE/Pz8Cr1ZbtiwwWAgM/Q6fPPmTVm1apUEBASIVqs1eN87OTkpr/uXL18WjUajF0D3798vTk5OBvexqoTj8giqJQmOCxcuFDMzMxk1apR89913sm/fPtm3b5989913MmrUKLGwsND7p+VeZQnkxWHIEZH+/ftLeHi4iIj06tVLJkyYoFf+4YcfSpMmTQq1KyrkFMjPzzf4YPDw8JAffvhBRO7+l6nVamXdunVK+fbt2w0+KTUajTRp0kS8vLzEyspKNmzYoFf+yy+/GHxTffPNN6Vx48byww8/SGxsrLzwwgsSEBCglO/YsUPq1KljcB+cnZ0Nno4osGXLFnF2di6yXOTuVLCjo6NotdoHhhx7e3v5/PPP5ezZswaX7du3G3wyN23aVDmmIndnbu49PREXF2cwAIjc/Y/u/mnQ27dvS0hIiDRt2lQOHTpksM97/xMUKRyszp07V2Sw2rhxo7i6usqCBQuUdSV583BwcDD45mHoDeu5556TVatWGdzmyJEjxcbGpsg31q5duyqnFoKCggqdRlu2bJnUq1fP4FgNPTfi4uJk4MCBUq1aNalWrVqh8oLQJSJy4cIF0Wg0sn37dqV89+7dUqtWrULtXFxc9E4NXrlyRTQajRKkzpw5Y/DYjBgxQtzc3GTjxo16s5WZmZmyceNGcXd3l4iIiELtAgICZMaMGYXWF0hJSTH4n3X9+vX19qfAtWvXxNfXV5o1a1bkfeHi4iKbN28uss+DBw8WalunTh29N4pPPvlEL1wmJycX+UZ+73YbNmwoQ4YMkezs7Id6nA4dOlRGjx4tDg4OhV4Dk5OTpUaNGoXa7d27V6ytrWXixImyYMECqVGjhkyYMEFWr14t0dHRYmNjY/CY33t6zJBTp07pnbou0L9/f/Hx8ZGvvvpKXnrpJQkKCpLnn39ejh8/LidOnJC2bdsanI0RqVrhuLRBtTTBUUTkm2++ER8fHzE2NlbCt7Gxsfj4+MjatWuL7LOsgbwoDDly98XU3d1d2rRpI2PGjBELCwvx9/eXwYMHS5s2bcTU1NTgC5O7u/sDp+8MmTBhgtSsWVMGDRokHh4eMn78eKldu7YsXrxYlixZIq6uroXOR4uITJo0SW/ZsWOHXvnbb78tffr0KdTu2rVr8sorrygPOj8/P70nzI8//qgXsu713nvvia2trcydO1d+//13SU9Pl/T0dPn9999l7ty5YmdnZ/A0wP3S0tJk8+bNcv369WLrdezYUd5///0iy4t681i8eLFs27atyHZRUVFKkL1fkyZNCgVGkf8fdGrXrm3wBaRBgwZ61x1t27ZNmR0TEdm3b5/BN+QCf/31l7Rr1046deokf//990O98HTp0kW6d+8utra2hcLnvn37DJ6S+/DDD5VTN4YMHz68yOtAjh07Jvb29hIWFibvv/++WFlZSf/+/eWDDz6QsLAwMTMzk+XLlxdq96A3nszMzEKnhUXuhq569erJ1KlTpWXLljJw4EBp0KCB/PDDD7Jjxw5p0qSJvP7664XaDRw4UNq2bSvHjx+XM2fOKBerFti9e7fBU7m3bt2SYcOGiampqWi1WjE3Nxdzc3PRarViamoqw4cPl1u3bhVqt3TpUoPXTRVIT0/Xuw6uwBtvvFHkG2dWVpb4+PgU+Wb10ksvyXvvvVdkn4aeG0OHDpVly5YV2WbatGnSpUuXIssL3LhxQ4YOHSr16tUTIyOjYh+nbdu21fvAwf39v//++9K2bVuDbffu3SvPP/98oRmqp556yuC1WCIP/mezKOnp6dKhQwexsrKSoKAguXr1qkREROh9oOTeN9l7VaVwLFLyoFra4Hiv3NxcuXjxoly8eLHID0XcqzwCuSEMOf/PlStXZNy4cdKwYUMxNzcXU1NTcXNzk379+klSUlK59pWXlycffPCBvPjii/Lhhx9Kfn6+fP311+Lq6ir29vby6quvPjAMlMbNmzcNfqrhQaZPny7Ozs56U60ajUacnZ2LfcKWxsaNG+XLL78ssvzy5cuyYsWKcu3znXfeMXhdkcjdoNO1a1eDLzyTJk0q8pN3IiLvvvuuvPzyy8X2nZ+fLx9++KE4OTk98M3j1Vdf1Vvu/69o7NixEhQUVGx/pfHnn39Knz59pHr16sqbjomJifj5+cmmTZsMtintG8/169dl8ODB0rhxYxkyZIjk5OTIrFmzxNTUVDQajQQEBBjcbkZGhvLmqNVqxc3NTe90wvr16+Xjjz8ust/MzEyJjY2VNWvWyJo1ayQ2NtbgdWhldfny5UIzcPfKysoqcoYgLi5Ob7byftevXy92dsGQM2fO6H3S7kG+++47iYyMLNV9W+D06dOSlpZWbJ1Lly7Jvn37ZO/evXqzpYacPXvW4Kd5yjK++2eC71eWcFxUWBOpmHBcoCRBtbTP37Ior0B+P35PDj201NRUve8RMfSdFVXRnTt3cOPGDeh0uiLLL1y4UKLvBQGAGzduwMjICGZmZg+sm5ycjD179iAsLAy2trYl6qdAdnY2jIyMYG5uXqr2DyIiuHTpEvLz81GjRg3l+0wehVu3buH27duoXr16sfVOnTqFnJwcNGjQAMbG/K5TqlhZWVlITk7We1309vYu8rWktK5cuYKLFy+iUaNGBsuvXbuG3377DW3btn3gtrZs2YKff/4ZUVFRcHBwMFjn3LlzqF27NjQaTZnGXZ5SU1Nhbm4OZ2fnErXjzzrQQ/Pw8ICvry98fX2VgJOWlobXX3/9kY2hIvozNjYu9kXp77//xuTJk0u83f/++w/Dhw9/qLre3t548803YWtrW+p9vHz5MkaMGFHidg9Lo9HA0dERzs7OSsAp7VhL2s7c3BzVq1d/YLt69eqhcePGhQJOce1u3ryJPXv24NixY4XKbt26hVWrVj0W7UqrLP1VlWNTGffF8ePH8e233ypfxOrl5YV169YhMjISsbGxxbZbvnw5Tpw4AQA4ceIEhg8fjtdff73Idra2ttBqtUW2S0pKKjLg3N/fM888g5s3b2L8+PFF9ufm5oYTJ06UeJxlVdyxSU1NLXHAAcAvA6SyKep7HdTSX1n6rCrtyqKq7GNR7Qx9UeKFCxeU8qI+tVLaL1gsyxczlkZZ+nvU+1hV2omU/stH1d6uLCqqT87nUrG2bNlSbPmZM2eqdH9l6bOqtCuLqrKPpW03btw4NG7cGAcOHMDVq1cRGRkJf39/7N69u9ifVjDUrlWrVhXWrrTK0t+j3seq0g4ApkyZgrFjx2Lq1Kn45ptv0K9fPwwfPhwffPABACAqKgrTp08v9FMyam9XFhXWZ7lGMVKd0n6ZVFXpryx9VpV2PDZFtyvtFyU+6nalVZb+qsqxqYz7orRfPqr2dmVRUX3ymhwqlrOzMzZu3Ij8/HyDy2+//Val+ytLn1WlXVlUlX0sbbubN2/qXb+j0WiwePFivPTSS2jbti3++OOPx6JdaZWlv6pybCrrvii4KFer1cLc3BzW1tZKWfXq1ZGZmflEtiuLiuiTIYeK5e3tjeTk5CLLNRoNpBw/oPeo+ytLn1WlXVlUlX0sbbsGDRrgwIEDhdYvXLgQ3bp1Q9euXQ1u71G3K62y9FdVjk1l3Bfu7u44deqUcjshIUHvFNf58+cNXiSr9nZlUVF9MuRQscaOHQs/P78iy+vWrYuff/65yvZXlj6rSruyqCr7WNp23bt3x9dff22wzcKFC9G3b1+D4ehRtyutsvRXVY5NZdwXw4cPR15ennL7/k/0/fDDDwavHVF7u7KoqD75PTlERESkSpzJISIiIlViyCEiIiJVYsghIiIiVWLIISIiIlViyCGichcQEIDIyMjKHkapuLu7Y968ecXWmTRpEpo3b/5IxkNEpcefdSCicrdx48ZH+ivlpbFixQpERkbi6tWreuuTkpJQrVo15bZGo8GmTZsQEhLyaAdIRGXGkENE5c7Ozq6yh1BqNWvWrOwhEFE54ekqIip3956u+uSTT1CvXj2Ym5vD0dERPXv2VOpt2LABTZo0gYWFBezt7REYGIjs7OxC2ygQEhKCV199Vbmdk5ODt99+G0899RSqVasGHx8f7N69+4Hj2717N1577TVkZmZCo9FAo9Fg0qRJAPRPV7m7uwO4+8VxGo1GuW3IZ599Bk9PT5ibm6NBgwb45JNPHjgOIqpYnMkhogpz4MABjBo1Cl9++SX8/Pxw+fJlxMfHAwD+/vtv9O3bFzNnzkT37t1x7do1xMfHl+gbfyMiInDs2DF88803cHFxwaZNm9CpUyccPnwY9erVK7Kdn58f5s2bh+joaJw8eRIAYGVlVaheUlISHBwcsHz5cnTq1AlGRkYGt7d69WpER0dj4cKF8PLywsGDBzF48GBUq1YNAwcOfOj9IaLyxZBDRBXm/PnzqFatGl588UVUr14dbm5u8PLyAnA35Ny5cwcvv/wy3NzcAABNmjQp0baXL1+O8+fPw8XFBQDw9ttvY8eOHVi+fDk+/PDDItuamprC2toaGo0GTk5ORdYrOHVlY2NTbL2JEydizpw5ePnllwEAHh4eOHbsGD799FOGHKJKxJBDRBWmQ4cOcHNzw9NPP41OnTqhU6dO6N69OywtLdGsWTO0b98eTZo0QVBQEDp27IiePXvC1tb2obZ9+PBh5OXl4ZlnntFbn5OTA3t7+4rYHYOys7Nx+vRphIeHY/Dgwcr6O3fu6P2KMhE9egw5RFRhqlevjt9++w27d+/Gzp07ER0djUmTJiEpKQk2NjaIiYnB3r17sXPnTixYsAD/+9//kJiYCA8PD2i12kKnrm7fvq38ff36dRgZGSE5ObnQaSRDp54qyvXr1wEAy5Ytg4+Pj15ZUae3iOjR4IXHRFShjI2NERgYiJkzZ+LQoUM4e/YsYmNjAdz9eHarVq0wefJkHDx4EKampti0aROAu6eK/v77b2U7eXl5OHLkiHLby8sLeXl5uHTpEurWrau3FHdqqYCpqanerx4XxcTEpNh6jo6OcHFxwZkzZwqNw8PD44HbJ6KKw5kcIqow27Ztw5kzZ9CmTRvY2tri+++/R35+PurXr4/ExETs2rULHTt2hIODAxITE/HPP//A09MTANCuXTuMGTMG27dvR506dTB37ly977R55plnEBoairCwMMyZMwdeXl74559/sGvXLjRt2hTBwcHFjs3d3R3Xr1/Hrl270KxZM1haWsLS0tJgvV27dqFVq1YwMzMzeDpt8uTJGDVqFKytrdGpUyfk5OTgwIEDuHLlCsaMGVO2g0hEpcaZHCKqMDY2Nti4cSPatWsHT09PLFmyBF9//TUaNWoEnU6HuLg4dOnSBc888wwmTJiAOXPmoHPnzgCA119/HQMHDkRYWBjatm2Lp59+Gi+88ILe9pcvX46wsDC89dZbqF+/PkJCQpCUlITatWs/cGx+fn4YNmwYevfujZo1a2LmzJkG682ZMwcxMTFwdXVVLpq+36BBg/DZZ59h+fLlaNKkCdq2bYsVK1ZwJoeokmmkJJ/XJCIiIqoiOJNDREREqsSQQ0Sq1LlzZ1hZWRlcivsOHSJSD56uIiJVunDhAm7evGmwzM7Orkr/vhYRPRyGHCIiIlIlnq4iIiIiVWLIISIiIlViyCEiIiJVYsghIiIiVWLIISIiIlViyCEiIiJVYsghIiIiVWLIISIiIlX6P2A8vBCYu6hsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"issue_title\"].apply(lambda x: len(x.split())).value_counts().plot(kind=\"bar\", title=\"Number of words in a summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "encoder = RobertaModel.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: numpy in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (0.20.2)\n",
      "Requirement already satisfied: Pillow in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: \"Create google account\" link should not be shown when BWSI is disabled\n",
      "Sentence 2: page_cycler_tests and others deprecated in favor of performance_ui_tests\n",
      "Similarity score: 0.060293953865766525\n"
     ]
    }
   ],
   "source": [
    "sentence1 = X_df.iloc[8435].issue_title\n",
    "sentence2 = X_df.iloc[2101].issue_title\n",
    "# encode sentences to get their embeddings\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.cos_sim(embedding1, embedding2)\n",
    "print(\"Sentence 1:\", sentence1)\n",
    "print(\"Sentence 2:\", sentence2)\n",
    "print(\"Similarity score:\", cosine_scores.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amit@chromium.org</td>\n",
       "      <td>Scrolling with some scroll mice (touchpad, etc...</td>\n",
       "      <td>\\nProduct Version      : &lt;see about:version&gt;\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Proxy causes some or all network requests to fail</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfeldman@chromium.org</td>\n",
       "      <td>Web inspector button \"dock to main window\" doe...</td>\n",
       "      <td>\\nProduct Version      : chrome beta 1\\r\\nURLs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Habari admin interface is not rendered correctly</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkasting@chromium.org</td>\n",
       "      <td>Maximize on second larger monitor not working</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27\\r\\nURLs (i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   owner                                        issue_title  \\\n",
       "0      amit@chromium.org  Scrolling with some scroll mice (touchpad, etc...   \n",
       "1       jon@chromium.org  Proxy causes some or all network requests to fail   \n",
       "2  pfeldman@chromium.org  Web inspector button \"dock to main window\" doe...   \n",
       "3       jon@chromium.org   Habari admin interface is not rendered correctly   \n",
       "4  pkasting@chromium.org      Maximize on second larger monitor not working   \n",
       "\n",
       "                                         description  \n",
       "0  \\nProduct Version      : <see about:version>\\r...  \n",
       "1  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...  \n",
       "2  \\nProduct Version      : chrome beta 1\\r\\nURLs...  \n",
       "3  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...  \n",
       "4  \\nProduct Version      : 0.2.149.27\\r\\nURLs (i...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"text\"] = X_df.apply(lambda row: row.issue_title + \"\\n\" + row.description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amit@chromium.org</td>\n",
       "      <td>Scrolling with some scroll mice (touchpad, etc...</td>\n",
       "      <td>\\nProduct Version      : &lt;see about:version&gt;\\r...</td>\n",
       "      <td>Scrolling with some scroll mice (touchpad, etc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Proxy causes some or all network requests to fail</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "      <td>Proxy causes some or all network requests to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfeldman@chromium.org</td>\n",
       "      <td>Web inspector button \"dock to main window\" doe...</td>\n",
       "      <td>\\nProduct Version      : chrome beta 1\\r\\nURLs...</td>\n",
       "      <td>Web inspector button \"dock to main window\" doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Habari admin interface is not rendered correctly</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "      <td>Habari admin interface is not rendered correct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkasting@chromium.org</td>\n",
       "      <td>Maximize on second larger monitor not working</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27\\r\\nURLs (i...</td>\n",
       "      <td>Maximize on second larger monitor not working\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   owner                                        issue_title  \\\n",
       "0      amit@chromium.org  Scrolling with some scroll mice (touchpad, etc...   \n",
       "1       jon@chromium.org  Proxy causes some or all network requests to fail   \n",
       "2  pfeldman@chromium.org  Web inspector button \"dock to main window\" doe...   \n",
       "3       jon@chromium.org   Habari admin interface is not rendered correctly   \n",
       "4  pkasting@chromium.org      Maximize on second larger monitor not working   \n",
       "\n",
       "                                         description  \\\n",
       "0  \\nProduct Version      : <see about:version>\\r...   \n",
       "1  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...   \n",
       "2  \\nProduct Version      : chrome beta 1\\r\\nURLs...   \n",
       "3  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...   \n",
       "4  \\nProduct Version      : 0.2.149.27\\r\\nURLs (i...   \n",
       "\n",
       "                                                text  \n",
       "0  Scrolling with some scroll mice (touchpad, etc...  \n",
       "1  Proxy causes some or all network requests to f...  \n",
       "2  Web inspector button \"dock to main window\" doe...  \n",
       "3  Habari admin interface is not rendered correct...  \n",
       "4  Maximize on second larger monitor not working\\...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = model.encode(X_df.issue_title.to_list(), batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[samples_per_block*block: samples_per_block*(block+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df[\"owner\"].isin(list(X_df[\"owner\"].unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text\"] = test_df.apply(lambda row: row.issue_title + \"\\n\" + row.description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55102</th>\n",
       "      <td>thestig@chromium.org</td>\n",
       "      <td>Cancelling print preview caused a NOTREACHED i...</td>\n",
       "      <td>\\nWhat steps will reproduce the problem?\\n1. O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      owner  \\\n",
       "55102  thestig@chromium.org   \n",
       "\n",
       "                                             issue_title  \\\n",
       "55102  Cancelling print preview caused a NOTREACHED i...   \n",
       "\n",
       "                                             description  \n",
       "55102  \\nWhat steps will reproduce the problem?\\n1. O...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.index == 55070]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents not arranged properly under Grid view'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[X_df.index==11654].issue_title.to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Upstream changes in net/'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.index==55074].issue_title.to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54990\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4696, 0.4537, 0.4519, 0.4480, 0.4423, 0.4419, 0.4392, 0.4363, 0.4360,\n",
      "        0.4344]),\n",
      "indices=tensor([45788,  5195, 14256, 13864, 44751, 29598, 30862, 16212, 46586,  7605]))\n",
      "54992\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7083, 0.6475, 0.6376, 0.6210, 0.6210, 0.6097, 0.6041, 0.6036, 0.6001,\n",
      "        0.5867]),\n",
      "indices=tensor([43036,  6573, 25066, 46944, 48976, 11218, 48514, 15868, 45944,  3790]))\n",
      "54993\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7695, 0.7476, 0.7402, 0.7238, 0.6832, 0.6765, 0.6718, 0.6637, 0.6605,\n",
      "        0.6602]),\n",
      "indices=tensor([  945, 25644, 42308, 43789, 42331, 21539, 50643, 40702, 17262,  6175]))\n",
      "54994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6371, 0.5974, 0.5925, 0.5701, 0.5659, 0.5640, 0.5595, 0.5593, 0.5584,\n",
      "        0.5564]),\n",
      "indices=tensor([47751, 29570, 38297, 49162, 22029, 19884, 24969,  8978, 42178, 29754]))\n",
      "54997\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6714, 0.6396, 0.6253, 0.6112, 0.5895, 0.5831, 0.5747, 0.5746, 0.5726,\n",
      "        0.5676]),\n",
      "indices=tensor([ 8559, 22504, 18602, 22807, 27065, 17915,  5735, 29691, 20709, 11698]))\n",
      "54998\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7673, 0.7482, 0.6498, 0.6497, 0.6453, 0.6418, 0.6330, 0.6248, 0.5960,\n",
      "        0.5945]),\n",
      "indices=tensor([41697,  7946, 17689, 50888, 23867, 10004, 14099, 50650, 47602,  6892]))\n",
      "55000\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5599, 0.5443, 0.5399, 0.4671, 0.4619, 0.4603, 0.4514, 0.4464, 0.4458,\n",
      "        0.4433]),\n",
      "indices=tensor([ 6747, 21593,  8672, 33222,  4344,   323, 47787, 49578,  6047,   592]))\n",
      "55002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5714, 0.5527, 0.5511, 0.5502, 0.5465, 0.5340, 0.5242, 0.5213, 0.5171,\n",
      "        0.5104]),\n",
      "indices=tensor([50189, 42120, 16467, 37379, 42115, 30679, 25326, 25307,   315,  6253]))\n",
      "55005\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7810, 0.7002, 0.6883, 0.6743, 0.6535, 0.6479, 0.6450, 0.6427, 0.6360,\n",
      "        0.6239]),\n",
      "indices=tensor([38745, 30666, 23984, 38694, 50267,  7775, 34256, 23977, 36708, 26910]))\n",
      "55006\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5741, 0.5606, 0.5505, 0.5336, 0.5230, 0.5067, 0.4934, 0.4887, 0.4851,\n",
      "        0.4847]),\n",
      "indices=tensor([48453, 14721, 21926, 10658, 27299, 48575, 48459,  3008, 41322, 35806]))\n",
      "55007\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7088, 0.6364, 0.6248, 0.6221, 0.6215, 0.6173, 0.6154, 0.6104, 0.6087,\n",
      "        0.6015]),\n",
      "indices=tensor([48801, 14201, 35047, 44703, 49381, 27183,  3801, 13584,  6964,  9507]))\n",
      "55008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7970, 0.6942, 0.6823, 0.6803, 0.6796, 0.6623, 0.6610, 0.6467, 0.6459,\n",
      "        0.6388]),\n",
      "indices=tensor([46173, 27003, 45777, 43845, 46542, 27565, 50129, 44961, 22941, 41731]))\n",
      "55009\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5927, 0.5866, 0.5805, 0.5786, 0.5740, 0.5651, 0.5397, 0.5255, 0.5188,\n",
      "        0.5131]),\n",
      "indices=tensor([50867, 41762, 42240, 39074, 41736, 36020,   288, 35853, 13657, 50792]))\n",
      "55010\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6623, 0.5970, 0.5919, 0.5686, 0.5504, 0.5357, 0.5190, 0.5178, 0.5158,\n",
      "        0.5137]),\n",
      "indices=tensor([ 1096, 13052, 22154,   819, 32264,  3295, 32266, 32268, 40058, 15464]))\n",
      "55011\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5883, 0.5358, 0.5304, 0.5188, 0.5082, 0.4867, 0.4837, 0.4821, 0.4806,\n",
      "        0.4654]),\n",
      "indices=tensor([14397, 15360, 30044, 15347, 19969, 30417, 39772, 49369, 43165, 43606]))\n",
      "55012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6706, 0.6489, 0.5045, 0.5012, 0.4929, 0.4836, 0.4759, 0.4731, 0.4686,\n",
      "        0.4612]),\n",
      "indices=tensor([39995, 17648,  7358, 37623, 11948, 32646, 35557, 10236, 28033, 13882]))\n",
      "55013\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6704, 0.6056, 0.6047, 0.5967, 0.5684, 0.5675, 0.5510, 0.5476, 0.5464,\n",
      "        0.5397]),\n",
      "indices=tensor([26729, 19554,  4933,  1142, 49230,   895, 33463,  8172, 12252, 28942]))\n",
      "55014\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6511, 0.6209, 0.6061, 0.6013, 0.5732, 0.5592, 0.5586, 0.5532, 0.5524,\n",
      "        0.5502]),\n",
      "indices=tensor([36222,  5498, 21532, 13879,  5564, 44288,  7237, 37276, 11995, 15359]))\n",
      "55015\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7305, 0.6865, 0.6484, 0.6184, 0.6087, 0.5977, 0.5909, 0.5793, 0.5625,\n",
      "        0.5496]),\n",
      "indices=tensor([25376, 29204,  8894, 17300, 15633, 37225, 25004, 36850, 24082, 48670]))\n",
      "55017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7407, 0.6893, 0.6424, 0.6324, 0.6234, 0.6213, 0.6163, 0.6130, 0.6124,\n",
      "        0.5943]),\n",
      "indices=tensor([29459, 23124, 26796,  7420, 16196,  2020,  8621, 48221, 43671, 27360]))\n",
      "55019\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6992, 0.6869, 0.6674, 0.6427, 0.6343, 0.6148, 0.6105, 0.6076, 0.6052,\n",
      "        0.6045]),\n",
      "indices=tensor([ 3687, 25621, 21680,  1154,  4242, 46619,  2759, 40675, 48116, 33839]))\n",
      "55020\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4770, 0.4734, 0.4668, 0.4594, 0.4589, 0.4524, 0.4462, 0.4422, 0.4400,\n",
      "        0.4380]),\n",
      "indices=tensor([19461, 24209,  3039, 40505, 50807, 22004, 19386, 26869, 40833, 48383]))\n",
      "55021\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7399, 0.6950, 0.6948, 0.6780, 0.6739, 0.6702, 0.6691, 0.6592, 0.6533,\n",
      "        0.6526]),\n",
      "indices=tensor([26344, 36909,  6114, 43870, 26962, 16398, 16538, 25379, 36858, 14937]))\n",
      "55022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7660, 0.7360, 0.6684, 0.6579, 0.6425, 0.6355, 0.6307, 0.6278, 0.6253,\n",
      "        0.6248]),\n",
      "indices=tensor([17383, 16896, 31078, 42470, 14631, 30835,  7348, 17010, 10591, 45827]))\n",
      "55023\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6230, 0.6082, 0.6035, 0.6009, 0.5891, 0.5857, 0.5855, 0.5811, 0.5746,\n",
      "        0.5741]),\n",
      "indices=tensor([40454, 10042, 39439, 28834, 34374,  2852, 10898, 38153, 37939, 49762]))\n",
      "55024\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7267, 0.5584, 0.5583, 0.5481, 0.5466, 0.5432, 0.5431, 0.5374, 0.5209,\n",
      "        0.5170]),\n",
      "indices=tensor([29952,  3971, 28424, 12946, 15605, 41775, 14750, 23923, 14739, 37817]))\n",
      "55025\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7018, 0.6906, 0.6886, 0.6511, 0.6439, 0.6424, 0.6413, 0.6326, 0.6237,\n",
      "        0.6155]),\n",
      "indices=tensor([ 2890, 44474,  9581, 35281, 20340, 26820, 27468, 16351, 16378, 39016]))\n",
      "55027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7631, 0.6786, 0.6067, 0.5999, 0.5761, 0.5652, 0.5593, 0.5269, 0.5250,\n",
      "        0.4974]),\n",
      "indices=tensor([49412, 50315,  7632, 15734, 35906, 11420, 50192,  2030, 21979, 34428]))\n",
      "55028\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6996, 0.6604, 0.6311, 0.6267, 0.6016, 0.5610, 0.5502, 0.5489, 0.5391,\n",
      "        0.5367]),\n",
      "indices=tensor([10636,   483, 11365, 11367, 42379, 11275, 18127, 11302, 38136,  6064]))\n",
      "55029\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5895, 0.5772, 0.5767, 0.5661, 0.5584, 0.5564, 0.5509, 0.5470, 0.5443,\n",
      "        0.5414]),\n",
      "indices=tensor([35481, 24353, 29341, 46789, 46867, 40624, 49110, 45848, 19402, 21140]))\n",
      "55030\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6055, 0.4935, 0.4803, 0.4763, 0.4695, 0.4660, 0.4659, 0.4483, 0.4475,\n",
      "        0.4472]),\n",
      "indices=tensor([29071, 40140, 45282, 48396, 11345, 21852, 19005,  1111, 10044, 37313]))\n",
      "55031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7641, 0.7566, 0.7294, 0.7234, 0.7218, 0.7161, 0.7118, 0.7111, 0.7092,\n",
      "        0.7035]),\n",
      "indices=tensor([26347, 27360, 32238, 11158,  3510, 31192,  3012,  3514, 31204, 38781]))\n",
      "55033\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4820, 0.4495, 0.3573, 0.3470, 0.3409, 0.3314, 0.3302, 0.3197, 0.3173,\n",
      "        0.3157]),\n",
      "indices=tensor([50882, 26789, 28101,  7990, 39245, 12623, 40665, 49991, 42202, 42464]))\n",
      "55034\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7183, 0.6213, 0.5258, 0.4994, 0.4962, 0.4785, 0.4754, 0.4705, 0.4617,\n",
      "        0.4577]),\n",
      "indices=tensor([18164,  2445,  6907, 29424,   257, 15679, 20423, 42212, 20959, 31287]))\n",
      "55036\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9464, 0.7107, 0.7104, 0.7101, 0.6960, 0.6662, 0.6662, 0.6455, 0.6298,\n",
      "        0.6219]),\n",
      "indices=tensor([11832,  6525,  8214,  6920, 21487,  8338,  4986, 38654, 50860,  4954]))\n",
      "55037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6499, 0.5806, 0.5420, 0.5294, 0.5154, 0.5104, 0.4954, 0.4952, 0.4951,\n",
      "        0.4931]),\n",
      "indices=tensor([ 8573,  2451, 46145, 46756,   542, 35594, 13164, 13296, 28350, 33359]))\n",
      "55038\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7079, 0.6845, 0.6327, 0.6293, 0.6005, 0.5900, 0.5892, 0.5846, 0.5803,\n",
      "        0.5771]),\n",
      "indices=tensor([ 8694, 22470, 35343, 22592, 15507,  4731,  5537, 12081,  6939,  4179]))\n",
      "55039\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5840, 0.5840, 0.5503, 0.5416, 0.5203, 0.5134, 0.4994, 0.4972, 0.4787,\n",
      "        0.4569]),\n",
      "indices=tensor([ 5689,  4671, 16169, 37910, 39388, 13214, 48812, 40766,  8472, 21738]))\n",
      "55040\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6719, 0.5886, 0.5797, 0.5711, 0.5529, 0.5516, 0.5405, 0.5244, 0.4995,\n",
      "        0.4982]),\n",
      "indices=tensor([47983, 44778, 37330, 46099, 26904,  3014, 44774, 43643, 18380, 46955]))\n",
      "55042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6506, 0.5964, 0.5756, 0.5620, 0.5592, 0.5502, 0.5379, 0.5341, 0.5256,\n",
      "        0.5193]),\n",
      "indices=tensor([45005, 22419, 20739, 30437, 22123, 11593, 10093, 21237,   382,  8390]))\n",
      "55043\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6782, 0.5759, 0.5643, 0.5557, 0.5523, 0.5496, 0.5450, 0.5417, 0.5349,\n",
      "        0.5327]),\n",
      "indices=tensor([ 5802, 25473, 50406, 46738, 28540, 16529, 21685, 37216,  2485, 44511]))\n",
      "55044\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.9807, 0.9801, 0.9732, 0.9609, 0.9589, 0.9513, 0.9064, 0.9056, 0.9030,\n",
      "        0.9029]),\n",
      "indices=tensor([46420, 49753, 47888, 45501, 43057, 47892, 44227, 49080, 49811, 42028]))\n",
      "55045\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6489, 0.6161, 0.6114, 0.5712, 0.5712, 0.5689, 0.5623, 0.5352, 0.5217,\n",
      "        0.5158]),\n",
      "indices=tensor([44966, 49324, 13335,  6664, 23931, 16748, 48079, 17853, 45686, 38735]))\n",
      "55047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.4722, 0.4521, 0.4473, 0.4473, 0.4378, 0.4290, 0.4283, 0.4262, 0.4244,\n",
      "        0.4233]),\n",
      "indices=tensor([29129, 50910, 20783, 42169, 35516, 20025, 15361, 22314, 11636, 24781]))\n",
      "55048\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5106, 0.5051, 0.4812, 0.4769, 0.4721, 0.4659, 0.4608, 0.4579, 0.4523,\n",
      "        0.4448]),\n",
      "indices=tensor([46695, 11836, 44449, 48441, 49708, 13196, 46444, 50142, 19954, 49519]))\n",
      "55050\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6432, 0.5950, 0.5687, 0.5618, 0.5614, 0.5560, 0.5516, 0.5516, 0.5512,\n",
      "        0.5470]),\n",
      "indices=tensor([41641, 50129, 31066, 42942, 46385, 21857, 18197,  1442, 27907, 41618]))\n",
      "55052\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4790, 0.4789, 0.4505, 0.4408, 0.4344, 0.4112, 0.4100, 0.4078, 0.4076,\n",
      "        0.4055]),\n",
      "indices=tensor([ 9351, 19494, 43132, 40562, 40146, 46296, 44171, 41440, 44630, 42895]))\n",
      "55054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.4161, 0.3918, 0.3836, 0.3777, 0.3585, 0.3509, 0.3497, 0.3496, 0.3492,\n",
      "        0.3391]),\n",
      "indices=tensor([27307,  6436, 16630, 46047, 10887, 26937, 18980,  9419, 27558, 31918]))\n",
      "55056\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6226, 0.5992, 0.5851, 0.5804, 0.5633, 0.5619, 0.5598, 0.5558, 0.5526,\n",
      "        0.5490]),\n",
      "indices=tensor([49198, 16603, 48074,  2371, 41151, 37086, 36184,    35, 12449, 33345]))\n",
      "55057\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5826, 0.5756, 0.5481, 0.5414, 0.5288, 0.5189, 0.5173, 0.5161, 0.5150,\n",
      "        0.5121]),\n",
      "indices=tensor([13943,  3930,  7780, 31027,  2776, 38818,  6036, 49822, 42619, 10339]))\n",
      "55058\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7923, 0.7905, 0.7768, 0.7763, 0.7572, 0.7571, 0.7516, 0.7277, 0.7176,\n",
      "        0.7154]),\n",
      "indices=tensor([39212,  1059, 12817, 28551, 31939,  5766,  4080, 33068, 12197, 38482]))\n",
      "55059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6380, 0.5868, 0.5631, 0.5450, 0.5417, 0.5356, 0.5266, 0.5243, 0.5185,\n",
      "        0.5174]),\n",
      "indices=tensor([50284, 27388, 49074, 44296, 19581, 39892, 41568,  9584, 34581,   470]))\n",
      "55062\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5803, 0.5500, 0.5390, 0.5353, 0.5330, 0.5255, 0.5254, 0.4795, 0.4763,\n",
      "        0.4712]),\n",
      "indices=tensor([21939, 43882, 25989, 33731, 40345, 23452, 16713, 24290, 16185, 43078]))\n",
      "55063\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7647, 0.6688, 0.6176, 0.6082, 0.5601, 0.5484, 0.5433, 0.5372, 0.5180,\n",
      "        0.5154]),\n",
      "indices=tensor([41544, 46659, 20123, 47308, 43265, 23738, 20122, 37891, 12491, 36206]))\n",
      "55064\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6116, 0.6101, 0.6043, 0.6026, 0.6007, 0.5983, 0.5953, 0.5862, 0.5835,\n",
      "        0.5818]),\n",
      "indices=tensor([49766, 36910,  5768,  9125, 16814, 15468, 12936, 41119, 40545,  3317]))\n",
      "55065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6986, 0.6791, 0.6195, 0.6043, 0.5701, 0.5585, 0.5487, 0.5445, 0.5422,\n",
      "        0.5422]),\n",
      "indices=tensor([45631, 39981, 42400, 46975,  3962, 25352, 35016, 30350, 23004, 20649]))\n",
      "55066\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6472, 0.6404, 0.6196, 0.6133, 0.6123, 0.5881, 0.5873, 0.5854, 0.5854,\n",
      "        0.5833]),\n",
      "indices=tensor([41197, 22262, 30093, 39668,  5772,  7948, 22782, 38234, 47823, 39662]))\n",
      "55067\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5799, 0.5483, 0.5217, 0.5006, 0.4996, 0.4953, 0.4949, 0.4902, 0.4803,\n",
      "        0.4760]),\n",
      "indices=tensor([25049, 20002, 32275, 31805, 30282, 31740, 46404,  6207, 45446, 25496]))\n",
      "55070\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7024, 0.6595, 0.6480, 0.6463, 0.6282, 0.6243, 0.6140, 0.6010, 0.6003,\n",
      "        0.5942]),\n",
      "indices=tensor([ 3257, 18772,  5976, 11508,  6368, 35583, 31466,  5122, 11739, 26380]))\n",
      "55071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6653, 0.5872, 0.5832, 0.5810, 0.5785, 0.5771, 0.5721, 0.5631, 0.5604,\n",
      "        0.5603]),\n",
      "indices=tensor([38767,  7072, 31156, 29470, 18337, 16539, 11643, 48307, 24011, 47844]))\n",
      "55072\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6983, 0.6926, 0.6795, 0.6656, 0.6603, 0.6602, 0.6363, 0.6199, 0.6075,\n",
      "        0.6014]),\n",
      "indices=tensor([43784, 40382, 42853, 49055, 45654, 36908, 15413, 30498, 39680, 44826]))\n",
      "55073\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.4838, 0.4739, 0.4510, 0.4431, 0.4427, 0.4355, 0.4306, 0.4129, 0.4112,\n",
      "        0.4110]),\n",
      "indices=tensor([10398, 17843, 10914,  7506, 43905, 35871, 35301, 28089, 46696,  6819]))\n",
      "55074\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5764, 0.5471, 0.5274, 0.5164, 0.5149, 0.5149, 0.4910, 0.4862, 0.4823,\n",
      "        0.4808]),\n",
      "indices=tensor([ 3850, 50861, 50908, 19538, 35670, 22772,  3847, 46211, 48500, 28148]))\n",
      "55075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9153, 0.7109, 0.6960, 0.6817, 0.6792, 0.6673, 0.6666, 0.6496, 0.6324,\n",
      "        0.6291]),\n",
      "indices=tensor([11654, 42070,  7716, 11625,  1808, 32158, 32157, 11640,  8011, 32160]))\n",
      "55077\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6895, 0.6425, 0.6407, 0.6206, 0.6127, 0.5923, 0.5864, 0.5838, 0.5833,\n",
      "        0.5691]),\n",
      "indices=tensor([42312, 42303, 34975,  1010, 26475, 32536, 37943, 21825,  7488, 36648]))\n",
      "55082\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6834, 0.5529, 0.5526, 0.5300, 0.5123, 0.5031, 0.4981, 0.4976, 0.4972,\n",
      "        0.4960]),\n",
      "indices=tensor([34569, 43263,  4496, 35351, 38346, 42353,  3590, 36266, 42730, 25581]))\n",
      "55083\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.8580, 0.8061, 0.7414, 0.7414, 0.7285, 0.7233, 0.7228, 0.7216, 0.7156,\n",
      "        0.7111]),\n",
      "indices=tensor([28019, 50267, 30666,  7775, 34256, 12182, 11572, 41206,  5630, 21748]))\n",
      "55085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5456, 0.4424, 0.4154, 0.4146, 0.4040, 0.3986, 0.3967, 0.3960, 0.3945,\n",
      "        0.3934]),\n",
      "indices=tensor([36081, 11787, 16748, 28049, 21195, 44487, 19146, 19381,  7277, 46863]))\n",
      "55087\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6777, 0.6539, 0.6435, 0.6342, 0.6226, 0.6193, 0.6134, 0.6084, 0.6082,\n",
      "        0.5913]),\n",
      "indices=tensor([19318, 15933, 20626, 45500,  6499, 24318,  1726, 24880, 44441, 50151]))\n",
      "55089\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7901, 0.7809, 0.7641, 0.7532, 0.7485, 0.7477, 0.7418, 0.7401, 0.7353,\n",
      "        0.7347]),\n",
      "indices=tensor([34753,  1764, 16438, 50396, 26757, 28677, 23981, 46288, 42646, 22570]))\n",
      "55090\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7680, 0.6298, 0.5865, 0.5753, 0.5685, 0.5659, 0.5481, 0.5416, 0.5297,\n",
      "        0.5261]),\n",
      "indices=tensor([32492, 11406, 39333, 35239, 47703, 10934, 43825, 41035, 41038, 10943]))\n",
      "55092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7054, 0.7004, 0.6873, 0.6731, 0.6555, 0.6538, 0.6450, 0.6234, 0.6194,\n",
      "        0.6054]),\n",
      "indices=tensor([24571,  2333,  5284, 39056, 28778, 32457,  8448, 39515, 23461,  5067]))\n",
      "55093\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5264, 0.4882, 0.4833, 0.4814, 0.4667, 0.4640, 0.4613, 0.4509, 0.4490,\n",
      "        0.4378]),\n",
      "indices=tensor([34179, 48148, 22568, 41054, 43275, 47760, 36289, 29151, 47546, 38761]))\n",
      "55094\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5602, 0.5568, 0.5558, 0.5534, 0.5507, 0.5165, 0.4999, 0.4960, 0.4917,\n",
      "        0.4914]),\n",
      "indices=tensor([45391, 19371, 50905, 43958, 15817,   237, 19117,  9234,  2834, 28160]))\n",
      "55095\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6026, 0.5643, 0.5566, 0.5442, 0.5381, 0.5372, 0.5352, 0.5351, 0.5350,\n",
      "        0.5324]),\n",
      "indices=tensor([22164, 28781, 32604, 39381, 38417, 49745,  7052, 24091, 40488, 10925]))\n",
      "55096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.7322, 0.5785, 0.5384, 0.5365, 0.5140, 0.5105, 0.5056, 0.5009, 0.4985,\n",
      "        0.4885]),\n",
      "indices=tensor([40221,  4496, 43352, 24693, 28668,  5797, 50183, 36227,  9883, 13427]))\n",
      "55097\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.7410, 0.6750, 0.6420, 0.6040, 0.5883, 0.5759, 0.5614, 0.5497, 0.5460,\n",
      "        0.5343]),\n",
      "indices=tensor([43352,  4496, 40221, 24693, 34569,  5797,  9883, 48920, 47182, 50183]))\n",
      "55098\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6306, 0.6258, 0.6008, 0.5991, 0.5857, 0.5804, 0.5678, 0.5620, 0.5570,\n",
      "        0.5499]),\n",
      "indices=tensor([36458, 39072, 42997, 36446, 47931, 34852, 34278, 30595, 44925,  3676]))\n",
      "55099\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6000, 0.5486, 0.5447, 0.5376, 0.5130, 0.5069, 0.4983, 0.4861, 0.4823,\n",
      "        0.4816]),\n",
      "indices=tensor([49728, 16943, 23647, 22366, 42548, 10079, 49755,  2000,  8358, 15368]))\n",
      "55100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5561, 0.5531, 0.5504, 0.5485, 0.5482, 0.5414, 0.5352, 0.5347, 0.5345,\n",
      "        0.5296]),\n",
      "indices=tensor([34489,  6342, 13004, 15336, 16941, 24907, 31628, 15370,  2011, 46282]))\n",
      "55101\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5337, 0.5218, 0.4986, 0.4968, 0.4865, 0.4732, 0.4721, 0.4590, 0.4540,\n",
      "        0.4509]),\n",
      "indices=tensor([30838, 43425, 50203,  3305, 38738, 46746, 18369,  4406, 35237, 20340]))\n",
      "55102\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6848, 0.6760, 0.6738, 0.6570, 0.6560, 0.6546, 0.6493, 0.6437, 0.6414,\n",
      "        0.6414]),\n",
      "indices=tensor([43299, 50650, 38879, 42037, 37471, 40131, 41655, 30503,  4099,  8274]))\n",
      "55104\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6069, 0.5964, 0.5938, 0.5908, 0.5879, 0.5855, 0.5835, 0.5758, 0.5667,\n",
      "        0.5633]),\n",
      "indices=tensor([23560, 37610,  7261,  5921, 23814,  4397, 26112, 21275, 43961, 35376]))\n",
      "55105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.6316, 0.5821, 0.5734, 0.5668, 0.5663, 0.5518, 0.5384, 0.5190, 0.5151,\n",
      "        0.4994]),\n",
      "indices=tensor([14983,  9490, 35543, 47991,  3375,  9577, 15408, 15440, 50479, 38517]))\n",
      "55106\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5039, 0.4870, 0.4820, 0.4796, 0.4757, 0.4593, 0.4399, 0.4215, 0.4181,\n",
      "        0.4153]),\n",
      "indices=tensor([ 7928, 42277, 19897, 47983, 42111, 47417, 44152, 45447,  7146, 27495]))\n",
      "55107\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.5889, 0.5627, 0.5543, 0.5516, 0.5492, 0.5353, 0.5226, 0.5159, 0.5149,\n",
      "        0.5142]),\n",
      "indices=tensor([ 2729, 31779, 18589, 45756, 31360, 39849, 32465, 10718, 43062, 14795]))\n",
      "55108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
      "/tmp/ipykernel_1218752/3773668800.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(idx)\n\u001b[1;32m      7\u001b[0m test_embed \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(row\u001b[38;5;241m.\u001b[39missue_title)\n\u001b[0;32m----> 8\u001b[0m cos \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m topk \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(torch\u001b[38;5;241m.\u001b[39mtensor(cos[\u001b[38;5;241m0\u001b[39m]), k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(topk)\n",
      "File \u001b[0;32m~/miniconda3/envs/trx/lib/python3.10/site-packages/sentence_transformers/util.py:49\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     46\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m a_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(a, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m b_norm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmm(a_norm, b_norm\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_matches = 0\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    # print(row.issue_title)\n",
    "    print(idx)\n",
    "\n",
    "    test_embed = model.encode(row.issue_title)\n",
    "    cos = util.cos_sim(test_embed, all_embeddings)\n",
    "    topk = torch.topk(torch.tensor(cos[0]), k=10)\n",
    "    print(topk)\n",
    "\n",
    "    similar = X_df.iloc[topk.indices.numpy()][[\"issue_title\", \"owner\"]]\n",
    "\n",
    "    if row.owner in list(similar.owner.unique()):\n",
    "        # print(\"Match found\")\n",
    "        # print(row.owner, similar.owner)\n",
    "        total_matches += 1\n",
    "\n",
    "    # print(f\"Target: {row.owner}\")\n",
    "    # print(f\"Found: {similar.owner.to_list()}\")\n",
    "    # print(\"\\n\\n\")\n",
    "\n",
    "    # print(X_df.iloc[topk.indices.numpy()][[\"issue_title\", \"owner\"]])\n",
    "\n",
    "\n",
    "    # print(row.issue_title, row.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "owner                                       jcampan@chromium.org\n",
       "issue_title                  CRASH: searching on news.google.com\n",
       "description    \\nCRASH: searching on news.google.com\\r\\n\\r\\nU...\n",
       "Name: 5736, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.iloc[5502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4392065084141313"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_matches/len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1140731/2233454408.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  topk = torch.topk(torch.tensor(cos[0]), k=5)\n"
     ]
    }
   ],
   "source": [
    "0.4711913518332776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_title</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>shill: 3g dongles: don't run dhcpcd on ppp links</td>\n",
       "      <td>quiche@chromium.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>Failed to play mp3 music on the App:Files</td>\n",
       "      <td>mtomasz@chromium.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>Don't show accidental search infobar for bookm...</td>\n",
       "      <td>isherman@chromium.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>webNavigation onCreatedNavigationTarget doesn'...</td>\n",
       "      <td>jochen@chromium.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mp4 files with moof atom dont play</td>\n",
       "      <td>fbarchard@chromium.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            issue_title  \\\n",
       "4786   shill: 3g dongles: don't run dhcpcd on ppp links   \n",
       "7546          Failed to play mp3 music on the App:Files   \n",
       "8428  Don't show accidental search infobar for bookm...   \n",
       "9003  webNavigation onCreatedNavigationTarget doesn'...   \n",
       "31                   mp4 files with moof atom dont play   \n",
       "\n",
       "                       owner  \n",
       "4786     quiche@chromium.org  \n",
       "7546    mtomasz@chromium.org  \n",
       "8428   isherman@chromium.org  \n",
       "9003     jochen@chromium.org  \n",
       "31    fbarchard@chromium.org  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Don't ship example sound files (1.3MB) installed by alsa-utils\",\n",
       " 'de...@chromium.org')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.encode(sentence1, convert_to_tensor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977022409439087"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens = tokenizer(str(sentence1), max_length=50, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "# encodings1 = encoder(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])\n",
    "\n",
    "# tokens = tokenizer(str(sentence2), max_length=50, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "# encodings2 = encoder(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])\n",
    "\n",
    "# util.pytorch_cos_sim(encodings1.pooler_output[0].cpu().detach(), encodings2.pooler_output[0].cpu().detach()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8778e-01,  1.7355e-01,  2.1240e-01,  1.1607e-01, -6.4882e-02,\n",
       "        -4.1916e-01,  3.1011e-01,  3.2231e-01, -7.3365e-02, -4.8741e-02,\n",
       "        -1.9027e-01,  9.3727e-02,  8.0243e-02,  1.3210e-01, -1.2497e-01,\n",
       "        -1.1492e-01,  2.6302e-02,  6.3775e-03, -7.7349e-02, -2.1205e-01,\n",
       "         2.4901e-01, -2.4632e-02, -5.1050e-02, -9.8065e-02,  4.6330e-01,\n",
       "         9.7453e-02,  1.3215e-01, -2.7845e-01, -3.4513e-01, -1.7305e-03,\n",
       "        -2.3607e-02,  3.4116e-01, -2.8000e-02,  2.5268e-02, -1.5155e-01,\n",
       "        -8.6437e-05, -3.0130e-01,  2.4454e-01, -8.8204e-02, -2.7867e-01,\n",
       "         1.6598e-01,  2.4728e-01,  1.3855e-01,  1.9302e-02, -1.3854e-01,\n",
       "         3.9041e-01,  5.8220e-02,  4.8500e-01, -2.9421e-01, -2.2585e-02,\n",
       "         2.6137e-01,  2.7570e-01, -8.3157e-02,  1.2487e-01, -4.9683e-02,\n",
       "         6.1158e-01, -1.1188e-01, -3.7462e-01, -9.8203e-02, -2.6143e-01,\n",
       "         2.6483e-01, -3.5074e-01, -1.2012e-01, -1.0044e-02,  1.3767e-02,\n",
       "        -2.5773e-01,  1.2054e-01,  2.4969e-01,  1.5549e-01, -2.0992e-01,\n",
       "         7.1286e-02, -4.3874e-01,  9.0930e-02, -3.0922e-01,  3.5943e-01,\n",
       "        -9.2072e-03, -1.2369e-01,  2.2890e-02,  3.7265e-01,  4.1106e-01,\n",
       "         3.5067e-01,  1.2685e-01,  1.0722e-01,  1.7121e-01,  1.1285e-01,\n",
       "        -3.1865e-01,  5.8751e-01, -1.3211e-01,  1.6609e-01,  3.1549e-01,\n",
       "        -1.5279e-01,  3.6567e-01,  1.2827e-01,  1.3563e-01, -6.9633e-02,\n",
       "        -3.2426e-01,  3.5972e-02,  1.4177e-01, -5.0602e-01, -6.6437e-02,\n",
       "         1.3157e-01,  3.1319e-01, -2.1175e-01,  3.1399e-01, -2.3187e-01,\n",
       "         1.4252e-01, -2.2385e-02,  6.5652e-02, -4.5006e-02, -2.7711e-01,\n",
       "         1.8104e-01, -4.4167e-01,  1.0565e-01,  1.6806e-01, -1.8135e-01,\n",
       "         2.1454e-01,  3.7210e-01,  2.3757e-01,  5.2324e-02, -1.1959e-01,\n",
       "        -3.0206e-01,  1.7441e-01,  3.6388e-02, -7.5571e-02,  1.0170e-01,\n",
       "        -1.1293e-01, -6.8885e-02, -8.8854e-03,  1.1329e-01, -8.8475e-02,\n",
       "         2.0071e-01, -5.3633e-01, -1.1242e-01,  3.0242e-01,  3.1150e-02,\n",
       "        -1.7271e-02,  1.7563e-01, -1.1661e-01,  1.7982e-01,  2.4122e-02,\n",
       "         4.2195e-01,  1.6122e-01, -1.3343e-01,  4.9038e-02,  3.3103e-01,\n",
       "        -2.4939e-01,  1.0160e-01, -4.3789e-02,  1.8100e-01, -4.7922e-02,\n",
       "        -2.4301e-01, -2.6200e-02,  1.7682e-01, -3.2677e-01, -3.2360e-02,\n",
       "         2.7986e-01, -3.2582e-02,  1.8157e-01,  1.8829e-01, -4.4751e-02,\n",
       "        -1.0138e-01,  2.5273e-01,  1.8083e-01, -1.2031e-01,  1.4143e-01,\n",
       "         1.3689e-01,  1.7997e-01, -1.9495e-01, -1.7357e-01,  2.6327e-01,\n",
       "        -1.2577e-01,  2.3164e-01,  5.7958e-02, -1.4614e-01,  1.7105e-01,\n",
       "        -2.0599e-01,  2.8421e-01,  3.7630e-01,  2.6185e-03, -4.6783e-02,\n",
       "        -2.4031e-01,  2.0721e-01,  7.1043e-03,  2.0623e-01,  1.1138e-01,\n",
       "        -8.3942e-02,  1.3086e-01, -5.8647e-01,  5.1579e-03, -2.9591e-01,\n",
       "         1.8850e-01,  2.7652e-01,  1.8521e-01, -1.5191e-01,  1.7250e-01,\n",
       "         1.6189e-01,  3.0881e-01, -2.6864e-01,  1.7537e-01, -4.7530e-01,\n",
       "        -2.1111e-01, -1.0920e-02, -2.9836e-01, -1.6501e-01,  1.4400e-01,\n",
       "         1.5486e-01,  5.7474e-02, -7.3618e-02,  3.7822e-01,  2.1965e-01,\n",
       "         1.7526e-01,  2.5892e-01, -5.0420e-02,  1.2886e-01,  7.6784e-02,\n",
       "         2.4427e-01, -4.1475e-02, -1.1346e-01, -3.5893e-01,  8.0084e-03,\n",
       "         4.9541e-02, -1.3037e-03,  7.7865e-02,  1.1363e-01, -1.1741e-01,\n",
       "         3.1565e-03,  1.2398e-01,  4.3397e-02,  1.6966e-01,  2.3911e-01,\n",
       "         2.4968e-01,  3.8330e-01,  6.3555e-02, -2.2192e-01, -6.4787e-02,\n",
       "        -2.2374e-01, -2.1446e-02,  1.9186e-02,  1.6460e-01, -9.2124e-02,\n",
       "        -1.5520e-01, -4.4339e-02,  4.3381e-01, -4.0068e-01, -2.6174e-02,\n",
       "        -2.6851e-01,  5.5628e-02,  2.5258e-01,  1.4467e-02,  5.0912e-02,\n",
       "        -7.4222e-02, -8.8930e-02, -1.4334e-01, -1.8667e-01,  1.1831e-01,\n",
       "        -1.1121e-01,  1.6895e-01, -7.5643e-02, -3.6731e-01, -3.4346e-01,\n",
       "        -2.7817e-01, -2.2844e-01, -3.8922e-01,  8.4927e-02, -1.8238e-01,\n",
       "         3.0080e-01,  1.9108e-01, -8.3571e-02,  1.0439e-01, -4.4269e-02,\n",
       "         5.0459e-02, -2.2650e-02,  1.0612e-01, -2.0667e-01, -6.0649e-02,\n",
       "        -3.3093e-02, -4.0822e-01,  3.1904e-01,  8.8766e-02,  3.3571e-01,\n",
       "        -3.7187e-01,  2.6618e-01,  1.3910e-01, -2.4912e-01, -9.7306e-02,\n",
       "        -1.1930e-01,  1.0432e-01, -3.1485e-02,  2.5803e-02, -4.7550e-01,\n",
       "         1.7479e-01,  2.5029e-01,  1.6394e-01,  1.3107e-01, -2.3076e-01,\n",
       "        -3.1297e-01,  1.6920e-02,  3.0341e-01,  1.6452e-01,  1.3435e-01,\n",
       "        -2.5785e-01,  1.6371e-01, -2.5827e-01, -7.8887e-02,  5.6322e-02,\n",
       "         1.0598e-01,  2.3148e-01,  2.4739e-01,  1.1518e-01, -5.6678e-01,\n",
       "        -7.9077e-02,  4.6786e-02, -1.0346e-01,  2.9042e-02,  2.0310e-01,\n",
       "         1.1289e-01, -1.6226e-01,  1.4949e-01,  1.6508e-01, -1.7774e-02,\n",
       "        -3.4298e-01, -3.7281e-01, -3.3698e-01,  1.5043e-01,  1.1500e-01,\n",
       "         1.8974e-01,  3.9935e-01,  2.3307e-01,  1.4086e-01,  1.2736e-01,\n",
       "        -2.4506e-01,  4.8055e-02, -5.8528e-02,  1.1275e-01, -2.5243e-01,\n",
       "        -2.6866e-01, -8.1820e-02,  7.0200e-02,  6.1464e-02, -5.0218e-02,\n",
       "         2.6623e-01,  7.1168e-02, -2.4350e-02,  4.7023e-01, -1.5217e-01,\n",
       "        -1.1479e-01, -1.9367e-01, -8.3496e-02,  1.8930e-01, -9.0477e-02,\n",
       "         7.8704e-03, -5.0321e-01,  1.6934e-02, -6.8810e-02,  1.6940e-01,\n",
       "         9.9774e-02,  4.2428e-02, -1.5245e-02, -4.0693e-01,  1.8954e-01,\n",
       "        -7.9505e-02,  3.5036e-01, -1.9146e-01,  1.9586e-01, -1.0500e-01,\n",
       "        -2.0537e-01,  5.6683e-02,  2.6505e-02,  2.2039e-01,  1.6992e-01,\n",
       "         3.2908e-01, -1.3686e-01, -1.2084e-01, -1.3178e-01,  6.8766e-02,\n",
       "         3.1521e-01,  1.4039e-02, -1.0933e-01,  6.4165e-02, -3.1315e-01,\n",
       "         1.3888e-01, -1.8388e-01,  9.5703e-02,  9.3979e-02, -3.2569e-01,\n",
       "         7.0479e-03,  1.6438e-01, -1.4011e-01,  1.2008e-01, -2.4180e-01,\n",
       "        -4.3086e-02, -8.7123e-02, -5.1471e-02, -9.8375e-02, -3.1486e-01,\n",
       "        -1.2152e-01, -4.9182e-01,  9.0977e-02,  1.9817e-02,  1.8829e-01,\n",
       "         2.7026e-03,  2.3614e-03, -3.8065e-02,  2.6951e-01,  8.9039e-02,\n",
       "        -1.3697e-01, -4.1522e-01, -1.6419e-02, -9.3682e-02, -3.2617e-02,\n",
       "         1.3690e-01, -3.4733e-01, -4.3141e-02, -2.0413e-01,  1.4401e-01,\n",
       "        -1.1781e-02,  3.1069e-01,  8.8701e-02,  5.1351e-02, -2.4442e-01,\n",
       "        -7.4539e-02,  1.0970e-01, -1.8457e-01,  4.3075e-01, -3.3599e-01,\n",
       "         1.8771e-01,  5.8737e-02,  4.2806e-01,  1.6776e-01, -4.1658e-01,\n",
       "        -3.8266e-01, -3.9848e-02,  8.0329e-02,  3.2660e-01,  2.4214e-01,\n",
       "        -2.7902e-01,  6.4418e-02,  4.3189e-01, -1.0491e-01,  1.3575e-01,\n",
       "         2.9684e-02, -1.0965e-01,  1.4541e-01,  2.7164e-01,  1.2146e-01,\n",
       "         1.6234e-01,  2.5517e-01, -5.4354e-02, -3.3444e-01, -2.7198e-01,\n",
       "         1.9619e-01,  1.7620e-01,  3.1398e-02,  4.7495e-01,  1.6934e-01,\n",
       "        -2.8137e-02, -3.9828e-01,  3.1520e-01, -5.6256e-02, -1.6190e-02,\n",
       "        -1.8588e-01,  1.3782e-01,  4.7759e-02,  4.2530e-01,  2.9187e-01,\n",
       "        -8.6143e-02, -4.2422e-02,  1.1109e-01,  1.2418e-02,  2.1191e-01,\n",
       "         4.2258e-02,  1.9169e-01,  2.4069e-01, -3.1372e-01, -1.0590e-01,\n",
       "         3.8425e-01, -5.8371e-02,  1.3641e-01, -2.2634e-01,  2.2701e-01,\n",
       "         4.3964e-01,  6.9671e-02,  7.9008e-02,  2.8761e-01, -2.1512e-01,\n",
       "         2.2662e-01, -1.3391e-01,  2.4464e-01,  7.3497e-02,  6.0770e-02,\n",
       "        -7.6773e-02, -7.5431e-02, -8.5167e-02, -2.7371e-01, -7.3583e-02,\n",
       "        -4.7881e-01,  1.1171e-02, -6.9418e-02, -3.2032e-01,  5.0731e-02,\n",
       "         8.9861e-02, -3.2007e-01,  1.1352e-02, -1.1811e-01, -2.0765e-01,\n",
       "         3.3160e-01, -2.0439e-01,  2.2826e-01,  2.9770e-01, -1.8842e-02,\n",
       "         1.1259e-01, -2.3784e-01,  3.3630e-01, -2.1036e-01,  2.6353e-01,\n",
       "         1.9533e-01,  8.4846e-02, -1.9231e-01,  6.9652e-02, -2.5567e-01,\n",
       "         2.5469e-01,  4.9908e-02, -1.9522e-01,  3.4204e-01, -3.5193e-02,\n",
       "         5.2654e-01,  1.2866e-01, -1.5482e-01, -4.2503e-01,  1.2790e-01,\n",
       "         2.9377e-01,  7.0470e-02,  2.3217e-01,  2.1835e-01,  3.0616e-02,\n",
       "         2.2322e-01, -1.1096e-01, -1.6762e-01, -5.9661e-01,  7.4492e-02,\n",
       "         1.1174e-01,  6.6950e-02, -5.1200e-02,  2.1923e-01,  6.9534e-02,\n",
       "         6.2030e-03, -1.7973e-02, -4.3663e-02, -8.1348e-02,  1.4495e-01,\n",
       "        -2.1449e-01,  1.9930e-01, -1.1254e-01, -4.4663e-02, -2.9584e-01,\n",
       "        -2.3416e-01,  2.7493e-01,  2.2336e-01, -3.8974e-01,  2.5578e-01,\n",
       "         1.1864e-01, -1.2314e-01,  1.1653e-01,  1.8351e-01,  2.1269e-01,\n",
       "         1.8400e-01, -8.9127e-03, -1.7249e-01,  1.0028e-01,  2.8275e-02,\n",
       "         5.6264e-02,  2.7839e-01,  1.0045e-01,  2.0522e-01,  3.2580e-02,\n",
       "         1.2752e-01, -8.4022e-02, -2.4739e-01,  1.3914e-01,  7.5286e-02,\n",
       "         2.6132e-02, -5.4766e-02,  1.6539e-01, -6.3648e-01,  3.2649e-02,\n",
       "         1.8220e-01,  2.2473e-01,  4.0722e-02,  1.3211e-01,  3.6089e-01,\n",
       "         3.5658e-02, -2.4128e-01,  1.6995e-01, -2.1217e-03, -1.5543e-01,\n",
       "         9.1748e-02, -7.1851e-02, -2.0229e-01,  9.9393e-02, -3.9231e-01,\n",
       "        -3.6233e-02,  1.1293e-01,  4.9993e-02, -1.9932e-01,  3.1111e-01,\n",
       "         1.9019e-01, -1.1083e-01, -2.7646e-01, -5.5817e-02, -6.1365e-02,\n",
       "        -1.8416e-01,  4.0929e-01, -1.2805e-01,  3.7673e-02,  9.3454e-02,\n",
       "         7.3639e-02,  1.4765e-01,  1.3650e-01,  2.0754e-01, -1.7379e-01,\n",
       "        -2.3902e-02, -2.2186e-01,  8.4003e-02,  7.9298e-02,  2.6474e-01,\n",
       "         1.4413e-01, -2.9880e-01, -1.9004e-02, -1.3332e-01, -1.4228e-01,\n",
       "        -1.5470e-01, -2.8255e-01, -3.3759e-02,  3.0576e-01,  9.3451e-02,\n",
       "        -1.4732e-01, -2.6824e-01,  3.8702e-02, -2.2035e-01, -1.4487e-01,\n",
       "         4.3223e-02,  2.3220e-01, -9.0397e-02,  2.1214e-01, -2.8818e-02,\n",
       "         6.1905e-02, -4.2104e-02,  2.4473e-02,  5.1729e-02, -3.9428e-02,\n",
       "        -3.0002e-01, -4.1359e-03,  3.6690e-02,  2.8930e-02, -2.5273e-01,\n",
       "        -2.2192e-01,  4.0819e-01,  5.6207e-02, -1.7885e-01,  8.5702e-02,\n",
       "         2.1543e-01,  3.0145e-01, -4.3882e-01,  8.6647e-02,  3.4249e-02,\n",
       "        -1.4641e-01, -1.6618e-01, -6.3208e-02, -3.8343e-03,  1.8712e-01,\n",
       "        -4.6026e-02, -1.3212e-01,  2.3761e-02, -6.2648e-01, -1.2699e-01,\n",
       "        -1.5283e-01,  2.7701e-01,  1.6818e-01,  3.5300e-02, -3.9758e-01,\n",
       "         3.0291e-01,  4.0898e-01, -9.2186e-02,  1.0626e-01,  3.3333e-01,\n",
       "        -1.9108e-01,  1.0245e-01, -7.9356e-02, -1.9375e-01, -1.5428e-01,\n",
       "         1.2694e-02, -1.2087e-01, -2.5904e-01,  4.8081e-02, -3.3935e-01,\n",
       "         2.5476e-01,  3.3252e-01, -1.4671e-01,  3.7196e-01,  3.7713e-01,\n",
       "        -3.6474e-02, -2.7259e-01,  1.4019e-01,  1.5765e-01,  1.4338e-01,\n",
       "        -9.8180e-03, -5.1711e-01, -1.2628e-01, -2.0524e-02,  7.8897e-02,\n",
       "         1.4570e-01,  4.9860e-02, -3.4385e-01,  1.5685e-02, -1.7310e-01,\n",
       "         4.3547e-02, -2.7776e-01, -6.4952e-02,  5.4295e-01,  5.9469e-02,\n",
       "        -5.9097e-02,  1.3207e-01,  2.4541e-01, -1.5713e-01, -1.1924e-01,\n",
       "        -9.5536e-02, -1.2195e-01, -4.8611e-02, -3.2120e-01, -3.3704e-01,\n",
       "        -1.2765e-02, -2.9911e-01,  1.6732e-01, -2.7346e-01, -1.1385e-01,\n",
       "         1.8662e-01, -3.3832e-01, -8.2905e-02,  8.3249e-02, -3.9070e-02,\n",
       "         7.5209e-02,  1.2343e-02,  8.5485e-02, -6.3620e-02,  3.0091e-01,\n",
       "        -5.8024e-02, -1.5229e-01,  2.9249e-01,  2.9633e-01,  3.3644e-01,\n",
       "        -3.4495e-01, -2.6414e-01, -2.4734e-01,  7.8380e-02,  1.0674e-01,\n",
       "         6.3303e-02,  2.0818e-01,  6.0449e-02, -1.4893e-01,  1.6115e-01,\n",
       "        -4.3428e-01,  2.7068e-01,  2.3959e-01,  2.8596e-02, -2.6487e-02,\n",
       "        -2.5655e-01,  1.4789e-01, -8.2447e-02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings1.pooler_output[0].cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7030/7030 [12:55<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "max_tokens = 50\n",
    "\n",
    "for _, row in tqdm(X_df.iterrows(), total=len(X_df)):\n",
    "    text = row.issue_title\n",
    "    tokens = tokenizer(str(text), max_length=max_tokens, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    encodings = encoder(input_ids=tokens[\"input_ids\"], attention_mask=tokens[\"attention_mask\"])\n",
    "    pooler_out = encodings.pooler_output.squeeze(0).cpu().detach().numpy()\n",
    "    \n",
    "    X.append(pooler_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"embeddings\"] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>description</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amit@chromium.org</td>\n",
       "      <td>Scrolling with some scroll mice (touchpad, etc...</td>\n",
       "      <td>\\nProduct Version      : &lt;see about:version&gt;\\r...</td>\n",
       "      <td>[0.3622683, 0.014743308, 0.08317446, 0.1922355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Proxy causes some or all network requests to fail</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "      <td>[0.37318918, 0.029505463, 0.092881486, 0.20365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfeldman@chromium.org</td>\n",
       "      <td>Web inspector button \"dock to main window\" doe...</td>\n",
       "      <td>\\nProduct Version      : chrome beta 1\\r\\nURLs...</td>\n",
       "      <td>[0.36826685, 0.019743465, 0.07911971, 0.197896...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jon@chromium.org</td>\n",
       "      <td>Habari admin interface is not rendered correctly</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27 (1583)\\r\\n...</td>\n",
       "      <td>[0.36389366, 0.032136887, 0.108592205, 0.22007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkasting@chromium.org</td>\n",
       "      <td>Maximize on second larger monitor not working</td>\n",
       "      <td>\\nProduct Version      : 0.2.149.27\\r\\nURLs (i...</td>\n",
       "      <td>[0.3730424, 0.020901347, 0.094066195, 0.214888...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   owner                                        issue_title  \\\n",
       "0      amit@chromium.org  Scrolling with some scroll mice (touchpad, etc...   \n",
       "1       jon@chromium.org  Proxy causes some or all network requests to fail   \n",
       "2  pfeldman@chromium.org  Web inspector button \"dock to main window\" doe...   \n",
       "3       jon@chromium.org   Habari admin interface is not rendered correctly   \n",
       "4  pkasting@chromium.org      Maximize on second larger monitor not working   \n",
       "\n",
       "                                         description  \\\n",
       "0  \\nProduct Version      : <see about:version>\\r...   \n",
       "1  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...   \n",
       "2  \\nProduct Version      : chrome beta 1\\r\\nURLs...   \n",
       "3  \\nProduct Version      : 0.2.149.27 (1583)\\r\\n...   \n",
       "4  \\nProduct Version      : 0.2.149.27\\r\\nURLs (i...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.3622683, 0.014743308, 0.08317446, 0.1922355...  \n",
       "1  [0.37318918, 0.029505463, 0.092881486, 0.20365...  \n",
       "2  [0.36826685, 0.019743465, 0.07911971, 0.197896...  \n",
       "3  [0.36389366, 0.032136887, 0.108592205, 0.22007...  \n",
       "4  [0.3730424, 0.020901347, 0.094066195, 0.214888...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_json(\"dt_gc20_block1_thresh20.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  7 22:32:48 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              36W / 250W |      4MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0, n_init=\"auto\").fit(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"cluster\"]= kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = X_df[X_df[\"cluster\"] == 4]\n",
    "len(cl[\"owner\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
