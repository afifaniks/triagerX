{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from triagerx.dataset.processor import DatasetProcessor\n",
    "from triagerx.model.lbt_p import LBTPClassifier\n",
    "from triagerx.model.roberta_cnn import RobertaCNNClassifier\n",
    "from triagerx.model.roberta_fcn import RobertaFCNClassifier\n",
    "from triagerx.trainer.model_trainer import ModelTrainer\n",
    "from triagerx.trainer.train_config import TrainConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/deeptriage/gc_20.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues: 109979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/deeptriage/gc_20.json\"\n",
    "\n",
    "df = pd.read_json(dataset_path)\n",
    "df = df[df[\"owner\"].notna()]\n",
    "\n",
    "def clean_data(df):\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def prepare_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"text\"] = df.apply(\n",
    "            lambda x: \"Title: \"\n",
    "            + str(x[\"issue_title\"])\n",
    "            + \"\\nDescription: \"\n",
    "            + str(x[\"description\"]),\n",
    "            axis=1,\n",
    "        )\n",
    "    \n",
    "    min_length = 15\n",
    "    df = df[df[\"text\"].str.len().gt(min_length)]\n",
    "\n",
    "    # df[\"owner_id\"] = pd.factorize(df[\"assignees\"])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_dataframe(df)\n",
    "df = clean_data(df)\n",
    "\n",
    "num_issues = len(df)\n",
    "\n",
    "print(f\"Total number of issues: {num_issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per block: 10998\n",
      "Training data: 7030, Validation data: 6095\n"
     ]
    }
   ],
   "source": [
    "num_cv = 10\n",
    "sample_threshold=20\n",
    "samples_per_block = len(df) // num_cv + 1\n",
    "print(f\"Samples per block: {samples_per_block}\")\n",
    "\n",
    "block = 1\n",
    "X_df = df[:samples_per_block*block]\n",
    "y_df = df[samples_per_block*block : samples_per_block * (block+1)]\n",
    "\n",
    "\n",
    "developers = X_df[\"owner\"].value_counts()\n",
    "filtered_developers = developers.index[developers >= sample_threshold]\n",
    "X_df = X_df[X_df[\"owner\"].isin(filtered_developers)]\n",
    "\n",
    "train_owners = set(X_df[\"owner\"])\n",
    "test_owners = set(y_df[\"owner\"])\n",
    "\n",
    "unwanted = list(test_owners - train_owners)\n",
    "\n",
    "y_df = y_df[~y_df[\"owner\"].isin(unwanted)]\n",
    "\n",
    "print(f\"Training data: {len(X_df)}, Validation data: {len(y_df)}\")\n",
    "\n",
    "lbl2idx = {}\n",
    "\n",
    "for idx, dev in enumerate(train_owners):\n",
    "    lbl2idx[dev] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"owner_id\"] = X_df[\"owner\"].apply(lambda owner: lbl2idx[owner])\n",
    "y_df[\"owner_id\"] = y_df[\"owner\"].apply(lambda owner: lbl2idx[owner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LBTPClassifier(\n",
    "    output_size=len(X_df.owner_id.unique())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount(X_df[\"owner_id\"])\n",
    "num_samples = sum(class_counts)\n",
    "labels = X_df[\"owner_id\"].to_list() #corresponding labels of samples\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 50\n",
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_name = sampler.__class__.__name__ if sampler else \"None\"\n",
    "model_name = model.__class__.__name__\n",
    "\n",
    "output_file = f\"dt_lbtp_cv{block}_{model_name}_20_{sampler_name}\"\n",
    "output_path = f\"/home/mdafifal.mamun/notebooks/triagerX/output/{output_file}.pt\"\n",
    "\n",
    "wandb_config = {\n",
    "        \"project\": \"triagerx_dt_cv\",\n",
    "        \"name\": f\"run_{output_file}\",\n",
    "        \"config\": {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"Roberta-FCN\",\n",
    "        \"dataset\": \"deeptriage\",\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    "}\n",
    "\n",
    "criterion = CombineLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=10, factor=0.1, threshold=1e-8)\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_dataset=X_df,\n",
    "    validation_dataset=y_df,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    output_file=output_path,\n",
    "    sampler=sampler,\n",
    "    scheduler=scheduler,\n",
    "    wandb=wandb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-29 14:23:32.948\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.dataset.triage_dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-01-29 14:23:32.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.dataset.triage_dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n",
      "\u001b[32m2024-01-29 14:23:43.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.dataset.triage_dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[34m\u001b[1mGenerating torch dataset...\u001b[0m\n",
      "\u001b[32m2024-01-29 14:23:43.877\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.dataset.triage_dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mTokenizing texts...\u001b[0m\n",
      "\u001b[32m2024-01-29 14:23:52.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[34m\u001b[1mInitializing wandb...\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mdafifal.mamun/notebooks/triagerX/wandb/run-20240129_142359-2xrb72mw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/afifaniks/triagerx_dt_cv/runs/2xrb72mw' target=\"_blank\">run_dt_lbtp_cv1_LBTPClassifier_20_WeightedRandomSampler</a></strong> to <a href='https://wandb.ai/afifaniks/triagerx_dt_cv' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/afifaniks/triagerx_dt_cv' target=\"_blank\">https://wandb.ai/afifaniks/triagerx_dt_cv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/afifaniks/triagerx_dt_cv/runs/2xrb72mw' target=\"_blank\">https://wandb.ai/afifaniks/triagerx_dt_cv/runs/2xrb72mw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-29 14:24:06.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[34m\u001b[1mSelected compute device: cuda\u001b[0m\n",
      "  0%|          | 0/469 [00:00<?, ?it/s]/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 14:31:03.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 1 | Train Loss:  1.354                     | Train Accuracy:  0.039                     | Val Loss:  1.330                     | Val Accuracy:  0.047                     | Top 10: 0.2047579983593109                     | Precision:  0.029                     | Recall:  0.036                     | F1-score:  0.015\u001b[0m\n",
      "\u001b[32m2024-01-29 14:31:03.339\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.80it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 14:38:04.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 2 | Train Loss:  1.170                     | Train Accuracy:  0.230                     | Val Loss:  1.182                     | Val Accuracy:  0.127                     | Top 10: 0.4646431501230517                     | Precision:  0.123                     | Recall:  0.117                     | F1-score:  0.084\u001b[0m\n",
      "\u001b[32m2024-01-29 14:38:04.489\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 14:45:04.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 3 | Train Loss:  0.968                     | Train Accuracy:  0.414                     | Val Loss:  1.090                     | Val Accuracy:  0.162                     | Top 10: 0.5356849876948319                     | Precision:  0.183                     | Recall:  0.185                     | F1-score:  0.132\u001b[0m\n",
      "\u001b[32m2024-01-29 14:45:04.880\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 14:52:06.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 4 | Train Loss:  0.808                     | Train Accuracy:  0.515                     | Val Loss:  1.016                     | Val Accuracy:  0.208                     | Top 10: 0.5991796554552912                     | Precision:  0.233                     | Recall:  0.245                     | F1-score:  0.190\u001b[0m\n",
      "\u001b[32m2024-01-29 14:52:06.239\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 14:59:07.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 5 | Train Loss:  0.664                     | Train Accuracy:  0.617                     | Val Loss:  0.965                     | Val Accuracy:  0.225                     | Top 10: 0.6183757178014766                     | Precision:  0.233                     | Recall:  0.259                     | F1-score:  0.203\u001b[0m\n",
      "\u001b[32m2024-01-29 14:59:07.008\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 15:06:08.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 6 | Train Loss:  0.542                     | Train Accuracy:  0.709                     | Val Loss:  0.925                     | Val Accuracy:  0.239                     | Top 10: 0.6525020508613618                     | Precision:  0.237                     | Recall:  0.278                     | F1-score:  0.231\u001b[0m\n",
      "\u001b[32m2024-01-29 15:06:08.121\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:13:09.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 7 | Train Loss:  0.446                     | Train Accuracy:  0.779                     | Val Loss:  0.905                     | Val Accuracy:  0.248                     | Top 10: 0.659064807219032                     | Precision:  0.255                     | Recall:  0.285                     | F1-score:  0.243\u001b[0m\n",
      "\u001b[32m2024-01-29 15:13:09.952\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:20:10.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 8 | Train Loss:  0.352                     | Train Accuracy:  0.844                     | Val Loss:  0.880                     | Val Accuracy:  0.258                     | Top 10: 0.6748154224774405                     | Precision:  0.264                     | Recall:  0.291                     | F1-score:  0.254\u001b[0m\n",
      "\u001b[32m2024-01-29 15:20:10.314\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:27:10.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 9 | Train Loss:  0.281                     | Train Accuracy:  0.890                     | Val Loss:  0.867                     | Val Accuracy:  0.261                     | Top 10: 0.6821985233798196                     | Precision:  0.278                     | Recall:  0.286                     | F1-score:  0.260\u001b[0m\n",
      "\u001b[32m2024-01-29 15:27:10.409\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:34:10.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 10 | Train Loss:  0.213                     | Train Accuracy:  0.930                     | Val Loss:  0.867                     | Val Accuracy:  0.265                     | Top 10: 0.6828547990155865                     | Precision:  0.288                     | Recall:  0.284                     | F1-score:  0.262\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:41:06.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 11 | Train Loss:  0.169                     | Train Accuracy:  0.947                     | Val Loss:  0.858                     | Val Accuracy:  0.273                     | Top 10: 0.6884331419196063                     | Precision:  0.290                     | Recall:  0.286                     | F1-score:  0.269\u001b[0m\n",
      "\u001b[32m2024-01-29 15:41:06.664\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:48:06.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 12 | Train Loss:  0.129                     | Train Accuracy:  0.968                     | Val Loss:  0.859                     | Val Accuracy:  0.271                     | Top 10: 0.6908941755537326                     | Precision:  0.292                     | Recall:  0.275                     | F1-score:  0.262\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 15:55:01.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 13 | Train Loss:  0.099                     | Train Accuracy:  0.976                     | Val Loss:  0.857                     | Val Accuracy:  0.272                     | Top 10: 0.690566037735849                     | Precision:  0.295                     | Recall:  0.279                     | F1-score:  0.268\u001b[0m\n",
      "\u001b[32m2024-01-29 15:55:01.517\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[32m\u001b[1mFound new best model. Saving weights...\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:02:02.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 14 | Train Loss:  0.076                     | Train Accuracy:  0.983                     | Val Loss:  0.866                     | Val Accuracy:  0.274                     | Top 10: 0.6895816242821985                     | Precision:  0.304                     | Recall:  0.273                     | F1-score:  0.265\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:08:57.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 15 | Train Loss:  0.058                     | Train Accuracy:  0.990                     | Val Loss:  0.872                     | Val Accuracy:  0.270                     | Top 10: 0.6877768662838392                     | Precision:  0.295                     | Recall:  0.268                     | F1-score:  0.261\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.82it/s]\n",
      "\u001b[32m2024-01-29 16:15:53.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 16 | Train Loss:  0.045                     | Train Accuracy:  0.991                     | Val Loss:  0.882                     | Val Accuracy:  0.272                     | Top 10: 0.6872846595570139                     | Precision:  0.304                     | Recall:  0.270                     | F1-score:  0.266\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:22:49.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 17 | Train Loss:  0.035                     | Train Accuracy:  0.993                     | Val Loss:  0.889                     | Val Accuracy:  0.274                     | Top 10: 0.6810500410172272                     | Precision:  0.306                     | Recall:  0.267                     | F1-score:  0.264\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 16:29:45.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 18 | Train Loss:  0.028                     | Train Accuracy:  0.995                     | Val Loss:  0.892                     | Val Accuracy:  0.279                     | Top 10: 0.6871205906480722                     | Precision:  0.300                     | Recall:  0.273                     | F1-score:  0.267\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:36:41.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 19 | Train Loss:  0.021                     | Train Accuracy:  0.998                     | Val Loss:  0.905                     | Val Accuracy:  0.277                     | Top 10: 0.6828547990155865                     | Precision:  0.305                     | Recall:  0.268                     | F1-score:  0.264\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:43:38.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 20 | Train Loss:  0.018                     | Train Accuracy:  0.997                     | Val Loss:  0.914                     | Val Accuracy:  0.275                     | Top 10: 0.6843314191960623                     | Precision:  0.311                     | Recall:  0.270                     | F1-score:  0.267\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:50:34.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 21 | Train Loss:  0.012                     | Train Accuracy:  0.999                     | Val Loss:  0.935                     | Val Accuracy:  0.273                     | Top 10: 0.6772764561115668                     | Precision:  0.303                     | Recall:  0.264                     | F1-score:  0.260\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 16:57:30.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 22 | Train Loss:  0.011                     | Train Accuracy:  0.998                     | Val Loss:  0.935                     | Val Accuracy:  0.269                     | Top 10: 0.6813781788351108                     | Precision:  0.308                     | Recall:  0.266                     | F1-score:  0.262\u001b[0m\n",
      "100%|██████████| 469/469 [04:18<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 17:04:26.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 23 | Train Loss:  0.010                     | Train Accuracy:  0.998                     | Val Loss:  0.953                     | Val Accuracy:  0.269                     | Top 10: 0.6769483182936833                     | Precision:  0.316                     | Recall:  0.263                     | F1-score:  0.263\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-01-29 17:11:22.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 24 | Train Loss:  0.008                     | Train Accuracy:  0.998                     | Val Loss:  0.964                     | Val Accuracy:  0.276                     | Top 10: 0.676456111566858                     | Precision:  0.313                     | Recall:  0.262                     | F1-score:  0.261\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 17:18:18.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 25 | Train Loss:  0.006                     | Train Accuracy:  0.999                     | Val Loss:  0.959                     | Val Accuracy:  0.279                     | Top 10: 0.6779327317473339                     | Precision:  0.314                     | Recall:  0.267                     | F1-score:  0.268\u001b[0m\n",
      "100%|██████████| 469/469 [04:19<00:00,  1.81it/s]\n",
      "\u001b[32m2024-01-29 17:25:14.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.trainer.model_trainer\u001b[0m:\u001b[36m_log_step\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpochs: 26 | Train Loss:  0.005                     | Train Accuracy:  0.999                     | Val Loss:  0.957                     | Val Accuracy:  0.283                     | Top 10: 0.6779327317473339                     | Precision:  0.316                     | Recall:  0.272                     | F1-score:  0.271\u001b[0m\n",
      " 34%|███▍      | 160/469 [01:28<02:50,  1.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(train_config)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebooks/triagerX/triagerx/trainer/model_trainer.py:57\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     54\u001b[0m total_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m---> 57\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     mask \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     59\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(train_config)\n",
    "trainer.train(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
