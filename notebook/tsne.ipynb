{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from loguru import logger\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "from triagerx.loss.loss_functions import CombinedLoss\n",
    "from triagerx.trainer.train_config import TrainConfig\n",
    "from triagerx.utils.early_stopping import EarlyStopping\n",
    "import pandas as pd\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
    "from triagerx.dataset.text_processor import TextProcessor\n",
    "from triagerx.model.cnn_transformer import CNNTransformer\n",
    "from triagerx.model.fcn_transformer import FCNTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10781/10781 [00:00<00:00, 1015992.80it/s]\n",
      "\u001b[32m2024-10-25 12:37:00.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.dataset.text_processor\u001b[0m:\u001b[36mprepare_dataframe\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mCleaning text...\u001b[0m\n",
      "100%|██████████| 10781/10781 [00:01<00:00, 5584.60it/s]\n",
      "\u001b[32m2024-10-25 12:37:02.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtriagerx.dataset.text_processor\u001b[0m:\u001b[36mprepare_dataframe\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mAdding description...\u001b[0m\n",
      "100%|██████████| 10781/10781 [00:00<00:00, 115191.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 98165, Validation data: 10781\n",
      "Number of train developers: 986\n",
      "Number of test developers: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/data/google_chromium/classifier_data_20.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df.rename(columns={\"assignees\": \"owner\", \"issue_body\": \"description\"})\n",
    "df = df[df[\"owner\"].notna()]\n",
    "\n",
    "num_cv = 10\n",
    "block = 9\n",
    "# sample_threshold=20 # Threshold to filter developers\n",
    "samples_per_block = len(df) // num_cv\n",
    "\n",
    "sliced_df = df[: samples_per_block * (block + 1)]\n",
    "df_train = sliced_df[: samples_per_block * block]\n",
    "df_test = sliced_df[samples_per_block * block : samples_per_block * (block + 1)]\n",
    "\n",
    "sample_threshold = 20\n",
    "developers = df_train[\"owner\"].value_counts()\n",
    "filtered_developers = developers.index[developers >= sample_threshold]\n",
    "df_train = df_train[df_train[\"owner\"].isin(filtered_developers)]\n",
    "\n",
    "train_owners = set(df_train[\"owner\"])\n",
    "test_owners = set(df_test[\"owner\"])\n",
    "\n",
    "unwanted = list(test_owners - train_owners)\n",
    "\n",
    "df_test = df_test[~df_test[\"owner\"].isin(unwanted)]\n",
    "\n",
    "lbl2idx = {}\n",
    "idx2lbl = {}\n",
    "\n",
    "train_owners = sorted(train_owners)\n",
    "\n",
    "for idx, dev in enumerate(train_owners):\n",
    "    lbl2idx[dev] = idx\n",
    "    idx2lbl[idx] = dev\n",
    "\n",
    "df_train[\"owner_id\"] = df_train[\"owner\"].apply(lambda owner: lbl2idx[owner])\n",
    "df_test[\"owner_id\"] = df_test[\"owner\"].apply(lambda owner: lbl2idx[owner])\n",
    "df_test = TextProcessor.prepare_dataframe(df_test, False, False, True, False, False)\n",
    "\n",
    "print(f\"Training data: {len(df_train)}, Validation data: {len(df_test)}\")\n",
    "print(f\"Number of train developers: {len(df_train.owner.unique())}\")\n",
    "print(f\"Number of test developers: {len(df_test.owner.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer\n",
    "import numpy as np\n",
    "\n",
    "class TriageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer: RobertaTokenizer,\n",
    "        feature: str = \"text\",\n",
    "        target: str = \"owner_id\",\n",
    "        max_tokens: int = 256,\n",
    "    ):\n",
    "        print(\"Generating torch dataset...\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = [label for label in df[target]]\n",
    "        print(\"Tokenizing texts...\")\n",
    "        self.texts = [\n",
    "            self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_tokens,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
