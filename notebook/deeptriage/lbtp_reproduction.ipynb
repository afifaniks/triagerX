{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import RobertaModel, RobertaConfig, RobertaTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the teacher model (RoBERTa-large)\n",
    "teacher_model = RobertaModel.from_pretrained('roberta-large', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_config = RobertaConfig.from_pretrained(\"roberta-large\")\n",
    "student_config.num_hidden_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = RobertaModel(student_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_data = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/deeptriage/deep_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "product version       allurls if applicable  not applicableother browsers testedadd ok or fail after other browsers where you have tested this issue     safari 3 fail    firefox 3 pass         ie 7 partial failwhat steps will reproduce the problem1 try to install an adblockingaddon2 failwhat is the expected resultthe expected result is an addonapi similiar to firefox extensionsallowing third parties to enhance the functionality of chromewhat happens insteadchrome offers next to no customizationoptionsplease provide any additional information below attach a screenshot ifpossiblenot applicable\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(open_data)[:1000]\n",
    "print(len(df))\n",
    "print(df.iloc[15].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_distill_data(df):\n",
    "    df[\"text\"] = df.apply(\n",
    "        lambda x: str(x[\"issue_title\"]) + \"\\n\" + str(x[\"description\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\"[^A-Za-z0-9 ]+\", \" \", regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_distill_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer,\n",
    "        feature: str,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = [\n",
    "            self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "\n",
    "        return batch_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DistillationDataset(df, tokenizer, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_dataloader = DataLoader(dataset, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "s = teacher_model.config.num_hidden_layers // student_model.config.num_hidden_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = teacher_model.to(device)\n",
    "student_model = student_model.to(device)\n",
    "# optimizer = optimizer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_teacher_layers = teacher_model.config.num_hidden_layers\n",
    "num_student_layers = student_model.config.num_hidden_layers\n",
    "s = num_teacher_layers // num_student_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pkd_loss(student_reps, teacher_reps, s):\n",
    "    loss = 0\n",
    "    for i in range(len(student_reps)):\n",
    "        student_layer = student_reps[i]\n",
    "        teacher_layer = teacher_reps[i * s]\n",
    "        student_layer = F.normalize(student_layer, p=2, dim=-1)\n",
    "        teacher_layer = F.normalize(teacher_layer, p=2, dim=-1)\n",
    "        loss += F.mse_loss(student_layer, teacher_layer)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s, loss=0.00216]\n",
      "Epoch 2/3: 100%|██████████| 100/100 [00:34<00:00,  2.92it/s, loss=0.00185]\n",
      "Epoch 3/3: 100%|██████████| 100/100 [00:34<00:00,  2.91it/s, loss=0.00154]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Wrap the dataloader with tqdm for progress bar\n",
    "    progress_bar = tqdm(distill_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].squeeze(1).to(student_model.device)\n",
    "        attention_mask = batch['attention_mask'].squeeze(1).to(student_model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask)\n",
    "            teacher_hidden_states = teacher_outputs.hidden_states\n",
    "\n",
    "        student_outputs = student_model(input_ids, attention_mask=attention_mask)\n",
    "        student_hidden_states = student_outputs.hidden_states\n",
    "        # break\n",
    "\n",
    "        loss = pkd_loss(student_hidden_states, teacher_hidden_states, s)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar with loss value\n",
    "        progress_bar.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 20 23:01:40 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              38W / 250W |   6269MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1805090      C   ...amun/miniconda3/envs/trx/bin/python     6256MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distill_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m distill_dataloader\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distill_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "del distill_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 20 23:04:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              38W / 250W |   2837MiB / 40960MiB |     77%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1805090      C   ...amun/miniconda3/envs/trx/bin/python     2824MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Collect garbage\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Classifier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df[\"text\"] = df.apply(\n",
    "        lambda x: str(x[\"issue_title\"]) + \"\\n\" + str(x[\"description\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df['text'] = df['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\"[^A-Za-z0-9 ]+\", \" \", regex=True)\n",
    "    df[\"text\"] = df['text'].str.replace(\" +\", \" \", regex=True)\n",
    "\n",
    "    min_length = 15\n",
    "    df = df[df[\"text\"].str.len().gt(min_length)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/mdafifal.mamun/notebooks/triagerX/notebook/data/deeptriage/gc_20_topics_kmeans.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df[df[\"owner\"].notna()]\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues: 109972\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of issues: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per block: 10997\n"
     ]
    }
   ],
   "source": [
    "num_cv = 10\n",
    "# sample_threshold=20 # Threshold to filter developers\n",
    "samples_per_block = len(df) // num_cv\n",
    "print(f\"Samples per block: {samples_per_block}\")\n",
    "\n",
    "block = 1\n",
    "sliced_df = df[: samples_per_block * (block+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 10997, Validation data: 10806\n",
      "Number of developers: 803\n"
     ]
    }
   ],
   "source": [
    "# Train and Validation preparation\n",
    "\n",
    "X_df = sliced_df[:samples_per_block*block]\n",
    "y_df = sliced_df[samples_per_block*block : samples_per_block * (block+1)]\n",
    "\n",
    "# developers = X_df[\"owner\"].value_counts()\n",
    "# filtered_developers = developers.index[developers >= sample_threshold]\n",
    "# X_df = X_df[X_df[\"owner\"].isin(filtered_developers)]\n",
    "\n",
    "train_owners = set(X_df[\"owner\"])\n",
    "test_owners = set(y_df[\"owner\"])\n",
    "\n",
    "unwanted = list(test_owners - train_owners)\n",
    "\n",
    "y_df = y_df[~y_df[\"owner\"].isin(unwanted)]\n",
    "\n",
    "print(f\"Training data: {len(X_df)}, Validation data: {len(y_df)}\")\n",
    "print(f\"Number of developers: {len(X_df.owner.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1805090/2653260710.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_df[\"owner_id\"] = X_df[\"owner\"].apply(lambda owner: lbl2idx[owner])\n"
     ]
    }
   ],
   "source": [
    "# Label encode developers\n",
    "\n",
    "lbl2idx = {}\n",
    "\n",
    "train_owners = sorted(train_owners)\n",
    "\n",
    "for idx, dev in enumerate(train_owners):\n",
    "    lbl2idx[dev] = idx\n",
    "\n",
    "X_df[\"owner_id\"] = X_df[\"owner\"].apply(lambda owner: lbl2idx[owner])\n",
    "y_df[\"owner_id\"] = y_df[\"owner\"].apply(lambda owner: lbl2idx[owner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        tokenizer: RobertaTokenizer,\n",
    "        feature: str = \"text\",\n",
    "        target: str = \"owner_id\",\n",
    "    ):\n",
    "        print(\"Generating torch dataset...\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = [label for label in df[target]]\n",
    "        print(\"Tokenizing texts...\")\n",
    "        self.texts = [self.tokenizer(\n",
    "                row[feature],\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LBTPClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, student_model, output_size, unfrozen_layers=1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.base_model = student_model\n",
    "\n",
    "        # Freeze embedding layers\n",
    "        for p in self.base_model.embeddings.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Freeze encoder layers till last {unfrozen_layers} layers\n",
    "        for i in range(0, self.base_model.config.num_hidden_layers - unfrozen_layers):\n",
    "            for p in self.base_model.encoder.layer[i].parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        filter_sizes = [3, 4, 5, 6]\n",
    "        self._num_filters = 256\n",
    "        self._max_tokens = 512\n",
    "        self._embed_size = student_model.config.hidden_size\n",
    "        self.unfrozen_layers = unfrozen_layers\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv2d(1, self._num_filters, (K, self._embed_size)),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Flatten(),\n",
    "                            nn.MaxPool1d(self._max_tokens - (K - 1)),\n",
    "                            nn.Flatten(start_dim=1),\n",
    "                        )\n",
    "                        for K in filter_sizes\n",
    "                    ]\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifiers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(\n",
    "                    len(filter_sizes) * self._num_filters + self._embed_size, output_size\n",
    "                )\n",
    "                for _ in range(unfrozen_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = []\n",
    "\n",
    "        base_out = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        pooler_out = base_out.pooler_output.squeeze(0)\n",
    "        hidden_states = base_out.hidden_states[-self.unfrozen_layers :]\n",
    "\n",
    "        for i in range(self.unfrozen_layers):\n",
    "            batch_size, sequence_length, hidden_size = hidden_states[i].size()\n",
    "            x = [\n",
    "                conv(hidden_states[i].view(batch_size, 1, sequence_length, hidden_size))\n",
    "                for conv in self.conv_blocks[i]\n",
    "            ]\n",
    "            x = torch.cat(x, dim=1)\n",
    "            x = torch.cat([pooler_out, x], dim=1)\n",
    "            # x = self.dropout(x)\n",
    "            x = self.classifiers[i](x)\n",
    "\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        prediction,\n",
    "        labels\n",
    "    ) -> torch.Tensor:\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(len(prediction)):\n",
    "            loss += self._ce(prediction[i], labels)\n",
    "            # print(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LBTPClassifier(\n",
    "    student_model,\n",
    "    output_size=len(X_df.owner_id.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 12\n",
    "batch_size = 10\n",
    "\n",
    "criterion = CombineLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating torch dataset...\n",
      "Tokenizing texts...\n",
      "Generating torch dataset...\n",
      "Tokenizing texts...\n"
     ]
    }
   ],
   "source": [
    "train = TriageDataset(X_df, tokenizer)\n",
    "val = TriageDataset(y_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        topk,\n",
    "    ):\n",
    "        log = f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                    | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                    | Val Loss: {total_loss_val / len(validation_data): .3f} \\\n",
    "                    | Val Accuracy: {total_acc_val / len(validation_data): .3f} \\\n",
    "                    | Top 10: {topk} \\\n",
    "                    | Precision: {precision: .3f} \\\n",
    "                    | Recall: {recall: .3f} \\\n",
    "                    | F1-score: {f1_score: .3f}\"\n",
    "\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps: 100%|██████████| 1100/1100 [01:12<00:00, 15.23it/s]\n",
      "Validation Steps: 100%|██████████| 1081/1081 [00:42<00:00, 25.68it/s]\n",
      "/home/mdafifal.mamun/miniconda3/envs/trx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.612                     | Train Accuracy:  0.026                     | Val Loss:  0.633                     | Val Accuracy:  0.006                     | Top 10: 0.08115861558393485                     | Precision:  0.000                     | Recall:  0.001                     | F1-score:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Steps:  18%|█▊        | 199/1100 [00:13<00:59, 15.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m total_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Steps\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# print(train_input)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     train_label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     mask \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader, desc=\"Training Steps\"):\n",
    "        # print(train_input)\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input[\"attention_mask\"].squeeze(1).to(device)\n",
    "        input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, train_label.long())\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        output = torch.sum(torch.stack(output), 0)\n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        \n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_acc_val = 0\n",
    "    total_loss_val = 0\n",
    "    correct_top_k = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for val_input, val_label in tqdm(val_dataloader, desc=\"Validation Steps\"):\n",
    "            val_label = val_label.to(device)            \n",
    "            input_id = val_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            mask = val_input[\"attention_mask\"].squeeze(1).to(device)    \n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            output = torch.sum(torch.stack(output), 0)\n",
    "            _, top_k_predictions = output.topk(10, 1, True, True)\n",
    "\n",
    "            top_k_predictions = top_k_predictions.t()\n",
    "\n",
    "            correct_top_k += (\n",
    "                top_k_predictions.eq(\n",
    "                    val_label.view(1, -1).expand_as(top_k_predictions)\n",
    "                )\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "\n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "\n",
    "            all_preds.append(output.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.append(val_label.cpu().numpy())\n",
    "\n",
    "            total_acc_val += acc\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    top10 = correct_top_k / len(y_df)\n",
    "\n",
    "    log_step(\n",
    "        epoch_num,\n",
    "        total_acc_train,\n",
    "        total_acc_val,\n",
    "        total_loss_train,\n",
    "        total_loss_val,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        X_df,\n",
    "        y_df,\n",
    "        top10,\n",
    "    )\n",
    "\n",
    "    val_loss = total_loss_val / len(y_df)\n",
    "\n",
    "    # if val_loss < best_loss:\n",
    "    #     print(\"Found new best model. Saving weights...\")\n",
    "    #     torch.save(model.state_dict(), weights_save_location)\n",
    "    #     best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
