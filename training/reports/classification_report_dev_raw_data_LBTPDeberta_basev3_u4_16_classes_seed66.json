{
  "0": {
    "precision": 0.4090909090909091,
    "recall": 0.42857142857142855,
    "f1-score": 0.4186046511627907,
    "support": 42.0
  },
  "1": {
    "precision": 0.38235294117647056,
    "recall": 0.203125,
    "f1-score": 0.2653061224489796,
    "support": 64.0
  },
  "2": {
    "precision": 1.0,
    "recall": 0.14285714285714285,
    "f1-score": 0.25,
    "support": 7.0
  },
  "3": {
    "precision": 0.1111111111111111,
    "recall": 0.3333333333333333,
    "f1-score": 0.16666666666666666,
    "support": 3.0
  },
  "4": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1.0
  },
  "5": {
    "precision": 0.4639175257731959,
    "recall": 0.5487804878048781,
    "f1-score": 0.5027932960893854,
    "support": 82.0
  },
  "6": {
    "precision": 1.0,
    "recall": 0.16666666666666666,
    "f1-score": 0.2857142857142857,
    "support": 6.0
  },
  "7": {
    "precision": 0.24242424242424243,
    "recall": 0.32,
    "f1-score": 0.2758620689655172,
    "support": 25.0
  },
  "8": {
    "precision": 0.125,
    "recall": 0.23076923076923078,
    "f1-score": 0.16216216216216217,
    "support": 13.0
  },
  "9": {
    "precision": 0.3,
    "recall": 0.42857142857142855,
    "f1-score": 0.3529411764705882,
    "support": 7.0
  },
  "10": {
    "precision": 0.4666666666666667,
    "recall": 0.4117647058823529,
    "f1-score": 0.43749999999999994,
    "support": 51.0
  },
  "11": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 7.0
  },
  "12": {
    "precision": 0.379746835443038,
    "recall": 0.43478260869565216,
    "f1-score": 0.40540540540540543,
    "support": 69.0
  },
  "13": {
    "precision": 0.058823529411764705,
    "recall": 0.08333333333333333,
    "f1-score": 0.06896551724137931,
    "support": 12.0
  },
  "14": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 5.0
  },
  "accuracy": 0.3680203045685279,
  "macro avg": {
    "precision": 0.3292755840731599,
    "recall": 0.24883702443236316,
    "f1-score": 0.23946142348847738,
    "support": 394.0
  },
  "weighted avg": {
    "precision": 0.38964720031209277,
    "recall": 0.3680203045685279,
    "f1-score": 0.3612757117426317,
    "support": 394.0
  },
  "top3_accuracy": 0.6472081218274112,
  "run_name": "dev_raw_data_LBTPDeberta_basev3_u4_16_classes_seed66",
  "model_location": "/work/disa_lab/projects/triagerx/models/dev_raw_data_LBTPDeberta_basev3_u4_16_classes_seed66.pt"
}