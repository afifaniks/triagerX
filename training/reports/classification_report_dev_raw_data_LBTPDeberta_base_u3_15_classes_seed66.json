{
  "0": {
    "precision": 0.6129032258064516,
    "recall": 0.4523809523809524,
    "f1-score": 0.5205479452054794,
    "support": 42.0
  },
  "1": {
    "precision": 0.3333333333333333,
    "recall": 0.1875,
    "f1-score": 0.24000000000000005,
    "support": 64.0
  },
  "2": {
    "precision": 0.6,
    "recall": 0.42857142857142855,
    "f1-score": 0.5,
    "support": 7.0
  },
  "3": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3.0
  },
  "4": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1.0
  },
  "5": {
    "precision": 0.46551724137931033,
    "recall": 0.6585365853658537,
    "f1-score": 0.5454545454545454,
    "support": 82.0
  },
  "6": {
    "precision": 1.0,
    "recall": 0.16666666666666666,
    "f1-score": 0.2857142857142857,
    "support": 6.0
  },
  "7": {
    "precision": 0.22727272727272727,
    "recall": 0.2,
    "f1-score": 0.21276595744680854,
    "support": 25.0
  },
  "8": {
    "precision": 0.16666666666666666,
    "recall": 0.3076923076923077,
    "f1-score": 0.21621621621621623,
    "support": 13.0
  },
  "9": {
    "precision": 0.35714285714285715,
    "recall": 0.7142857142857143,
    "f1-score": 0.4761904761904762,
    "support": 7.0
  },
  "10": {
    "precision": 0.48717948717948717,
    "recall": 0.37254901960784315,
    "f1-score": 0.42222222222222217,
    "support": 51.0
  },
  "11": {
    "precision": 0.16666666666666666,
    "recall": 0.14285714285714285,
    "f1-score": 0.15384615384615383,
    "support": 7.0
  },
  "12": {
    "precision": 0.36764705882352944,
    "recall": 0.36231884057971014,
    "f1-score": 0.36496350364963503,
    "support": 69.0
  },
  "13": {
    "precision": 0.043478260869565216,
    "recall": 0.08333333333333333,
    "f1-score": 0.057142857142857134,
    "support": 12.0
  },
  "14": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 5.0
  },
  "accuracy": 0.37817258883248733,
  "macro avg": {
    "precision": 0.321853835009373,
    "recall": 0.27177946608939685,
    "f1-score": 0.2663376108725786,
    "support": 394.0
  },
  "weighted avg": {
    "precision": 0.4002496806113488,
    "recall": 0.37817258883248733,
    "f1-score": 0.37336628849821935,
    "support": 394.0
  },
  "top3_accuracy": 0.6954314720812182,
  "run_name": "dev_raw_data_LBTPDeberta_base_u3_15_classes_seed66",
  "model_location": "/work/disa_lab/projects/triagerx/models/dev_raw_data_LBTPDeberta_base_u3_15_classes_seed66.pt"
}