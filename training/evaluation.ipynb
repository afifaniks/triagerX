{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir = \"/home/mdafifal.mamun/notebooks/triagerX/training/reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_state</th>\n",
       "      <th>creator</th>\n",
       "      <th>labels</th>\n",
       "      <th>assignees</th>\n",
       "      <th>component</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Build instructions link in the README.md point...</td>\n",
       "      <td>The `Build instructions` link in the `README.m...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issues/2</td>\n",
       "      <td>closed</td>\n",
       "      <td>aarongraham9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gireeshpunathil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bug report highlights an issue with the \"B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>FAQ link in the README is broken</td>\n",
       "      <td>FAQ link in the README leads to: http://www.ec...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issues/3</td>\n",
       "      <td>closed</td>\n",
       "      <td>dorrab</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mpirvu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bug report states that the FAQ link in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Link to DockerFile on build instruction page i...</td>\n",
       "      <td>Link for DockerFile on [build instruction page...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issues/5</td>\n",
       "      <td>closed</td>\n",
       "      <td>r30shah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r30shah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bug report describes an issue with the lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>HOWTO Request: Managing changes across depende...</td>\n",
       "      <td>Like all projects, OpenJ9 builds on the should...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>open</td>\n",
       "      <td>mgaudet</td>\n",
       "      <td>question</td>\n",
       "      <td>hzongaro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is a summarized version of the bug report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>Compilation Output is too Verbose</td>\n",
       "      <td>The output when compiling the OpenJ9 source co...</td>\n",
       "      <td>https://github.com/eclipse-openj9/openj9/issue...</td>\n",
       "      <td>closed</td>\n",
       "      <td>rservant</td>\n",
       "      <td>enhancement, comp:build</td>\n",
       "      <td>hzongaro</td>\n",
       "      <td>comp:build</td>\n",
       "      <td>Here is a summarized version of the bug report...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  issue_number  \\\n",
       "0           0             2   \n",
       "1           1             3   \n",
       "2           2             5   \n",
       "3           3            11   \n",
       "4           4            13   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0  Build instructions link in the README.md point...   \n",
       "1                  FAQ link in the README is broken    \n",
       "2  Link to DockerFile on build instruction page i...   \n",
       "3  HOWTO Request: Managing changes across depende...   \n",
       "4                  Compilation Output is too Verbose   \n",
       "\n",
       "                                          issue_body  \\\n",
       "0  The `Build instructions` link in the `README.m...   \n",
       "1  FAQ link in the README leads to: http://www.ec...   \n",
       "2  Link for DockerFile on [build instruction page...   \n",
       "3  Like all projects, OpenJ9 builds on the should...   \n",
       "4  The output when compiling the OpenJ9 source co...   \n",
       "\n",
       "                                           issue_url issue_state  \\\n",
       "0  https://github.com/eclipse-openj9/openj9/issues/2      closed   \n",
       "1  https://github.com/eclipse-openj9/openj9/issues/3      closed   \n",
       "2  https://github.com/eclipse-openj9/openj9/issues/5      closed   \n",
       "3  https://github.com/eclipse-openj9/openj9/issue...        open   \n",
       "4  https://github.com/eclipse-openj9/openj9/issue...      closed   \n",
       "\n",
       "        creator                   labels        assignees   component  \\\n",
       "0  aarongraham9                      NaN  gireeshpunathil         NaN   \n",
       "1        dorrab                      NaN           mpirvu         NaN   \n",
       "2       r30shah                      NaN          r30shah         NaN   \n",
       "3       mgaudet                 question         hzongaro         NaN   \n",
       "4      rservant  enhancement, comp:build         hzongaro  comp:build   \n",
       "\n",
       "                                             summary  \n",
       "0  The bug report highlights an issue with the \"B...  \n",
       "1  The bug report states that the FAQ link in the...  \n",
       "2  The bug report describes an issue with the lin...  \n",
       "3  Here is a summarized version of the bug report...  \n",
       "4  Here is a summarized version of the bug report...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = \"/home/mdafifal.mamun/notebooks/triagerX/triagerx/data/df_all_summarized.csv\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(d)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summarized version of the bug report in natural language:\n",
      "The bug report describes a failure in the cmdLineTester_dumpromclasstests_0 test on AIX. The test was run using the BCI agent core and the jdmpview command to analyze a core dump file. The test started at 2018/11/06 01:26:12 Central Standard Time and took 959 milliseconds to execute. The test result was FAILED. The output from the test indicates that the dump file could not be loaded and a valid ImageFactory could not be created. The test was expecting specific output matches, but none of them were found. The expected matches included \"java/lang/Object\", \"intermediateClassData\", \"DDRInteractiveCommandException\", \"unable to read\", \"could not read\", and \"dump event\".\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1270].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/eclipse-openj9/openj9/issues/3562\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1270].issue_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(report_prefix: str):\n",
    "    accuracies = []\n",
    "    top3_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    \n",
    "    reports = list(pathlib.Path(report_dir).glob(report_prefix))\n",
    "\n",
    "    print(f\"Report prefix: {report_prefix}, total reports:  {len(reports)}\")\n",
    "    \n",
    "    for report_path in sorted(reports):\n",
    "        with open(report_path.as_posix(), \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            avg_type = \"macro avg\"\n",
    "\n",
    "            accuracies.append(json_data[\"accuracy\"])\n",
    "            top3_accuracies.append(json_data[\"top3_accuracy\"])\n",
    "            precisions.append(json_data[avg_type][\"precision\"])\n",
    "            recalls.append(json_data[avg_type][\"recall\"])\n",
    "            f1s.append(json_data[avg_type][\"f1-score\"])\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    avg_top3_accuracy = sum(top3_accuracies) / len(top3_accuracies)\n",
    "    avg_precision = sum(precisions) / len(precisions)\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    avg_f1_score = sum(f1s) / len(f1s)\n",
    "\n",
    "    return {\n",
    "        \"average_accuracy\": avg_accuracy,\n",
    "        \"average_top3_accuracy\": avg_top3_accuracy,\n",
    "        \"average_test_precision\": avg_precision,\n",
    "        \"average_test_recall\": avg_recall,\n",
    "        \"average_test_f1_score\": avg_f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report prefix: classification_report_comp_raw*, total reports:  3\n",
      "Report prefix: classification_report_comp_sp*, total reports:  3\n",
      "Report prefix: classification_report_comp_summary_description*, total reports:  3\n",
      "Report prefix: classification_report_comp_summary_sp_tokens*, total reports:  3\n",
      "+----------------------------+--------------------+------------------------+------------------------+---------------------+-----------------------+\n",
      "|    Preprocessing Method    |  Average Accuracy  | Average Top-3 Accuracy | Average Test Precision | Average Test Recall | Average Test F1 Score |\n",
      "+----------------------------+--------------------+------------------------+------------------------+---------------------+-----------------------+\n",
      "|      No Preprocessing      | 0.7529665587918015 |   0.9848975188781014   |   0.6285117814438443   | 0.6600723955075787  |  0.6260089095834536   |\n",
      "| Special Tokens (sp_tokens) | 0.7664509169363538 |   0.9848975188781014   |   0.6229234484485358   | 0.7157282222047329  |  0.6482618189736045   |\n",
      "|   Summary + Description    | 0.7901833872707659 |   0.9843581445523193   |   0.7013731576491714   |  0.678790605677743  |  0.6776835092544609   |\n",
      "|  Summary + Special Tokens  | 0.7518878101402374 |   0.988673139158576    |   0.5931364648341221   | 0.6459997757695483  |  0.6094848986129722   |\n",
      "+----------------------------+--------------------+------------------------+------------------------+---------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "training_type = \"comp\"\n",
    "\n",
    "no_preprocessing = compute_metrics(f\"classification_report_{training_type}_raw*\")\n",
    "sp_tokens = compute_metrics(f\"classification_report_{training_type}_sp*\")\n",
    "summary_description = compute_metrics(f\"classification_report_{training_type}_summary_description*\")\n",
    "summary_sp_tokens = compute_metrics(f\"classification_report_{training_type}_summary_sp_tokens*\")\n",
    "\n",
    "data = [\n",
    "    ['No Preprocessing', no_preprocessing['average_accuracy'], no_preprocessing['average_top3_accuracy'], no_preprocessing['average_test_precision'], no_preprocessing['average_test_recall'], no_preprocessing['average_test_f1_score']],\n",
    "    ['Special Tokens (sp_tokens)', sp_tokens['average_accuracy'], sp_tokens['average_top3_accuracy'], sp_tokens['average_test_precision'], sp_tokens['average_test_recall'], sp_tokens['average_test_f1_score']],\n",
    "    ['Summary + Description', summary_description['average_accuracy'], summary_description['average_top3_accuracy'], summary_description['average_test_precision'], summary_description['average_test_recall'], summary_description['average_test_f1_score']],\n",
    "    ['Summary + Special Tokens', summary_sp_tokens['average_accuracy'], summary_sp_tokens['average_top3_accuracy'], summary_sp_tokens['average_test_precision'], summary_sp_tokens['average_test_recall'], summary_sp_tokens['average_test_f1_score']]\n",
    "]\n",
    "\n",
    "# Define the headers\n",
    "headers = ['Preprocessing Method', 'Average Accuracy', 'Average Top-3 Accuracy', 'Average Test Precision', 'Average Test Recall', 'Average Test F1 Score']\n",
    "\n",
    "print(tabulate(data, headers=headers, tablefmt='pretty'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
